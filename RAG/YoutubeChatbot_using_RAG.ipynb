{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JEozLWCAcY-8"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"GEMINI_API_KEY\"] = \"Your_GEMINI_API_KEY_Here\"\n",
        "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"Your_HUGGINGFACEHUB_API_TOKEN_Here\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "1IOe7R_3dsYv"
      },
      "outputs": [],
      "source": [
        "!pip install -q youtube-transcript-api langchain-community langchain-openai \\\n",
        "               faiss-cpu tiktoken python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "14NXs-Tmebjv",
        "outputId": "c6adaa86-0095-4cdb-c78f-76f977846cef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting langchain-google-genai\n",
            "  Downloading langchain_google_genai-4.2.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting filetype<2.0.0,>=1.2.0 (from langchain-google-genai)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting google-genai<2.0.0,>=1.56.0 (from langchain-google-genai)\n",
            "  Downloading google_genai-1.57.0-py3-none-any.whl.metadata (53 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/53.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.3/53.3 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: langchain-core<2.0.0,>=1.2.5 in /usr/local/lib/python3.12/dist-packages (from langchain-google-genai) (1.2.6)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from langchain-google-genai) (2.12.3)\n",
            "Requirement already satisfied: anyio<5.0.0,>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.56.0->langchain-google-genai) (4.12.1)\n",
            "Collecting google-auth<3.0.0,>=2.46.0 (from google-auth[requests]<3.0.0,>=2.46.0->google-genai<2.0.0,>=1.56.0->langchain-google-genai)\n",
            "  Downloading google_auth-2.47.0-py3-none-any.whl.metadata (6.4 kB)\n",
            "Requirement already satisfied: httpx<1.0.0,>=0.28.1 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.56.0->langchain-google-genai) (0.28.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.28.1 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.56.0->langchain-google-genai) (2.32.5)\n",
            "Requirement already satisfied: tenacity<9.2.0,>=8.2.3 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.56.0->langchain-google-genai) (9.1.2)\n",
            "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.56.0->langchain-google-genai) (15.0.1)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.11.0 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.56.0->langchain-google-genai) (4.15.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.56.0->langchain-google-genai) (1.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.56.0->langchain-google-genai) (1.3.1)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.5->langchain-google-genai) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.5->langchain-google-genai) (0.6.1)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.5->langchain-google-genai) (25.0)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.5->langchain-google-genai) (6.0.3)\n",
            "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.5->langchain-google-genai) (0.13.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.0.0->langchain-google-genai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.0.0->langchain-google-genai) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.0.0->langchain-google-genai) (0.4.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0.0,>=4.8.0->google-genai<2.0.0,>=1.56.0->langchain-google-genai) (3.11)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.46.0->google-auth[requests]<3.0.0,>=2.46.0->google-genai<2.0.0,>=1.56.0->langchain-google-genai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.46.0->google-auth[requests]<3.0.0,>=2.46.0->google-genai<2.0.0,>=1.56.0->langchain-google-genai) (4.9.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.56.0->langchain-google-genai) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.56.0->langchain-google-genai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.56.0->langchain-google-genai) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.2.5->langchain-google-genai) (3.0.0)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.5->langchain-google-genai) (3.11.5)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.5->langchain-google-genai) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.5->langchain-google-genai) (0.25.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.28.1->google-genai<2.0.0,>=1.56.0->langchain-google-genai) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.28.1->google-genai<2.0.0,>=1.56.0->langchain-google-genai) (2.5.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.46.0->google-auth[requests]<3.0.0,>=2.46.0->google-genai<2.0.0,>=1.56.0->langchain-google-genai) (0.6.1)\n",
            "Downloading langchain_google_genai-4.2.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.5/66.5 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading google_genai-1.57.0-py3-none-any.whl (713 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m713.3/713.3 kB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading google_auth-2.47.0-py3-none-any.whl (234 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m234.9/234.9 kB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: filetype, google-auth, google-genai, langchain-google-genai\n",
            "  Attempting uninstall: google-auth\n",
            "    Found existing installation: google-auth 2.43.0\n",
            "    Uninstalling google-auth-2.43.0:\n",
            "      Successfully uninstalled google-auth-2.43.0\n",
            "  Attempting uninstall: google-genai\n",
            "    Found existing installation: google-genai 1.55.0\n",
            "    Uninstalling google-genai-1.55.0:\n",
            "      Successfully uninstalled google-genai-1.55.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires google-auth==2.43.0, but you have google-auth 2.47.0 which is incompatible.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed filetype-1.2.0 google-auth-2.47.0 google-genai-1.57.0 langchain-google-genai-4.2.0\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "19a2a5b2fea9433981c7161ddcc62779",
              "pip_warning": {
                "packages": [
                  "google"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "pip install langchain-google-genai\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "lWTq7XLedvw8"
      },
      "outputs": [],
      "source": [
        "from youtube_transcript_api import YouTubeTranscriptApi, TranscriptsDisabled\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_core.prompts import PromptTemplate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0-HLQWdel1m"
      },
      "source": [
        "## Step 1a - Indexing (Document Ingestion)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P5AdPDMJeknP",
        "outputId": "eb07d9e6-e60d-4fe8-ae69-4d13166dbe60"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "the following is a conversation with demus hasabis ceo and co-founder of deepmind a company that has published and builds some of the most incredible artificial intelligence systems in the history of computing including alfred zero that learned all by itself to play the game of gold better than any human in the world and alpha fold two that solved protein folding both tasks considered nearly impossible for a very long time demus is widely considered to be one of the most brilliant and impactful humans in the history of artificial intelligence and science and engineering in general this was truly an honor and a pleasure for me to finally sit down with him for this conversation and i'm sure we will talk many times again in the future this is the lex friedman podcast to support it please check out our sponsors in the description and now dear friends here's demis hassabis let's start with a bit of a personal question am i an ai program you wrote to interview people until i get good enough to interview you well i'll be impressed if if you were i'd be impressed by myself if you were i don't think we're quite up to that yet but uh maybe you're from the future lex if you did would you tell me is that is that a good thing to tell a language model that's tasked with interviewing that it is in fact um ai maybe we're in a kind of meta turing test uh probably probably it would be a good idea not to tell you so it doesn't change your behavior right this is a kind of heisenberg uncertainty principle situation if i told you you behave differently yeah maybe that's what's happening with us of course this is a benchmark from the future where they replay 2022 as a year before ais were good enough yet and now we want to see is it going to pass exactly if i was such a program would you be able to tell do you think so to the touring test question you've talked about the benchmark for solving intelligence what would be the impressive thing you've talked about winning a nobel prize in a system winning a nobel prize but i still return to the touring test as a compelling test the spirit of the touring test is a compelling test yeah the turing test of course it's been unbelievably influential and turing's one of my all-time heroes but i think if you look back at the 1950 papers original paper and read the original you'll see i don't think he meant it to be a rigorous formal test i think it was more like a thought experiment almost a bit of philosophy he was writing if you look at the style of the paper and you can see he didn't specify it very rigorously so for example he didn't specify the knowledge that the expert or judge would have um not you know how much time would they have to investigate this so these important parameters if you were gonna make it uh a true sort of formal test um and you know some by some measures people claimed the turing test passed several you know a decade ago i remember someone claiming that with a with a kind of very bog standard normal uh logic model um because they pretended it was a it was a kid so the the judges thought that the machine you know was was a was a child so um that would be very different from an expert ai person uh interrogating a machine and knowing how it was built and so on so i think um you know we should probably move away from that as a formal test and move more towards a general test where we test the ai capabilities on a range of tasks and see if it reaches human level or above performance on maybe thousands perhaps even millions of tasks eventually and cover the entire sort of cognitive space so i think for its time it was an amazing thought experiment and also 1950s obviously it was barely the dawn of the computer age so of course he only thought about text and now um we have a lot more different inputs so yeah maybe the better thing to test is the generalizability so across multiple tasks but i think it's also possible as as systems like god show that eventually that might map right back to language so you might be able to demonstrate your ability to generalize across tasks by then communicating your ability to generalize across tasks which is kind of what we do through conversation anyway when we jump around ultimately what's in there in that conversation is not just you moving around knowledge it's you moving around like these entirely different modalities of understanding that ultimately map to your ability to to uh operate successfully in all these domains which you can think of as tasks yeah i think certainly we as humans use language as our main generalization communication tool so i think we end up thinking in language and expressing our solutions in language um so it's going to be very powerful uh uh mode in which to uh explain you know the system to explain what it's doing um but i don't think it's the only uh uh modality that matters so i think there's gonna be a lot of you know there's there's a lot of different ways to express uh capabilities uh other than just language yeah visual robotics body language um yeah action is the interactive aspect of all that that's all part of it but what's interesting with gato is that it's a it's it's it's sort of pushing prediction to the maximum in terms of like you know mapping arbitrary sequences to other sequences and sort of just predicting what's going to happen next so prediction seems to be fundamental to intelligence and what you're predicting doesn't so much matter yeah it seems like you can generalize that quite well so obviously language models predict the next word um gato predicts potentially any uh action or any token uh and it's just the beginning really it's our most general agent one could call it so far but um you know that itself can be scaled up massively more than we've done so far obviously we're in the in the middle of doing that but the big part of solving agi is creating benchmarks that help us get closer and closer sort of creating benchmarks that test the journalizability and it's just still interesting that this fella alan turing was one of the first and probably still one of the only people that was trying maybe philosophically but was trying to formulate a benchmark that could be followed it is even though it's it's fuzzy it's still sufficiently rigorous to where you can run that test and i still think something like the touring test will at the end of the day be the thing that truly impresses other humans so that you can have a close friend who's an ai system for that friend to be a good friend they're going to have to be able to uh play starcraft and they're going to have to do all of these tasks um get you a beer so the robotics tasks uh play games with you use language humor all those kinds of things but that ultimately can boil down to language it feels like not in terms of the ai community but in terms of the actual impact of general intelligence on the world it feels like language will be the place where it truly shines i think so because it's such an important kind of input output for us i think you're right i think the turing test that what the the kind of the the philosophy behind it which is the idea of can can a machine mimic the behaviors of a human and men and i would say wider than just language and text then you know in terms of actions and everything else creativity all these things then um if it can sort of match or exceed human cognitive capabilities then i think we have a you know true intelligence so i thought from that perspective you're right i think he did formulate the right uh kind of uh setup i just i think there'll be a kind of humor in the ai systems of the future looking back to this conversation and thinking about the touring test and uh also thinking about by that time they would know which year they were finally able to sort of cross the threshold of human level intelligence and think how funny it is that we humans were still confused about this whole problem that has been long ago been solved well hello to the ai agents of the future anyway so going back to your to your journey when did you fall in love with programming first well it's pretty uh pretty young age actually so um you know i started off uh actually games was my first love so starting to play chess when i was around four years old and then um it was actually with winnings from a chess competition that i managed to buy my first chess computer when i was about eight years old it was a zx spectrum which was hugely popular in the uk at the time and uh it's amazing machine because i think it trained a whole generation of programmers in the uk because it was so accessible you know you literally switched it on and there was the basic prompt and you could just get going and um my parents didn't really know anything about computers so but because it was my money from a chess competition i could i could say i i wanted to buy it uh and then you know i just went to bookstores got books on programming and um started typing in you know the programming code and and then of course um once you start doing that you start adjusting it and then making your own games and that's when i fell in love with computers and realized that they were a very magical device um in a way i kind of i would have been able to explain this at the time but i felt that they were sort of almost a magical extension of your mind i always had this feeling and i've always loved this about computers that you can set them off doing something some task for you you can go to sleep come back the next day and it's solved um you know that feels magical to me so i mean all machines do that to some extent they all enhance our natural capabilities obviously cars make us allow us to move faster than we can run but this was a machine to extend the mind and and then of course ai is the ultimate expression of what a machine may be able to do or learn so very naturally for me that thought extended into into ai quite quickly remember the the programming language that was first started special to the machine no it was just the base it was just i think it was just basic uh on the zx spectrum i don't know what specific form it was and then later on i got a commodore amiga which uh was a fantastic machine no you're just showing off so yeah well lots of my friends had atari st's and i i managed to get amigas it was a bit more powerful and uh and that was incredible and used to do um programming in assembler and and uh also amos basic this this specific form of basic it was incredible actually as well all my coding skills and when did you fall in love with ai so when did you first start to gain an understanding that you can not just write programs that do some mathematical operations for you while you sleep but something that's a keen to bringing an entity to life sort of a thing that can figure out something more complicated than uh than a simple mathematical operation yeah so there was a few stages for me all while i was very young so first of all as i was trying to improve at playing chess i was captaining various england junior chess teams and at the time when i was about you know maybe 10 11 years old i was gonna become a professional chess player that was my first thought um that dream was there sure she tried to get to the highest level yeah so i was um you know i got to when i was about 12 years old i got to master stand and i was second highest rated player in the world to judith polgar who obviously ended up being an amazing chess player and uh world women's champion and when i was trying to improve at chess where you know what you do is you obviously first of all you're trying to improve your own thinking processes so that leads you to thinking about thinking how is your brain coming up with these ideas why is it making mistakes how can you how can you improve that thought process but the second thing is that you it was just the beginning this was like in the in the early 80s mid 80s of chess computers if you remember they were physical boards like the one we have in front of us and you pressed down the you know the squares and i think kasparov had a branded version of it that i i i got and um you were you know used to they're not as strong as they are today but they were they were pretty strong and you used to practice against them um to try and improve your openings and other things and so i remember i think i probably got my first one i was around 11 or 12. and i remember thinking um this is amazing you know how how has someone programmed uh uh this this chess board to play chess uh and uh it was very formative book i bought which was called the chess computer handbook by david levy which came out in 1984 or something so i must have got it when i was about 11 12 and it explained fully how these chess programs were made i remember my first ai program being uh programming my amiga it couldn't it wasn't powerful enough to play chess i couldn't write a whole chess program but i wrote a program for it to play othello reversey it's sometimes called i think in the u.s and so a slightly simpler game than chess but i used all of the principles that chess programs had alpha beta search all of that and that was my first ai program i remember that very well was around 12 years old so that that that brought me into ai and then the second part was later on uh when i was around 1617 and i was writing games professionally designing games uh writing a game called theme park which um had ai as a core gameplay component as part of the simulation um and it sold you know millions of copies around the world and people loved the way that the ai even though it was relatively simple by today's ai standards um was was reacting to the way you as the player played it so it was called a sandbox game so it's one of the first types of games like that along with simcity and it meant that every game you played was unique is there something you could say just on a small tangent about really impressive ai from a game design human enjoyment perspective really impressive ai that you've seen in games and maybe what does it take to create ai system and how hard of a problem is that so a million questions just as a brief tangent well look i think um games uh games have been significant in my life for three reasons so first of all to to i was playing them and training myself on games when i was a kid then i went through a phase of designing games and writing ai4 games so all the games i i professionally wrote uh had ai as a core component and that was mostly in the in the 90s and the reason i was doing that in games industry was at the time the games industry i think was the cutting edge of technology so whether it was graphics with people like john carmack and quake and those kind of things or ai i think actually all the action was going on in games and and we've seen we're still reaping the benefits of that even with things like gpus which you know i find ironic was obviously invented for graphics computer graphics but then turns out to be amazingly useful for ai it just turns out everything's a matrix multiplication it appears you know in the whole world so um so i think games at the time had the most cutting edge ai and a lot of the the games uh uh we you know i was involved in writing so there was a game called black and white which was one game i was involved with in the early stages of which i still think is the most um impressive uh example of reinforcement learning in a computer game so in that game you know you trained a little pet animal uh and yeah and it sort of learned from how you were treating it so if you treated it badly then it became mean yeah and then it would be mean to to your villagers and your and your population the sort of uh the little tribe that you were running uh but if you were kind to it then it would be kind and people were fascinated by how that was and so was i to be honest with the way it kind of developed and um especially the mapping to good and evil yeah it made you made you realize made me realize that you can sort of in the way in the choices you make can define uh the where you end up and that means all of us are capable of the good uh evil it all matters in uh the different choices along the trajectory to those places that you make it's fascinating i mean games can do that philosophically to you and it's rare it seems rare yeah well games are i think a unique medium because um you as the player you're not just passively consuming the the entertainment right you're actually actively involved as an as a as an agent so i think that's what makes it in some ways can be more visceral than other other mediums like you know films and books so the second so that was you know designing ai and games and then the third use uh uh i've we've used of ai is in deep mind from the beginning which is using games as a testing ground for proving out ai algorithms and developing ai algorithms and that was a that was a sort of um a core component of our vision at the start of deepmind was that we would use games very heavily uh as our main testing ground certainly to begin with um because it's super efficient to use games and also you know it's very easy to have metrics to see how well your systems are improving and what direction your ideas are going in and whether you're making incremental improvements and because those games are often rooted in something that humans did for a long time beforehand there's already a strong set of rules like it's already a damn good benchmark yes it's really good for so many reasons because you've got you've got you've got clear measures of how good humans can be at these things and in some cases like go we've been playing it for thousands of years um and and uh often they have scores or at least win conditions so it's very easy for reward learning systems to get a reward it's very easy to specify what that reward is um and uh also at the end it's easy to you know to test uh externally you know how strong is your system by of course playing against you know the world's strongest players at those games so it's it's so good for so many reasons and it's also very efficient to run potentially millions of simulations in parallel on the cloud so um i think there's a huge reason why we were so successful back in you know starting out 2010 how come we were able to progress so quickly because we'd utilize games and um you know at the beginning of deep mind we also hired some amazing game engineers uh who i knew from my previous uh lives in the games industry and uh and that helped to bootstrap us very quickly and plus it's somehow super compelling almost at a philosophical level of man versus machine over over a chessboard or a go board and especially given that the entire history of ai is defined by people saying it's going to be impossible to make a machine that beats a human being in chess and then once that happened people were certain when i was coming up in ai that go is not a game that could be solved because of the combinatorial complexity it's just too it's it's it's you know no matter how much moore's law you have compute is just never going to be able to crack the game of go yeah and so that then there's something compelling about facing sort of taking on the impossibility of that task from the ai researcher perspective engineer perspective and then as a human being just observing this whole thing your beliefs about what you thought was impossible being broken apart it's it's uh humbling to realize we're not as smart as we thought it's humbling to realize that the things we think are impossible now perhaps will be done in the future there's something really powerful about a game ai system being a human being in a game that drives that message uh home for like millions billions of people especially in the case of go sure well look i think it's a i mean it has been a fascinating journey and and especially as i i think about it from i can understand it from both sides both as the ai you know creators of the ai um but also as a games player originally so you know it was a it was a really interesting it was i mean it was a fantastic um but also somewhat bittersweet moment the alphago match for me um uh seeing that and and and being obviously heavily heavily involved in that um but you know as you say chess has been uh the i mean kasparov i think rightly called it the drosophila of of intelligence right so it's sort of i i love that phrase and and i think he's right because chess has been um hand in hand with ai from the beginning of the the whole field right so i think every ai practitioner starting with turing and claude shannon and all those uh the sort of forefathers of of of of the field um tried their hand at writing a chess program uh i've got original audition of claude shannon's first chess program i think it was 1949 uh the the original sort of uh paper and um they all did that and turing famously wrote a chess program that but all the computers around there were obviously too slow to run it so he had to run he had to be the computer right so he literally i think spent two or three days running his own program by hand with pencil and paper and playing playing a friend of his uh with his chess program so of course deep blue was a huge moment uh beating off um but actually when that happened i remember that very very vividly of course because it was you know chess and computers and ai all the things i loved and i was at college at the time but i remember coming away from that being more impressed by kasparov's mind than i was by deep blue because here was kasparov with his human mind not only could he play chess more or less to the same level as this brute of a calculation machine um but of course kasparov can do everything else humans can do ride a bike talk many languages do politics all the rest of the amazing things that kasparov does and so with the same brain yeah and and yet deep blue uh brilliant as it was at chess it had been hand coded for chess and um actually had distilled the knowledge of chess grand masters uh into into a cool program but it couldn't do anything else like it couldn't even play a strictly simpler game like tic-tac-toe so um something to me was missing from um intelligence from that system that we would regard as intelligence and i think it was this idea of generality and and also learning yeah um so and that's what we tried to do out with alphago yeah we alphago and alpha zero mu zero and then got on all the things that uh we'll get into some parts of there's just a fascinating trajectory here but let's just stick on chess briefly uh on the human side of chess you've proposed that from a game design perspective the thing that makes chess compelling as a game uh is that there's a creative tension between a bishop and the knight can you explain this first of all it's really interesting to think about what makes the game compelling makes it stick across centuries yeah i was sort of thinking about this and actually a lot of even amazing chess players don't think about it necessarily from a games designer point of view so it's with my game design hat on that i was thinking about this why is chess so compelling and i think a critical uh reason is the the dynamicness of of of the different kind of chess positions you can have whether they're closed or open and other things comes from the bishop and the night so if you think about how different the the the capabilities of the bishop and knight are in terms of the way they move and then somehow chess has evolved to balance those two capabilities more or less equally so they're both roughly worth three points each so you think that dynamics was always there and then the rest of the rules are kind of trying to stabilize the game well maybe i mean it's sort of i don't know his chicken and egg situation probably both came together but the fact that it's got to this beautiful equilibrium where you can have the bishop and knight they're so different in power um but so equal in value across the set of the universe of all positions right somehow they've been balanced by humanity over hundreds of years um i think gives gives the game the creative tension uh that you can swap the bishop and knights uh for a bishop for a knight and you you they're more or less worth the same but now you aim for a different type of position if you have the knight you want a closed position if you have the bishop you want an open position so i think that creates a lot of the creative tension in chess so some kind of controlled creative tension from an ai perspective do you think ai systems convention design games that are optimally compelling to humans well that's an interesting question you know sometimes i get asked about ai and creativity and and this and the way i answered that is relevant to that question which is that i think they're different levels of creativity one could say so i think um if we define creativity as coming up with something original right that's that's useful for a purpose then you know i think the kind of lowest level of creativity is like an interpolation so an averaging of all the examples you see so maybe a very basic ai system could say you could have that so you show it millions of pictures of cats and then you say give me an average looking cat right generate me an average looking cat i would call that interpolation then there's extrapolation which something like alphago showed so alphago played you know millions of games of go against itself and then it came up with brilliant new ideas like move 37 in game two bringing a motif strategies and go that that no humans had ever thought of even though we've played it for thousands of years and professionally for hundreds of years so that that i call that extrapolation but then that's still there's still a level above that which is you know you could call out the box thinking or true innovation which is could you invent go right could you invent chess and not just come up with a brilliant chess move or brilliant go move but can you can you actually invent chess or something as good as chess or go and i think one day uh ai could but what's missing is how would you even specify that task to a a program right now and the way i would do it if i was best telling a human to do it or a games designer a human games designer to do it is i would say something like go i would say um come up with a game that only takes five minutes to learn which go does because it's got simple rules but many lifetimes to master right or impossible to master in one lifetime because so deep and so complex um and then it's aesthetically beautiful uh and also uh it can be completed in three or four hours of gameplay time which is you know useful for our us you know in in a human day and so um you might specify these side of high level concepts like that and then you know with that and maybe a few other things uh one could imagine that go satisfies uh those those constraints um but the problem is is that we we're not able to specify abstract notions like that high-level abstract notions like that yet to our ai systems um and i think there's still something missing there in terms of um high-level concepts or abstractions that they truly understand and that you know combinable and compositional um so for the moment i think ai is capable of doing interpolation extrapolation but not true invention so coming up with rule sets uh and optimizing with complicated objectives around those rule sets we can't currently do but you could take a specific rule set and then run a kind of self-play experiment to see how long just observe how an ai system from scratch learns how long is that journey of learning and maybe if it satisfies some of those other things you mentioned in terms of quickness to learn and so on and you could see a long journey to master for even an ai system then you could say that this is a promising game um but it would be nice to do almost like alpha codes or programming rules so generating rules that kind of uh that automate even that part of the generation of rules so i have thought about systems actually um that i think would be amazing in in for a games designer if you could have a system that um takes your game plays it tens of millions of times maybe overnight and then self balances the rules better so it tweaks the the rules and the maybe the equations and the and the and the parameters so that the game uh is more balanced the units in the game or some of the rules could be tweaked so it's a bit of like a giving a base set and then allowing a monte carlo tree search or something like that to sort of explore it right and i think that would be super super a powerful tool actually for for balancing auto balancing a game which usually takes thousands of hours from hundreds of games human games testers normally to to balance some one you know game like starcraft which is you know blizzard are amazing at balancing their games but it takes them years and years and years so one could imagine at some point when this uh this stuff becomes uh efficient enough to you know you might be able to do that like overnight do you think a game that is optimal designed by an ai system would look very much like uh planet earth maybe maybe it's only the sort of game i would love to make is is and i've tried you know my in my game's career the games design career you know my first big game was designing a theme park an amusement park then uh with games like republic i tried to you know have games where we designed whole cities and and allowed you to play in so and of course people like will wright have written games like sim earth uh trying to simulate the whole of earth pretty tricky but um i see earth i haven't actually played that one so what is it does it incorporative evolution or yeah it has evolution and it's sort of um it tries to it sort of treats it as an entire biosphere but from quite a high level so nice to be able to sort of zoom in zoom out zoom in exactly so obviously he couldn't do that was in the night i think he wrote that in the 90s so it couldn't you know it wasn't it wasn't able to do that but that that would be uh obviously the ultimate sandbox game of course on that topic do you think we're living in a simulation yes well so okay so i'm gonna jump around from the absurdly philosophical to the short term sure very very happy to so i think uh my answer to that question is a little bit complex because uh there is simulation theory which obviously nick bostrom i think famously first proposed um and uh i don't quite believe it in in that sense so um in the in the sense that uh are we in some sort of computer game or have our descendants somehow recreated uh uh earth in the you know 21st century and and some for some kind of experimental reason i think that um but i do think that we that that we might be that the best way to understand physics and the universe is from a computational perspective so understanding it as an information universe and actually information being the most fundamental unit of uh reality rather than matter or energy so a physicist would say you know matter or energy you know e equals m c squared these are the things that are are the fundamentals of the universe i'd actually say information um which of course itself can be can specify energy or matter right matter is actually just you know we're we're just out the way our bodies and all the molecules in our body arrange is information so i think information may be the most fundamental way to describe the universe and therefore you could say we're in some sort of simulation because of that um but i don't i do i'm not i'm not really a subscriber to the idea that um you know these are sort of throw away billions of simulations around i think this is actually very critical and possibly unique this simulation particular one yes so but and you just mean treating the universe as a computer that's processing and modifying information is is a good way to solve the problems of physics of chemistry of biology and perhaps of humanity and so on yes i think understanding physics in terms of information theory uh might be the best way to to really uh understand what's going on here from our understanding of a universal turing machine from our understanding of a computer do you think there's something outside of the capabilities of a computer that is present in our universe you have a disagreement with roger penrose the nature of consciousness he he thinks that consciousness is more than just a computation uh do you think all of it the whole shebang is can be can be a competition yeah i've had many fascinating debates with uh sir roger penrose and obviously he's he's famously and i read you know emperors of new mind and and um and his books uh his classical books uh and they they were pretty influential and you know in the 90s and um he believes that there's something more you know something quantum that is needed to explain consciousness in the brain um i think about what we're doing actually at deepmind and what my career is being we're almost like true rings champion so we are pushing turing machines or classical computation to the limits what are the limits of what classical computing can do now um and at the same time i've also studied neuroscience to see and that's why i did my phd in was to see also to look at you know is there anything quantum in the brain from a neuroscience or biological perspective and um and so far i think most neuroscientists and most mainstream biologists and neuroscientists would say there's no evidence of any quantum uh systems or effects in the brain as far as we can see it's it can be mostly explained by classical uh classical theories so and then so there's sort of the the search from the biology side and then at the same time there's the raising of the water uh at the bar from what classical turing machines can do uh uh and and you know including our new ai systems and uh as you alluded to earlier um you know i think ai especially in the last decade plus has been a continual story now of surprising uh events uh and surprising successes knocking over one theory after another of what was thought to be impossible you know from go to protein folding and so on and so i think um i would be very hesitant to bet against how far the uh universal turing machine and classical computation paradigm can go and and my betting would be that all of certainly what's going on in our brain uh can probably be mimicked or or approximated on a on a classical machine um not you know not requiring something metaphysical or quantum and we'll get there with some of the work with alpha fold which i think begins the journey of modeling this beautiful and complex world of biology so you think all the magic of the human mind comes from this just a few pounds of mush of a biological computational mush that's akin to some of the neural networks not directly but in spirit that deep mind has been working with well look i think it's um you say it's a few you know of course it's this is the i think the biggest miracle of the universe is that um it is just a few pounds of mush in our skulls and yet it's also our brains are the most complex objects in the in that we know of in the universe so there's something profoundly beautiful and amazing about our brains and i think that it's an incredibly uh incredible efficient machine and and uh uh and it's a is you know phenomenal basically and i think that building ai one of the reasons i want to build ai and i've always wanted to is i think by building an intelligent artifact like ai and then comparing it to the human mind um that will help us unlock the uniqueness and the true secrets of the mind that we've always wondered about since the dawn of history like consciousness dreaming uh creativity uh emotions what are all these things right we've we've wondered about them since since the dawn of humanity and i think one of the reasons and you know i love philosophy and philosophy of mind is we found it difficult is there haven't been the tools for us to really other than introspection to from very clever people in in history very clever philosophers to really investigate this scientifically but now suddenly we have a plethora of tools firstly we have all the neuroscience tools fmri machines single cell recording all of this stuff but we also have the ability computers and ai to build uh intelligent systems so i think that um uh you know i think it is amazing what the human mind does and um and and i'm kind of in awe of it really and uh and i think it's amazing that without human minds we're able to build things like computers and and actually even you know think and investigate about these questions i think that's also a testament to the human mind yeah the universe built the human mind that now is building computers that help us understand both the universe and our own human mind right that's exactly it i mean i think that's one you know one could say we we are maybe we're the mechanism by which the universe is going to try and understand itself yeah it's beautiful so let's let's go to the basic building blocks of biology that i think is another angle at which you can start to understand the human mind the human body which is quite fascinating which is from the basic building blocks start to simulate start to model how from those building blocks you can construct bigger and bigger more complex systems maybe one day the entirety of the human biology so here's another problem that thought to be impossible to solve which is protein folding and alpha fold or specific alpha fold 2 did just that it solved protein folding i think it's one of the biggest breakthroughs uh certainly in the history of structural biology but uh in general in in science um maybe from a high level what is it and how does it work and then we can ask some fascinating sure questions after sure um so maybe like to explain it uh to people not familiar with protein folding is you know i first of all explain proteins which is you know proteins are essential to all life every function in your body depends on proteins sometimes they're called the workhorses of biology and if you look into them and i've you know obviously as part of alpha fold i've been researching proteins and and structural biology for the last few years you know they're amazing little bio nano machines proteins they're incredible if you actually watch little videos of how they work animations of how they work and um proteins are specified by their genetic sequence called the amino acid sequence so you can think of those their genetic makeup and then in the body uh in in nature they when they when they fold up into a 3d structure so you can think of it as a string of beads and then they fold up into a ball now the key thing is you want to know what that 3d structure is because the structure the 3d structure of a protein is what helps to determine what does it do the function it does in your body and also if you're interested in drug drugs or disease you need to understand that 3d structure because if you want to target something with a drug compound or about to block that something the protein is doing uh you need to understand where it's going to bind on the surface of the protein so obviously in order to do that you need to understand the 3d structure so the structure is mapped to the function the structure is mapped to the function and the structure is obviously somehow specified by the by the amino acid sequence and that's the in essence the protein folding problem is can you just from the amino acid sequence the one-dimensional string of letters can you immediately computationally predict the 3d structure right and this has been a grand challenge in biology for over 50 years so i think it was first articulated by christian anfinsen a nobel prize winner in 1972 uh as part of his nobel prize winning lecture and he just speculated this should be possible to go from the amino acid sequence to the 3d structure we didn't say how so i you know it's been described to me as equivalent to fermat's last theorem but for biology right you should as somebody that uh very well might win the nobel prize in the future but outside of that you should do more of that kind of thing in the margins just put random things that will take like 200 years to solve set people off for 200 years it should be possible exactly and just don't give any interest exactly i think everyone's exactly should be i'll have to remember that for future so yeah so he set off you know with this one throwaway remark just like fermat you know he he set off this whole 50-year uh uh uh field really of computational biology and and they had you know they got stuck they hadn't really got very far with doing this and and um until now until alpha fold came along this is done experimentally right very painstakingly so the rule of thumb is and you have to like crystallize the protein which is really difficult some proteins can't be crystallized like membrane proteins and then you have to use very expensive electron microscopes or x-ray crystallography machines really painstaking work to get the 3d structure and visualize the 3d structure so the rule of thumb in in experimental biology is that it takes one phd student their entire phd to do one protein uh and with alpha fold two we were able to predict the 3d structure in a matter of seconds um and so we were you know over christmas we did the whole human proteome or every protein in the human body all 20 000 proteins so the human proteins like the equivalent of the human genome but on protein space and uh and sort of revolutionize really what uh a structural biologist can do because now um they don't have to worry about these painstaking experimentals you know should they put all of that effort in or not they can almost just look up the structure of their proteins like a google search and so there's a data set on which it's trained and how to map this amino acids because first of all it's incredible that a protein this little chemical computer is able to do that computation itself in some kind of distributed way and do it very quickly that's a weird thing and they evolved that way because you know in the beginning i mean that's a great invention just the protein itself yes i mean and then they there's i think probably a history of like uh they evolved to have many of these proteins and those proteins figure out how to be computers themselves in such a way that you can create structures that can interact in complexes with each other in order to form high level functions i mean it's a weird system that they figured it out well for sure i mean we you know maybe we should talk about the origins of life too but proteins themselves i think are magical and incredible uh uh uh as i said little little bio-nano machines and um and and actually levantal who is another scientist uh uh a contemporary of anfinsen uh he he coined this eleventh house what became known as levantal's paradox which is exactly what you're saying he calculated roughly a protein an average protein which is maybe 2 000 amino acids bases long is um is is can fold in maybe 10 to the power 300 different conformations so there's 10 to the power 300 different ways that protein could fold up and yet somehow in nature physics solves this solves this in a matter of milliseconds so proteins fold up in your body in you know sometimes in fractions of a second so physics is somehow solving that search problem and just to be clear in many of these cases maybe you correct me if i'm wrong there's often a unique way for that sequence to form itself yes so among that huge number of possibilities yes it figures out a way how to stability uh in some cases there might be a misfunction so on which leads to a lot of the disorders and stuff like that but yes most of the time it's a unique mapping and that unique mapping is not obvious no exactly that's just what the problem is exactly so there's a unique mapping usually in a healthy in if it's healthy and as you say in disease so for example alzheimer's one one one conjecture is that it's because of a misfolded protein a protein that folds in the wrong way amyloid beta protein so um and then because it falls in the wrong way it gets tangled up right in your in your neurons so um it's super important to understand both healthy functioning and also disease is to understand uh you know what what these things are doing and how they're structuring of course the next step is sometimes proteins change shape when they interact with something so um they're not just static necessarily in in biology maybe you can give some interesting sort of beautiful things to you about these early days of alpha fold of of solving this problem because unlike games this is real physical systems that are less amenable to self-play type of mechanisms the the size of the data set is smaller that you might otherwise like so you have to be very clever about certain things is there something you could speak to um what was very hard to solve and what are some beautiful aspects about the the solution yeah i would say alpha fold is the most complex and also probably most meaningful system we've built so far so it's been an amazing time actually in the last you know two three years to see that come through because um as we talked about earlier you know games is what we started on uh building things like alphago and alpha zero but really the ultimate goal was to um not just to crack games it was just to to to build use them to bootstrap general learning systems we could then apply to real world challenges specifically my passion is scientific challenges like protein folding and then alpha fold of course is our first big proof point of that and so um you know in terms of the data uh and the amount of innovations that had to go into it we you know it was like more than 30 different component algorithms needed to be put together to crack the protein folding um i think some of the big innovations were that um kind of building in some hard coded constraints around physics and evolutionary biology um to constrain sort of things like the bond angles uh uh in the in the in the protein and things like that um a lot but not to impact the learning system so still allowing uh the system to be able to learn the physics uh itself um from the examples that we had and the examples as you say there are only about 150 000 proteins even after 40 years of experimental biology only around 150 000 proteins have been the structures have been found out about so that was our training set which is um much less than normally we would like to use but using various tricks things like self distillation so actually using alpha folds predictions um some of the best predictions that it thought was highly confident in we put them back into the training set right to make the training set bigger that was critical to to alpha fold working so there was actually a huge number of different um uh innovations like that that were required to to ultimately crack the problem after fold one what it produced was a distagram so a kind of a matrix of the pairwise distances between all of the molecules in the in the in the protein and then there had to be a separate optimization process to uh create the 3d structure and what we did for alpha volt2 is make it truly end to end so we went straight from the amino acid sequence of of of bases to the 3d structure directly without going through this intermediate step and in machine learning what we've always found is that the more end to end you can make it the better the system and it's probably because um we you know the in the end the system is better at learning what the constraints are than than we are as the human designers of specifying it so anytime you can let it flow end to end and actually just generate what it is you're really looking for in this case the 3d structure you're better off than having this intermediate step which you then have to hand craft the next step for so so it's better to let the gradients and the learning flow all the way through the system um from the end point the end output you want to the inputs so that's a good way to start a new problem handcraft a bunch of stuff add a bunch of manual constraints with a small intent learning piece or a small learning piece and grow that learning piece until it consumes the whole thing that's right and so you can also see you know this is a bit of a method we've developed over doing many sort of successful outfits we call them alpha x projects right is and the easiest way to see that is the evolution of alphago to alpha zero so alphago was um a learning system but it was specifically trained to only play go right so uh and what we wanted to do with first version of go is just get to world champion performance no matter how we did it right and then and then of course alphago zero we we we removed the need to use human games as a starting point right so it could just play against itself from random starting point from the beginning so that removed the the need for human knowledge uh about go and then finally alpha zero then generalized it so that any things we had in there the system including things like symmetry of the go board uh were removed so the alpha zero could play from scratch any two player game and then mu0 which is the final latest version of that set of things was then extending it so that you didn't even have to give it the rules of the game it would learn that for itself so it could also deal with computer games as well as board games so that line of alpha golf goes zero alpha zero mu zero that's the full trajectory of what you can take from uh imitation learning to full self supervised learning yeah exactly and learning learning uh the entire structure of the environment you put in from scratch right and and and and bootstrapping it uh through self-play uh yourself but the thing is it would have been impossible i think or very hard for us to build alpha zero or mu0 first out of the box even psychologically because you have to believe in yourself for a very long time you're constantly dealing with doubt because a lot of people say that it's impossible exactly so it was hard enough just to do go as you were saying everyone thought that was impossible or at least a decade away um from when we when we did it back in 2015 24 you know 2016 and um and so yes it would have been psychologically probably very difficult as well as the fact that of course we learnt a lot by building alphago first right so it's i think this is why i call ai in engineering science it's one of the most fascinating science disciplines but it's also an engineering science in the sense that unlike natural sciences um the phenomenon you're studying it doesn't exist out in nature you have to build it first so you have to build the artifact first and then you can study how how and pull it apart and how it works this is tough to uh ask you this question because you probably will say it's everything but let's let's try let's try to think to this because you're in a very interesting position where deepmind is the place of some of the most uh brilliant ideas in the history of ai but it's also a place of brilliant engineering so how much of solving intelligence this big goal for deepmind how much of it is science how much is engineering so how much is the algorithms how much is the data how much is the hardware compute infrastructure how much is it the software computer infrastructure yeah um what else is there how much is the human infrastructure and like just the humans interact in certain kinds of ways in all the space of all those ideas how much does maybe like philosophy how much what's the key if um uh if if you were to sort of look back like if we go forward 200 years look back what was the key thing that solved intelligence is that ideas i think it's a combination first of all of course it's a combination of all those things but the the ratios of them changed over over time so yeah so um even in the last 12 years so we started deep mine in 2010 which is hard to imagine now because 2010 it's only 12 short years ago but nobody was talking about ai uh you know if you remember back to your mit days you know no one was talking about it i did a postdoc at mit back around then and it was sort of thought of as a well look we know ai doesn't work we tried this hard in the 90s at places like mit mostly losing using logic systems and old-fashioned sort of good old-fashioned ai we would call it now um people like minsky and and and patrick winston and you know all these characters right and used to debate a few of them and they used to think i was mad thinking about that some new advance could be done with learning systems and um i was actually pleased to hear that because at least you know you're on a unique track at that point right even if every all of your you know professors are telling you you're mad that's true and of course in industry uh you can we couldn't get you know as difficult to get two cents together uh and which is hard to imagine now as well given it's the biggest sort of buzzword in in vcs and and fundraising's easy and all these kind of things today so back in 2010 it was very difficult and what we the reason we started then and shane and i used to discuss um uh uh what were the sort of founding tenets of deep mind and it was very various things one was um algorithmic advances so deep learning you know jeff hinton and cohen just had just sort of invented that in academia but no one in industry knew about it uh we love reinforcement learning we thought that could be scaled up but also understanding about the human brain had advanced um quite a lot uh in the decade prior with fmri machines and other things so we could get some good hints about architectures and algorithms and and sort of um representations maybe that the brain uses so as at a systems level not at a implementation level um and then the other big things were compute and gpus right so we could see a compute was going to be really useful and it got to a place where it became commoditized mostly through the games industry and and that could be taken advantage of and then the final thing was also mathematical and theoretical definitions of intelligence so things like ai xi aix which uh shane worked on with his supervisor marcus hutter which is a sort of theoretical uh proof really of universal intelligence um which is actually a reinforcement learning system um in the limit i mean it assumes infinite compute and infinite memory in the way you know like a turing machine proof but i was also waiting to see something like that too to you know like turing machines uh and and computation theory that people like turing and shannon came up with underpins modern computer science um uh you know i was waiting for a theory like that to sort of underpin agi research so when i you know met shane and saw he was working on something like that you know that to me was a sort of final piece of the jigsaw so in the early days i would say that ideas were the most important uh you know and for us it was deep reinforcement learning scaling up deep learning um of course we've seen transformers so huge leaps i would say you know three or four from for if you think from 2010 until now uh huge evolutions things like alphago um and um and and maybe there's a few more still needed but as we get closer to ai agi um i think engineering becomes more and more important and data because scale and of course the the recent you know results of gpt3 and all the big language models and large models including our ones uh has shown that scale is a is and large models are clearly going to be unnecessary but perhaps not sufficient part of an agi solution and throughout that like you said and i'd like to give you a big thank you you're one of the pioneers in this is sticking by ideas like reinforcement learning that this can actually work given actually limited success in the past and also which we still don't know but proudly having the best researchers in the world and talking about solving intelligence so talking about whatever you call it agi or something like this that speaking of mit that's that's just something not you wouldn't bring up no uh not not maybe you did in uh like 40 50 years ago but that was um ai was a place where you do tinkering very small scale not very ambitious projects and maybe the biggest ambitious projects were in the space of robotics and doing like the darpa challenge sure but the task of solving intelligence and believing you can that's really really powerful so in order for engineering to do its work to have great engineers build great systems you have to have that belief that threats throughout the whole thing that you can actually solve some of these impossible challenges yeah that's right and and back in 2010 you know our mission statement um and still is today you know it was used to be uh solving step one solve intelligence step two use it to solve everything else yes so if you can imagine pitching that to a vc in 2010 you know the kind of looks we we got we managed to you know find a few uh kooky people to back us but it was uh it was tricky and and i and i got to the point where we we wouldn't mention it to any of our professors because they would just eye roll and think we you know committed career suicide and and uh and and you know so it was there's a lot of things that we had to do but we always believed it and one reason you know by the way one reason we i believe i've always believed in reinforcement learning is that that if you look at neuroscience that is the way that the you know primate brain learns one of the main mechanisms is the dopamine system implement some form of td learning a very famous result in the late 90s uh where they saw this in monkeys and uh and as a you know proper game prediction error so we you know again in the limit this is this is what i think you can use neuroscience for is is you know any at mathematics you when you're when you're doing something as ambitious as trying to solve intelligence and you're you're you know it's blue sky research no one knows how to do it you you you need to use any evidence or any source of information you can to help guide you in the right direction or give you confidence you're going in the right direction so so that that was one reason we pushed so hard on that and that's and just going back to your early question about organization the other big thing that i think we innovated with at deepmind to encourage invention and and uh and innovation was the multi-disciplinary organization we built and we still have today so deepmind originally was a confluence of the of the most cutting-edge knowledge in neuroscience with machine learning engineering and mathematics right and and gaming and then since then we built that out even further so we have philosophers here and and uh by you know ethicists but also other types of scientists physicists and so on um and that's what brings together i tried to build a sort of um new type of bell labs but in this golden era right uh and and a new expression of that um to try and uh foster this incredible sort of innovation machine so talking about the humans in the machine the mind itself is a learning machine with a lots of amazing human minds in it coming together to try and build these uh learning systems if we return to the big ambitious dream of alpha fold that may be the early steps on a very long journey in um in biology do you think the same kind of approach can use to predict the structure and function of more complex biological systems so multi-protein interaction and then i mean you can go out from there just simulating bigger and bigger systems that eventually simulate something like the human brain or the human body just the big mush the mess of the beautiful resilient mesobiology do do you see that as a long-term vision i do and i think um you know if you think about what are the things top things i wanted to apply ai ai2 once we had powerful enough systems biology and curing diseases and understanding biology uh was right up there you know top of my list that's one of the reasons i personally pushed that myself and with alpha fold but i think alpha fold uh amazing as it is is just the beginning um and and and i hope it's evidence of uh what could be done with computational methods so um you know alpha fold solve this this huge problem of the structure of proteins but biology is dynamic so really what i imagine from here we're working on all these things now is protein protein interaction uh protein ligand binding so reacting with molecules um then you want to get build up to pathways and then eventually a virtual cell that's my dream uh maybe in the next 10 years and i've been talking actually to a lot of biologists friends of mine paul nurse who runs the qrik institute amazing biologist nobel prize winning biologist we've been discussing for 20 years now virtual cells could you build a virtual simulation of a cell and if you could that would be incredible for biology and disease discovery because you could do loads of experiments on the virtual cell and then only at the last stage validate it in the wet lab so you could you know in terms of the search space of discovering new drugs you know it takes 10 years roughly to go from uh uh to to go from uh you know identifying a target to uh having a drug candidate um maybe that could be shortened to you know by an order of magnitude with if you could do most of that that that work in silico so in order to get to a virtual cell we have to build up uh uh understanding of different parts of biology and the interactions and and um so you know every every few years we talk about this with i talked about this with paul and then finally last year after alpha fault i said now is the time we can finally go for it and and alpha falls the first proof point that this might be possible uh and he's very excited when we have some collaborations with his with his lab they're just across the road actually from us as you know wonderful being here in king's cross with the quick institute across the road and um and i think the next steps you know i think there's going to be some amazing advances in biology built on top of things like alpha fold uh we're already seeing that with the community doing that after we've open sourced it and released it um and uh you know i also i often say that i think uh if you think of mathematics is the perfect description language for physics i think ai might be end up being the perfect description language for biology because biology is so messy it's so emergent so dynamic and complex um i think i find it very hard to believe we'll ever get to something as elegant as newton's laws of motions to describe a cell right it's just too complicated um so i think ai is the right tool for this you have to uh you have to start at the basic building blocks and use ai to run the simulation for all those building blocks so have a very strong way to do prediction of what given these building blocks what kind of biology how the the function and the evolution of that biological system it's almost like a cellular automata you have to run you can't analyze it from a high level you have to take the basic ingredients figure out the rules yeah and let it run but in this case the rules are very difficult to figure out yes yes learn them that's exactly it so it's the biology is too complicated to figure out the rules it's it's it's too emergent too dynamic say compared to a physics system like the motion of a planet yeah right and and so you have to learn the rules and that's exactly the type of systems that we're building so you you mentioned you've open sourced alpha fold and even the data involved to me personally also really happy and a big thank you for open sourcing mijoko uh the physics simulation engine that's that's often used for robotics research and so on so i think that's a pretty gangster move uh so what what's the what's i mean this uh very few companies or people would do that kind of thing what's the philosophy behind that you know it's a case-by-case basis and in both those cases we felt that was the maximum benefit to humanity to do that and and the scientific community in one case the robotics uh physics community with mojoco so purchased it we purchased to obs we purchased it for the express principle to open source it so um so you know i hope people appreciate that it's great to hear that you do and then the second thing was and mostly we did it because the person building it is uh uh would not it was not able to cope with supporting it anymore because it was it got too big for him his amazing professor uh who who built it in the first place so we helped him out with that and then with alpha folds even bigger i would say and i think in that case we decided that there were so many downstream applications of alpha fold um that we couldn't possibly even imagine what they all were so the best way to accelerate uh drug discovery and also fundamental research would be to to um give all that data away and and and the and the and the system itself um you know it's been so gratifying to see what people have done that within just one year which is a short amount of time in science and uh it's been used by over 500 000 researchers have used it we think that's almost every biologist in the world i think there's roughly 500 000 biologists in the world professional biologists have used it to to look at their proteins of interest we've seen amazing fundamental research done so a couple of weeks ago front cover there was a whole special issue of science including the front cover which had the nuclear pore complex on it which is one of the biggest proteins in the body the nuclear poor complex is a protein that governs all the nutrients going in and out of your cell nucleus so they're like little hole gateways that open and close to let things go in and out of your cell nucleus so they're really important but they're huge because they're massive doughnut rings shaped things and they've been looking to try and figure out that structure for decades and they have lots of you know experimental data but it's too low resolution there's bits missing and they were able to like a giant lego jigsaw puzzle use alpha fold predictions plus experimental data and combined those two independent sources of information uh actually four different groups around the world were able to put it together the sec more or less simultaneously using alpha fault predictions so that's been amazing to see and pretty much every pharma company every drug company executive i've spoken to has said that their teams are using alpha fold to accelerate whatever drugs uh uh they're trying to discover so i think the knock-on effect has been enormous in terms of uh the impact that uh alpha-fold has made and it's probably bringing in it's creating biologists it's bringing more people into the field um both on the excitement and both on the technical skills involved and um it's almost like uh a gateway drug to biology yes it is you get more computational people involved too hopefully and and i think for us you know the next stage as i said you know in future we have to have other considerations too we're building on top of alpha fold and these other ideas i discussed with you about protein protein interactions and and genomics and other things and not everything will be open source some of it will will do commercially because that will be the best way to actually get the most resources and impact behind it in other ways some other projects will do non-profit style um and also we have to consider for future things as well safety and ethics as well like but you know synthetic biology there are you know there is dual use and we have to think about that as well with alpha fold we you know we consulted with 30 different bioethicists and and other people expert in this field to make sure it was safe before um we released it so there'll be other considerations in future but for right now you know i think alpha fold is a kind of a gift from us to to to the scientific community so i'm pretty sure that something like alpha fold uh would be part of nobel prizes in the future but us humans of course are horrible with credit assignment so we'll of course give it to the humans do you think there will be a day when ai system can't be denied that it earned that nobel prize do you think we'll see that in 21st century it depends what type of ais we end up building right whether they're um you know goal seeking agents who specifies the goals uh who comes up with the hypotheses who you know who determines which problems to tackle right so i think it's about an announcement yeah so it's announcing the results exactly as part of it um so i think right now of course it's it's it's it's amazing human ingenuity that's behind these systems and then the system in my opinion is just a tool you know it'd be a bit like saying with galileo and his telescope you know the ingenuity the the the credit should go to the telescope i mean it's clearly galileo building the tool which he then uses so i still see that in the same way today even though these tools learn for themselves um they're i think i think of things like alpha fold and that the things we're building as the ultimate tools for science and for acquiring new knowledge to help us as scientists acquire new knowledge i think one day there will come a point where an ai system may solve or come up with something like general relativity of its own bat not just by averaging everything on the internet or averaging everything on pubmed although that would be interesting to see what that would come up with um so that to me is a bit like our earlier debate about creativity you know inventing go rather than just coming up with a good go move and um so i think uh solving i think to to you know if we wanted to give it the credit of like a nobel type of thing then it would need to invent go uh and sort of invent that new conjecture out of the blue um rather than being specified by the the human scientists or the human creators so i think right now that's it's definitely just a tool although it is interesting how far you get by averaging everything on the internet like you said because you know a lot of people do see science as you're always standing on the shoulders of giants and the question is how much are you really reaching up above the shoulders of giants maybe it's just assimilating different kinds of results of the past with ultimately this new perspective that gives you this breakthrough idea but that idea may not be novel in the way that we can't be already discovered on the internet maybe the nobel prizes of the next 100 years are already all there on the internet to be discovered they could be they could be i mean i think um this is one of the big mysteries i think is that uh uh i i first of all i believe a lot of the big new breakthroughs that are going to come in the next few decades and even in the last decade are going to come at the intersection between different subject areas where um there'll be some new connection that's found between what seemingly with disparate areas and and one can even think of deep mind as i said earlier as a sort of interdisciplinary between neuroscience ideas and ai engineering ideas uh originally and so um so i think there's that and then one of the things we can't imagine today is and one of the reasons i think people we were so surprised by how well large models worked is that actually it's very hard for our human minds our limited human minds to understand what it would be like to read the whole internet right i think we can do a thought experiment and i used to do this of like well what if i read the whole of wikipedia what would i know and i think our minds can just about comprehend maybe what that would be like but the whole internet is beyond comprehension so i think we just don't understand what it would be like to be able to hold all of that in mind potentially right and then active at once and then maybe what are the connections that are available there so i think no doubt there are huge things to be discovered just like that but i do think there is this other type of creativity of true spark of new knowledge new idea never thought before about can't be average from things that are known um that really of course everything come you know nobody creates in a vacuum so there must be clues somewhere but just a unique way of putting those things together i think some of the greatest scientists in history have displayed that i would say although it's very hard to know going back to their time what was exactly known uh when they came up with those things although you're making me really think because just the thought experiment of deeply knowing a hundred wikipedia pages i don't think i can um i've been really impressed by wikipedia for for technical topics yeah so if you know a hundred pages or a thousand pages i don't think who can visually truly comprehend what's what kind of intelligence that is that's a pretty powerful intelligence if you know how to use that and integrate that information correctly yes i think you can go really far you can probably construct thought experiments based on that like simulate different ideas so if this is true let me run this thought experiment then maybe this is true it's not really invention it's like just taking literally the knowledge and using it to construct a very basic simulation of the world i mean some argue it's romantic in part but einstein would do the same kind of things with a thought experiment yeah one could imagine doing that systematically across millions of wikipedia pages plus pubmed all these things i think there are many many things to be discovered like that they're hugely useful you know you could imagine and i want us to do some of those things in material science like room temperature superconductors or something on my list one day i'd like to like you know have an ai system to help build better optimized batteries all of these sort of mechanical things mr i think a systematic sort of search could be uh guided by a model could be um could be extremely powerful so speaking of which you have a paper on nuclear fusion uh magnetic control of tokamak plasmas to deep reinforcement learning so you uh you're seeking to solve nuclear fusion with deep rl so it's doing control of high temperature plasmas can you explain this work and uh can ai eventually solve nuclear fusion it's been very fun last year or two and very productive because we've been taking off a lot of my dream projects if you like of things that i've collected over the years of areas of science that i would like to i think could be very transformative if we helped accelerate and uh really interesting problems scientific challenges in of themselves this is energy so energy yes exactly so energy and climate so we talked about disease and biology as being one of the biggest places i think ai can help with i think energy and climate uh is another one so maybe they would be my top two um and fusion is one one area i think ai can help with now fusion has many challenges mostly physics material science and engineering challenges as well to build these massive fusion reactors and contain the plasma and what we try to do whenever we go into a new field to apply our systems is we look for um we talk to domain experts we try and find the best people in the world to collaborate with um in this case in fusion we we collaborated with epfl in switzerland the swiss technical institute who are amazing they have a test reactor that they were willing to let us use which you know i double checked with the team we were going to use carefully and safely i was impressed they managed to persuade them to let us use it and um and it's a it's an amazing test reactor they have there and they try all sorts of pretty crazy experiments on it and um the the the what we tend to look at is if we go into a new domain like fusion what are all the bottleneck problems uh like thinking from first principles you know what are all the bottleneck problems that are still stopping fusion working today and then we look at we you know we get a fusion expert to tell us and then we look at those bottlenecks and we look at the ones which ones are amenable to our ai methods today yes right and and and then and would be interesting from a research perspective from our point of view from an ai point of view and that would address one of their bottlenecks and in this case plasma control was was perfect so you know the plasma it's a million degrees celsius something like that it's hotter than the sun and there's obviously no material that can contain it so they have to be containing these magnetic very powerful superconducting magnetic fields but the problem is plasma is pretty unstable as you imagine you're kind of holding a mini sun mini star in a reactor so you know you you kind of want to predict ahead of time what the plasma's going to do so you can move the magnetic field within a few milliseconds you know to to basically contain what it's going to do next so it seems like a perfect problem if you think of it for like a reinforcement learning prediction problem so uh you know your controller you're gonna move the magnetic field and until we came along you know they were they were doing it with with traditional operational uh research type of uh controllers uh which are kind of handcrafted and the problem is of course they can't react in the moment to something the plasma's doing that they have to be hard-coded and again knowing that that's normally our go-to solution is we would like to learn that instead and they also had a simulator of these plasma so there were lots of criteria that matched what we we like to to to use so can ai eventually solve nuclear fusion well so we with this problem and we published it in a nature paper last year uh we held the fusion that we held the plasma in specific shapes so actually it's almost like carving the plasma into different shapes and control and hold it there for the record amount of time so um so that's one of the problems of of fusion sort of um solved so i have a controller that's able to no matter the shape uh contain it continue yeah contain it and hold it in structure and there's different shapes that are better for for the energy productions called droplets and and and so on so um so that was huge and now we're looking we're talking to lots of fusion startups to see what's the next problem we can tackle uh in the fusion area so another fascinating place in a paper title pushing the frontiers of density functionals by solving the fractional electron problem so you're taking on modeling and simulating the quantum mechanical behavior of electrons yes um can you explain this work and can ai model and simulate arbitrary quantum mechanical systems in the future yeah so this is another problem i've had my eye on for you know a decade or more which is um uh sort of simulating the properties of electrons if you can do that you can basically describe how elements and materials and substances work so it's kind of like fundamental if you want to advance material science um and uh you know we have schrodinger's equation and then we have approximations to that density functional theory these things are you know are famous and um people try and write approximations to to these uh uh to these functionals and and kind of come up with descriptions of the electron clouds where they're gonna go how they're gonna interact when you put two elements together uh and what we try to do is learn a simulation uh uh learner functional that will describe more chemistry types of chemistry so um until now you know you can run expensive simulations but then you can only simulate very small uh molecules very simple molecules we would like to simulate large materials um and so uh today there's no way of doing that and we're building up towards uh building functionals that approximate schrodinger's equation and then allow you to describe uh what the electrons are doing and all materials sort of science and material properties are governed by the electrons and and how they interact so have a good summarization of the simulation through the functional um but one that is still close to what the actual simulation would come out with so what um how difficult is that to ask what's involved in that task is it running those those complicated simulations yeah and learning the task of mapping from the initial conditions and the parameters of the simulation learning what the functional would be yeah so it's pretty tricky and we've done it with um you know the nice thing is we there are we can run a lot of the simulations that the molecular dynamics simulations on our compute clusters and so that generates a lot of data so in this case the data is generated so we like those sort of systems and that's why we use games simulator generated data and we can kind of create as much of it as we want really um and just let's leave some you know if any computers are free in the cloud we just run we run some of these calculations right compute cluster calculation that's all the the free compute times used up on quantum mechanics quantum mechanics exactly simulations and protein simulations and other things and so um and so you know when you're not searching on youtube for video cat videos we're using those computers usefully and quantum chemistry that's the idea and and putting them for good use and then yeah and then all of that computational data that's generated we can then try and learn the functionals from that which of course are way more efficient once we learn the functional than um running those simulations would be do you think one day ai may allow us to do something like basically crack open physics so do something like travel faster than the speed of light my ultimate aim has always been with ai is um the reason i am personally working on ai for my whole life it was to build a tool to help us understand stand the universe so i wanted to and that means physics really and the nature of reality so um uh i don't think we have systems that are capable of doing that yet but when we get towards agi i think um that's one of the first things i think we should apply agi to i would like to test the limits of physics and our knowledge of physics there's so many things we don't know there's one thing i find fascinating about science and you know as a huge proponent of the scientific method as being one of the greatest ideas humanity's ever had and allowed us to progress with our knowledge but i think as a true scientist i think what you find is the more you find out uh you the more you realize we don't know and and i always think that it's surprising that more people don't aren't troubled you know every night i think about all these things we interact with all the time that we have no idea how they work time consciousness gravity life we can't i mean these are all the fundamental things of nature i think the way we don't really know what they are to live life we uh pin certain assumptions on them and kind of treat our assumptions as if they're a fact yeah that allows us to sort of box them off somehow yeah box them off but the reality is when you think of time you should remind yourself you should put it off the sh take it off the shelf and realize like no we have a bunch of assumptions there's still a lot of there's even now a lot of debate there's a lot of uncertainty about exactly what is time uh is there an error of time you know there's there's a lot of fundamental questions you can't just make assumptions about and maybe ai allows you to um not put anything on the shelf yeah not make any uh hard assumptions and really open it up and see what exactly i think we should be truly open-minded about that and uh exactly that not be dogmatic to a particular theory um it'll also allow us to build better tools experimental tools eventually that can then test certain theories that may not be testable today about as things about like what we spoke about at the beginning about the computational nature of the universe how one might if that was true how one might go about testing that right and and how much uh you know there are people who've conjectured people like uh scott aronson and others about uh you know how much information can a specific planck unit of space and time contain right so one might be able to think about testing those ideas if you had um ai helping you build some new exquisite uh uh experimental tools this is what i imagine you know many decades from now we'll be able to do and what kind of questions can be answered through running a simulation of of them so there's a bunch of physics simulations you can imagine that could be run in an uh so some kind of efficient way much like you're doing in the quantum simulation work and perhaps even the origin of life so figuring out how going even back before the work of alpha fault begins of how this whole whole thing um emerges from a rock yes from a static thing would what do you do you think ai will allow us to is that something you have your eye on it's trying to understand the origin of life first of all yourself what do you think um how the heck did life originate on earth yeah well maybe we i'll come to that in a second but i think the ultimate use of ai is to kind of use it to accelerate science to the maximum so i um think of it a little bit like the tree of all knowledge if you imagine that's all the knowledge there is in the universe to attain and we sort of barely scratched the surface of that so far in even though you know we've we've done pretty well since the enlightenment right as humanity and i think ai will turbo charge all of that like we've seen with alpha fold and i want to explore as much of that tree of knowledge as it's possible to do and um and i think that involves ai helping us with with with understanding or finding patterns um but also potentially designing and building new tools experimental tools so i think that's all uh and also running simulations and learning simulations all of that we're already we're sort of doing it at a at a at a you know baby steps level here but i can imagine that in in in the decades to come as uh you know what's the full flourishing of of that line of thinking it's going to be truly incredible i would say if i visualize this tree of knowledge something tells me that that knowledge for tree of knowledge for humans is much smaller in the set of all possible trees of knowledge is actually quite small giving our cognitive limitations limited cognitive capabilities that even with with the tools we build we still won't be able to understand a lot of things and that's perhaps what non-human systems might be able to reach farther not just as tools but in themselves understanding something that they can bring back yeah it could well be so i mean there's so many things that that are sort of encapsulated in what you just said there i think first of all um there's there's two different things there's like what do we understand today yeah what could the human mind understand and what is the totality of what is there to be understood yeah right and so there's three consensus you know you can think of them as three larger and larger trees or exploring more branches of that tree and i i think with ai we're going to explore that whole lot now the question is is uh you know if you think about what is the totality of what could be understood um there may be some fundamental physics reasons why certain things can't be understood like what's outside the simulation or outside the universe maybe it's not understandable from within the universe so that's there may be some hard constraints like that you know it could be smaller constraints like um we think of space time as fundamental us our human brains are really used to this idea of a three-dimensional world with time right maybe but our tools could go beyond that they wouldn't have that limitation necessary they could think in 11 dimensions 12 dimensions whatever is needed but um we could still maybe understand that in several different ways the example i always give is um when i you know play gary kasparov at speed chess or we've talked about chess and these kind of things um you know he if you if you if you're reasonably good at chess you can um you can't come up with the move gary comes up with in his move but he can explain it to you and you can understand and you can understand post hoc the reasoning yeah so so i think there's a there's an even further level of like well maybe you couldn't have invented that thing but but using like going back to using language again perhaps you can understand and appreciate that same way like you can appreciate you know vivaldi or mozart or something without you can appreciate the beauty of that without um being able to to construct it yourself right invent the music yourself so i think we see this in all forms of life so it'll be that times you know a million but it would you can imagine also one sign of intelligence is the ability to explain things clearly and simply right you know people like richard feynman another one of my all-time heroes used to say that right if you can't you know if you can explain it something simply then you that's a that's the best sign a complex topic simply then that's one of the best signs of you understanding it yeah so i can see myself talking trash in the ai system in that way yes uh it gets frustrated how dumb i am and trying to explain something to me i was like well that means you're not intelligent because if you were intelligent you'd be able to explain it simply yeah of course you know there's also the other option of course we could enhance ourselves and and without devices we we are already sort of symbiotic with our compute devices right with our phones and other things and you know this stuff like neural link and etc that could be could could advance that further um so i think there's lots of lots of really amazing possibilities uh that i could foresee from here well let me ask you some wild questions so out there looking for friends do you think there's a lot of alien civilizations out there so i guess this also goes back to your origin of life question too because i think that that's key um my personal opinion looking at all this and and you know it's one of my hobbies physics i guess so so i i you know it's something i think about a lot and talk to a lot of experts on and and and read a lot of books on and i think my feeling currently is that that we are alone i think that's the most likely scenario given what what evidence we have so um and the reasoning is i think that you know we've tried since uh things like seti program and i guess since the dawning of the the space age uh we've you know had telescopes open radio telescopes and other things and if you think about um and try to detect signals now if you think about the evolution of humans on earth we could have easily been um a million years ahead of our time now or million years behind quite easily with just some slightly different quirk thing happening hundreds of thousands years ago uh you know things could have been slightly different if the bto had hit the dinosaurs a million years earlier maybe things would have evolved uh we'd be a million years ahead of where we are now so what that means is if you imagine where humanity will be in a few hundred years let alone a million years especially if we hopefully um you know solve things like climate change and other things and we continue to flourish and we build things like ai and we do space traveling and all of the stuff that that humans have dreamed of for forever right and sci-fi has talked about forever um we will be spreading across the stars right and void neumann famously calculated you know it would only take about a million years if you send out von neumann probes to the nearest you know the nearest uh uh other solar systems and and then they built all they did was build two more versions of themselves and set those two out to the next nearest systems uh you you know within a million years i think you would have one of these probes in every system in the galaxy so it's not actually in cosmo cosmological time that's actually a very short amount of time so and and you know we've people like dyson have thought about constructing dyson spheres around stars to collect all the energy coming out of the star you know that there would be constructions like that would be visible across base um probably even across a galaxy so and then you know if you think about all of our radio television uh emissions that have gone out since since the you know 30s and 40s um imagine a million years of that and now hundreds of civilizations doing that when we opened our ears at the point we got technologically sophisticated enough in the space age we should have heard a cacophony of voices we should have joined that cacophony of voices and what we did we opened our ears and we heard nothing and many people who argue that there are aliens would say well we haven't really done exhaustive search yet and maybe we're looking in the wrong bands and and we've got the wrong devices and we wouldn't notice what an alien form was like to be so different to what we're used to but you know i'm not i don't really buy that that it shouldn't be as difficult as that like we i think we've searched enough there should be if it were everywhere if it was it should be everywhere we should see dyson's fears being put up sun's blinking in and out you know there should be a lot of evidence for those things and then there are other people argue well the sort of safari view of like well we're a primitive species still because we're not space faring yet and and and we're you know there's some kind of globe like universal rule not to interfere star trek rule but like look look we can't even coordinate humans to deal with climate change and we're one species what is the chance that of all of these different human civilization you know alien civilizations they would have the same priorities and and and and agree across you know these kind of matters and even if that was true and we were in some sort of safari for our own good to me that's not much different from the simulation hypothesis because what does it mean the simulation hypothesis i think in its most fundamental level it means what we're seeing is not quite reality right it's something there's something more deeper underlying it maybe computational now if we were in a if we were in a sort of safari park and everything we were seeing was a hologram and it was projected by the aliens or whatever that to me is not much different than thinking we're inside of another universe because we still can't see true reality right i mean there's there's other explanations it could be that the way they're communicating is just fundamentally different that we're too dumb to understand the much better methods of communication they have it could be i mean i mean it's silly to say but our own thoughts could be the methods by which they're communicating like the place from which our ideas writers talk about this like the muse yeah it sounds like very kind of uh wild but it could be thoughts it could be some interactions with our mind that we think are originating from us is actually something that uh is coming from other life forms elsewhere consciousness itself might be that it could be but i don't see any sensible argument to the why why would all of the alien species be using this way yes some of them will be more primitive they would be close to our level you know there would there should be a whole sort of normal distribution of these things right some would be aggressive some would be you know curious others would be very stoical and philosophical because you know maybe they're a million years older than us but it's not it shouldn't be like what i mean one one alien civilization might be like that communicating thoughts and others but i don't see why you know potentially the hundreds there should be would be uniform in this way right it could be a violent dictatorship that the the people the alien civilizations that uh become successful become um [Music] gain the ability to be destructive an order of magnitude more destructive but of course the the sad thought well either humans are very special we took a lot of leaps that arrived at what it means to be human yeah um there's a question there which was the hardest which was the most special but also if others have reached this level and maybe many others have reached this level the great filter that prevented them from going farther to becoming a multi-planetary species or reaching out into the stars and those are really important questions for us whether um whether there's other alien civilizations out there or not this is very useful for us to think about if we destroy ourselves how will we do it and how easy is it to do yeah well you know these are big questions and i've thought about these a lot but the the the interesting thing is that if we're if we're alone that's somewhat comforting from the great filter perspective because it probably means the great filters were are past us and i'm pretty sure they are so that by in going back to your origin of life question there are some incredible things that no one knows how happened like obviously the first life form from chemical soup that seems pretty hard but i would guess the multicellular i wouldn't be that surprised if we saw single single cell sort of life forms elsewhere uh bacteria type things but multicellular life seems incredibly hard that step of you know capturing mitochondria and then sort of using that as part of yourself you know when you've just eaten it would you say that's the biggest the most uh like if if you had to choose one sort of uh hitchhiker's got this galaxy one sentence summary of like oh those clever creatures did this that would be the multilist i think that was probably the one that that's the biggest i mean there's a great book called the 10 grand great inventions of evolution by nick lane and he speculates on 10 10 of these you know what could be great filters um i think that's one i think the the advent of of intelligence and and conscious intelligence and in order you know to us to be able to do science and things like that is huge as well i mean it's only evolved once as far as you know uh in in earth history so that would be a later candidate but there's certainly for the early candidates i think multicellular life forms is huge by the way what it's interesting to ask you if you can hypothesize about what is the origin of intelligence is it uh that we started cooking meat over fire is it that we somehow figured out that we could be very powerful when we start collaborating so cooperation between um our ancestors so that we can overthrow the alpha male uh what is it richard i talked to richard randham who thinks we're all just beta males who figured out how to collaborate to defeat the one the dictator the authoritarian alpha male um that control the tribe um is there other explanation did was there um 2001 space out any type of monolith yeah that came down to earth well i i think um i think all of those things you suggest for good candidates fire and and and cooking right so that's clearly important you know energy efficiency yeah cooking our meat and then and then being able to to to be more efficient about eating it and getting it consuming the energy um i think that's huge and then utilizing fire and tools i think you're right about the the tribal cooperation aspects and probably language as part of that yes um because probably that's what allowed us to outcompete neanderthals and and perhaps less cooperative species so um so that may be the case tool making spears axes i think that let us i mean i think it's pretty clear now that humans were responsible for a lot of the extinctions of megafauna um especially in in the americas when humans arrived so uh you can imagine once you discover tool usage how powerful that would have been and how scary for animals so i think all of those could have been explanations for it you know the interesting thing is that it's a bit like general intelligence too is it's very costly to begin with to have a brain and especially a general purpose brain rather than a special purpose one because the amount of energy our brains use i think it's like 20 of the body's energy and it's it's massive and when you're thinking chest one of the funny things that that we used to say is as much as a racing driver uses for a whole you know formula one race if just playing a game of you know serious high level chess which you you know you wouldn't think just sitting there um because the brain's using so much uh energy so in order for an animal an organism to justify that there has to be a huge payoff and the problem with with half a brain or half you know intelligence saying iqs of you know of like a monkey brain it's it's not clear you can justify that evolutionary until you get to the human level brain and so but how do you how do you do that jump it's very difficult which is why i think it's only been done once from the sort of specialized brains that you see in animals to this sort of general purpose chewing powerful brains that humans have um and which allows us to invent the modern modern world um and uh you know it takes a lot to to cross that barrier and i think we've seen the same with ai systems which is that uh maybe until very recently it's always been easier to craft a specific solution to a problem like chess than it has been to build a general learning system that could potentially do many things because initially uh that system will be way worse than uh less efficient than the specialized system so one of the interesting quirks of the human mind of this evolved system is that it appears to be conscious this thing that we don't quite understand but it seems very very special its ability to have a subjective experience that it feels like something to eat a cookie the deliciousness of it or see a color and that kind of stuff do you think in order to solve intelligence we also need to solve consciousness along the way do you think agi systems need to have consciousness in order to be truly intelligent yeah we thought about this a lot actually and um i think that my guess is that consciousness and intelligence are double dissociable so you can have one without the other both ways and i think you can see that with consciousness in that i think some animals and pets if you have a pet dog or something like that you can see some of the higher animals and dolphins things like that are uh have self-awareness and uh very sociable um seem to dream um you know those kinds of a lot of the traits one would regard as being kind of conscious and self-aware um and but yet they're not that smart right uh so they're not that intelligent by by say iq standards or something like that yeah it's also possible that our understanding of intelligence is flawed like putting an iq to it sure maybe the thing that a dog can do is actually gone very far along the path of intelligence and we humans are just able to play chess and maybe write poems right but if we go back to the idea of agi and general intelligence you know dogs are very specialized right most animals are pretty specialized they can be amazing at what they do but they're like kind of elite sports sports people or something right so they do one thing extremely well because their entire brain is is optimized they have somehow convinced the entirety of the human population to feed them and service them so in some way they're controlling yes exactly well we co-evolved to some crazy degree right uh including the the way the dogs you know even even wag their tails and twitch their noses right we find we're finding inexorably cute yeah um but i think um you can also see intelligence on the other side so systems like artificial systems that are amazingly smart at certain things like maybe playing go and chess and other things but they don't feel at all in any shape or form conscious in the way that you know you do to me or i do to you and um and i think actually building ai is uh these intelligent constructs uh is one of the best ways to explore the mystery of consciousness to break it down because um we're going to have devices that are pretty smart at certain things or capable of certain things but potentially won't have any semblance of self-awareness or other things and in fact i would advocate if there's a choice building systems in the first place ai systems that are not conscious to begin with uh are just tools um until we understand them better and the capabilities better so on that topic just not as the ceo of deep mind just as a human being let me ask you about this one particular anecdotal evidence of the google engineer who made a comment or believed that there's some aspect of a language model the lambda language model that exhibited sentience so you said you believe there might be a responsibility to build systems that are not essential and this experience of a particular engineer i think i'd love to get your general opinion on this kind of thing but i think it will happen more and more and more which uh not when engineers but when people out there that don't have an engineering background start interacting with increasingly intelligent systems we anthropomorphize them they they start to have deep impactful um interactions with us in a way that we miss them yeah when they're gone and we sure feel like they're living entities self-aware entities and maybe even we project sentience onto them so what what's your thought about this particular uh system was is uh have you ever met a language model that's sentient no i no no what do you make of the case of when you kind of feel that there's some elements of sentience to this system yeah so this is you know an interesting question and uh uh obviously a very fundamental one so first thing to say is i think that none of the systems we have today i i would say even have one iota of uh semblance of consciousness or sentience that's my personal feeling interacting with them every day so i think that's way premature to be discussing what that engineer talked about i appreciate i think at the moment it's more of a projection of the way our own minds work which is to see uh uh uh sort of purpose and direction in almost anything that we you know our brains are trained to interpret uh agency basically in things uh even the an inanimate thing sometimes and of course with a a language system because language is so fundamental to intelligence that's going to be easy for us to anthropomorphize that i mean back in the day even the first uh you know the dumbest sort of template chatbots ever eliza and and and and the ilk of the original chatbots back in the 60s fooled some people under certain circumstances right they pretended to be a psychologist so just basically rabbit back to you the same question you asked it back to you um and uh some people believe that so i don't think we can this is why i think the turing test is a little bit flawed as a formal test because it depends on the sophistication of the of the judge um whether or not they are qualified to make that distinction so i think we should uh talk to you know the the top philosophers about this people like daniel dennett and uh david chalmers and others who've obviously thought deeply about consciousness of course consciousness itself hasn't been well there's no agreed definition if i was to you know uh speculate about that uh you know i kind of the definite the working definition i like is it's the way information feels when you know it gets processed i think maybe max tegmark came up with that i like that idea i don't know if it helps us get towards any more operational thing but but it's it's it's i think it's a nice way of viewing it um i think we can obviously see from neuroscience certain prerequisites that are required like self-awareness i think is necessary but not sufficient component this idea of a self and other and set of coherent preferences that are coherent over time you know these things are maybe memory um these things are probably needed for a sentient or conscious being um but but the reason that the difficult thing i think for us when we get and i think this is a really interesting philosophical debate is when we get closer to agi and and and you know and and much more powerful systems than we have today um how are we going to make this judgment and one way which is the turing test is sort of a behavioral judgment is is the system exhibiting all the behaviors um that a human sentient uh or a sentient being would would would exhibit um is it answering the right questions is it saying the right things is it indistinguishable from a human um and so on but i think there's a second thing that makes us as humans regard each other as sentient right why do we why do we think this and i debated this with daniel dennett and i think there's a second reason that's often overlooked which is that we're running on the same substrate right so if we're exhibiting the same behavior uh more or less as humans and we're running on the same you know carbon-based biological substrate the squishy you know few pounds of of flesh in our skulls then the most parsimonious i think explanation is that you're feeling the same thing as i'm feeling right but we will never have that second part the substrate equivalence with a machine right so we will have to only judge based on the behavior and i think the substrate equivalence is a critical part of why we make assumptions that we're conscious and in fact even with with animals high-level animals why we think they might be because they're exhibiting some of the behaviors we would expect from a sentient animal and we know they're made of the same things biological neurons so we're gonna have to come up with explanations uh or models of the gap between substrate differences between machines and humans did to get anywhere beyond the behavioral but to me sort of the practical question is very interesting and very important when you have millions perhaps billions of people believing that you have ascension ai believing what that google engineer believed which i just see is an obvious very near-term future thing certainly on the path to agi how does that change the world what's the responsibility of the ai system to help those millions of people and also what's the ethical thing because you can you can make a lot of people happy by creating a meaningful deep experience with a system that's faking it before it makes it yeah and i i don't is a are we the right or who is to say what's the right thing to do should ai always be tools like why why why are we constraining ais to always be tools as opposed to friends yeah i think well i mean these are you know you know fantastic questions and and also critical ones and we've been thinking about this uh since the start of d minor before that because we planned for success and you know how how you know you know however remote that looked like back in 2010 and we've always had sort of these ethical considerations as fundamental at deepmind um and my current thinking on the language models is and and large models is they're not ready we don't understand them well enough yet um and you know in terms of analysis tools and and guard rails what they can and can't do and so on to deploy them at scale because i think you know there are big still ethical questions like should an ai system always announce that it is an ai system to begin with probably yes um it what what do you do about answering those philosophical questions about the feelings uh people may have about ai systems perhaps incorrectly attributed so i think there's a whole bunch of research that needs to be done first um to responsibly before you know you can responsibly deploy these systems at scale that would be at least be my current position over time i'm very confident we'll have those tools like interpretability questions um and uh analysis questions uh and then with the ethical quandary you know i think there it's important to uh look beyond just science that's why i think philosophy social sciences even theology other things like that come into it where um what you know arts and humanities what what does it mean to be human and the spirit of being human and and to enhance that and and the human condition right and allow us to experience things we could never experience before and improve the the overall human condition and humanity overall you know get radical abundance solve many scientific problems solve disease so this is the era i think this is the amazing era i think we're heading into if we do it right um but we've got to be careful we've already seen with things like social media how dual use technologies can be misused by firstly by by by bad you know p bad actors or naive actors or crazy actors right so there's that set of just the common or garden misuse of existing dual use technology and then of course there's an additional uh uh thing that has to be overcome with ai that eventually it may have its own agency so it could be uh uh uh good or bad in in in of itself so i think these questions have to be approached very carefully um using the scientific method i would say in terms of hypothesis generation careful control testing not live a b testing out in the world because with powerful dual technologies like ai if something goes wrong it may cause you know a lot of harm before you can fix it um it's not like a you know an imaging app or game app where you know that if if something goes wrong it's relatively easy to fix and and the harm's relatively small so i think it comes with you know the the the usual uh cliche of like with a lot of power comes a lot of responsibility and i think that's the case here with things like ai given the the enormous opportunity in front of us and i think we need a lot of voices uh and as many inputs into things like the design of the systems and the values they should have and what goals should they be put to um i think as wide a group of voices as possible beyond just the technologies is needed uh to input into that and to have a say in that especially when it comes to deployment of these systems which is when the rubber really hits the road it really affects the general person in the street rather than fundamental research and that's why i say i think as a first step it would be better if we have the choice to build these systems as tools to give and i'm not saying that it should never they should never go beyond tools because of course the potential is there um for it to go way beyond just tools uh but um i think that would be a good first step in order for us to you know allow us to carefully experiment understand what these things can do so the leap between tool to sentient entity being is one should take very careful yes let me ask a dark personal question so you're one of the most brilliant people in the ag community also one of the most kind and uh if i may say sort of loved people in the community that said uh creation of a super intelligent ai system would be one of the most powerful things in the world tools or otherwise and again as the old saying goes power corrupts and absolute power crops absolutely you are likely to be one of the people i would say probably the most likely person to be in the control of such a system do you think about the corrupting nature of power when you talk about these kinds of systems that um as all dictators and people have caused atrocities in the past always think they're doing good but they don't do good because the powers polluted their mind about what is good and what is evil do you think about this stuff or are we just focused on language modeling no i think about them all the time and you know i think what are the defenses against that i think one thing is to remain very grounded and sort of humble uh no matter what you do or achieve and i try to do that i might you know my best friends are still my set of friends from my undergraduate cambridge days my family's you know and and friends are very important um i've always i think trying to be a multi-disciplinary person it helps to keep you humble because no matter how good you are at one topic someone will be better than you at that and it and always relearning a new topic again from scratch is or new field is very humbling right so for me that's been biology over the last five years you know huge area topic and and and it's been and i just love doing that but it helps to keep you grounded like it keeps you open-minded and and then the other important thing is to have a really good amazing set of uh people around you at your company or your organization who are also very ethical and grounded themselves and help to keep you that way and then ultimately just to answer your question i hope we're going to be a big part of of birthing ai and that being the greatest benefit to humanity of any tool or technology ever and and getting us into a world of radical abundance and curing diseases and and and solving many of the big challenges we have in front of us and then ultimately you know help the ultimate flourishing of humanity to travel the stars and find those aliens if they are there and if they're not there find out why they're not there what what is going on here in the universe um this is all to come and and that's what i've always dreamed about um but i don't think i think ai is too big an idea it's not going to be uh there'll be a certain set of pioneers who get there first i hope we're in the vanguard so we can influence how that goes and i think it matters who builds who which which cultures they come from and what values they have uh the builders of ai systems because i think even though the ai system is going to learn for itself most of its knowledge there'll be a residue in the system of the culture and the values of the creators of the system um and there's interesting questions to to discuss about that geopolitically you know different cultures as we're in a more fragmented world than ever unfortunately i think in terms of global cooperation we see that in things like climate where we can't seem to get our act together uh globally to cooperate on these pressing matters i hope that will change over time perhaps you know if we get to an era of radical abundance we don't have to be so competitive anymore maybe we can be more cooperative if resources aren't so scarce it's true that in terms of power corrupting and leading to destructive things it seems that some of the atrocities of the past happen when there's a significant constraint on resources i think that's the first thing i don't think that's enough i think scarcity is one thing that's led to competition destruct you know sort of zero sum game thinking i would like us to all be in a positive sum world and i think for that you have to remove scarcity i don't think that's enough unfortunately to get world peace because there's also other corrupting things like wanting power over people and this kind of stuff which is not necessarily satisfied by by just abundance but i think it will help um and i think uh but i think ultimately ai is not going to be run by any one person or one organization i think it should belong to the world belong to humanity um and i think maybe many there'll be many ways this will happen and ultimately um everybody should have a say in that do you have advice for uh young people in high school and college maybe um if they're interested in ai or interested in having a big impact on the world what they should do to have a career they can be proud of her to have a life they can be proud of i love giving talks to the next generation what i say to them is actually two things i i think the most important things to learn about and to find out about when you're when you're young is what are your true passions is first of all there's two things one is find your true passions and i think you can do that by the way to do that is to explore as many things as possible when you're young and you you have the time and you and you can take those risks um i would also encourage people to look at the finding the connections between things in a unique way i think that's a really great way to find a passion second thing i would say advise is know yourself so spend a lot of time understanding how you work best like what are the optimal times to work what are the optimal ways that you study um what are your how do you deal with pressure sort of test yourself in various scenarios and try and improve your weaknesses but also find out what your unique skills and strengths are and then hone those so then that's what will be your super value in the world later on and if you can then combine those two things and find passions that you're genuinely excited about that intersect with what your unique strong skills are then you're you know you're on to something incredible and and you know i think you can make a huge difference in the world so let me ask about know yourself this is fun this is fun quick questions about day in the life the perfect day the perfect productive day in the life of demise's house yeah maybe uh maybe these days you're um there's a lot involved yeah it may be a slightly younger you could focus on a demonstration project maybe um how early do you wake up are you night owl do you wake up early in the morning what are some interesting habits uh how many dozens of cups of coffees do you drink a day what's the computer um that you use uh what's the setup how many screens what kind of keyboard are we talking uh emacs vim are we talking something more modern so it's a bunch of those questions so maybe uh day in the life what what's the perfect day involved well these days it's quite different from say 10 20 years ago back 10 20 years ago it would have been you know a whole day of research individual research or programming doing some experiment neuroscience computer science experiment reading lots of research papers uh and then perhaps at night time you know um reading science fiction books or or uh playing uh some games but lots of focus so like deep focused work on whether it's uh programming or reading research paper yes yes so that would be a lot of debrief you know uh focused work these days for the last sort of i guess you know five to ten years i've actually got quite a structure that works very well for me now which is that um i'm a night complete night out always have been so i optimized for that so you know i get you know i basically do a normal day's work get into work about 11 o'clock and sort of do work to about seven uh in the office uh and i will arrange back-to-back meetings for the entire time of that and with as many me as many people as possible so that's my collaboration management part of the day then i go home uh spend time with the family and friends uh have dinner uh uh relax a little bit and then i start a second day of work i call it my second day work around 10 pm 11 p.m and that's the time till about the small hours of the morning four five in the morning where i will do my thinking and reading a research writing research papers um sadly don't have time to code anymore but it's it's not efficient to to do that uh these days uh given the amount of time i have um but that's when i do you know maybe do the long kind of stretches of of thinking and planning and then probably you know using using email or other things i would set i would fire off a lot of things to my team to deal with the next morning for actually thinking about this overnight we should go for this project or arrange this meeting the next day when you're thinking through a problem are you talking about a sheet of paper or the patent pen is there some independent structure yeah i like processes i still like pencil and paper best for working out things but um these days it's just so efficient to read research papers just on the screen i still often print them out actually i still prefer to mark out things and i find it goes into the brain quick better and sticks in the brain better when you're you're still using physical pen and pencil and paper so you take notes with the i have lots of nodes electronic ones and also um whole stacks of notebooks that um that i use at home yeah on some of these most challenging next steps for example stuff none of us know about that you're working on you're thinking there's some deep thinking required there right like what what is the right problem what is the right approach because you're gonna have to invest a huge amount of time for the whole team they're going to have to pursue this thing what's the right way to do it is is rl going to work here or not yes um what's the right thing to try what's the right benchmark to use yeah we need to construct a benchmark from scratch all those kinds of things yes so i think all those kind of things in the night time phase but also much more um i find i've always found the quiet hours of the morning um when everyone's asleep it's super quiet outside um i love that time it's the golden hours like between like one and three in the morning um put some music on some inspiring music on and then um think these deep thoughts so that's when i would read you know my philosophy books and uh spinoza's my you know recent favorite can all these things i i i you know read about a great uh uh a scientist of history how they did things how they thought things so that's when you do all your create that's when i do all my creative thinking and it's good i think i think people recommend you know you do your your your sort of creative thinking in one block and the way i organize the day that way i don't get interrupted because obviously no one else is up uh at those times so i can i can go uh you know as i can sort of get super deep and super into flow the other nice thing about doing it night time wise is if i'm really uh onto something or i've i've got really deep into something i can choose to extend it and i'll go into six in the morning whatever and then i'll just pay for it the next day yeah cause i'll be a bit tired and i won't be my best but that's fine i can decide looking at my schedule the next day that and given where i'm at with this particular thought or creative idea that i'm going to pay that cost the next day so so i think that's that's more flexible than morning people who do that you know they get up at four in the morning they can also do those golden hours then but then their start of their schedule day starts at breakfast you know 8 a.m whatever they have their first meeting and then it's hard you have to reschedule a day if you're in flow yeah that's going to be i don't have to see that special threat of thoughts that the you're too passionate about you that this is where some of the greatest ideas could potentially come is when you just lose yourself late into yeah and for the meetings i mean you're loading in really hard problems in a very short amount of time so you have to do some kind of first principles thinking here it's like what's the problem what's the state of things what's the right next step yes you have to get really good at context switching which is one of the hardest things because especially as we do so many things if you include all the scientific things we do scientific fields we're working in these are entire you know complex fields in themselves and you you have to sort of keep up to abreast of that but i enjoy it i've always been uh a sort of generalist in a way and that's actually what happened with my games career after chess i i i one of the reasons i stopped playing chess was that i got into computers but also i started realizing there were many other great games out there to play too so i've always been that way inclined multidisciplinary and there's too many interesting things in in the world to spend all your time just on one thing so you mentioned spinoza gotta ask the big ridiculously big question about life what do you think is the meaning of this whole thing uh why are we humans here you've already mentioned that perhaps the universe created us is that why you think we're here to understand how the universe yeah i think my answer to that would be and at least the the life i'm living is to gain and uh to gain and understand the knowledge you know to gain knowledge and understand the universe that's what i think uh i can't see any higher purpose than that if you think back to the classical greeks you know the virtue of gaining knowledge it's uh i think it's that it's one of the few true virtues is to understand um the world around us and the context and humanity better and um and i think if you do that you become more compassionate and more understanding yourself and and more tolerant and all these i think all these other things may flow from that and to me you know understanding the nature of reality that is the biggest question what is going on here is sometimes the colloquial way i say what is really going on here uh it's so mysterious i feel like we're in some huge puzzle and and it's but the world is also seems to be the universe seems to be structured in a way you know why is it structured in a way that science is even possible that you know methods the scientific method works things are repeatable um it feels like it's almost structured in a way to be conducive to gaining knowledge so i feel like and you know why should computers be even possible isn't that amazing that uh computational electronic devices can can can can be possible and they're made of sand our most you know common element that we have you know silicon that on the on the earth's crust they could be made of diamond or something then we would have only had one computer yeah right so it's a lot of things are kind of slightly suspicious to me it sure as heck sounds this puzzle sure sounds like something we talked about earlier what it takes to to design a game that's really fun to play for prolonged periods of time and it does seem like this puzzle like you mentioned the more you learn about it the more you realize how little you know so it humbles you but excites you by the possibility of learning more it's one heck of a one heck of a puzzle we got going on here um so like i mentioned of all the people in the world you're very likely to be the one who creates the agi system um that achieves human level intelligence and goes beyond it so if you got a chance and very well you could be the person that goes into the room with the system and have a conversation maybe you only get to ask one question if you do what question would you ask her i would probably ask um what is the true nature of reality i think that's the question i don't know if i'd understand the answer because maybe it would be 42 or something like that but um that's the question i would ask and then there'll be a deep sigh from the systems like all right how do i explain to the excuse me exactly all right let me i don't have time to explain uh maybe i'll draw you a picture that it is i mean how do you even begin um to answer that question well i think it would um what would you what would you think the answer could possibly look like i think it could it could start looking like uh uh more fundamental explanations of physics would be the beginning you know more careful specification of that taking you walking us through by the hand as to what one would do to maybe prove those things out maybe giving you glimpses of what things you totally missed in the physics of today exactly just here here's glimpses of no like there's a much uh a much more elaborate world or a much simpler world or something a much deeper maybe simpler explanation yes of things right than the standard model of physics which we know doesn't work but we still keep adding to so um and and that's how i think the beginning of an explanation would look and it would start encompassing many of the mysteries that we have wondered about for thousands of years like you know consciousness uh life and gravity all of these things yeah giving us a glimpses of explanations for those things yeah well um damas dear one of the special human beings in this giant puzzle of ours and it's a huge honor that you would take a pause from the bigger puzzle to solve this small puzzle of a conversation with me today it's truly an honor and a pleasure thank you thank you i really enjoyed it thanks lex thanks for listening to this conversation with demas establish to support this podcast please check out our sponsors in the description and now let me leave you with some words from edskar dykstra computer science is no more about computers than astronomy is about telescopes thank you for listening and hope to see you next time\n"
          ]
        }
      ],
      "source": [
        "from youtube_transcript_api import YouTubeTranscriptApi, TranscriptsDisabled\n",
        "\n",
        "video_id = \"Gfr50f6ZBvo\"\n",
        "\n",
        "try:\n",
        "    api = YouTubeTranscriptApi()\n",
        "    transcript_list = api.fetch(video_id, languages=[\"en\"])\n",
        "\n",
        "    # Use attribute access instead of dict indexing\n",
        "    transcript = \" \".join(chunk.text for chunk in transcript_list)\n",
        "    print(transcript)\n",
        "\n",
        "except TranscriptsDisabled:\n",
        "    print(\"No captions available for this video.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gl4DxS_5exjt",
        "outputId": "5e546cdf-9e32-4eec-e4f4-5d78a8f0ecb5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[  0.08s →   3.52s] the following is a conversation with\n",
            "[  1.76s →   6.72s] demus hasabis\n",
            "[  3.52s →   8.64s] ceo and co-founder of deepmind\n",
            "[  6.72s →  11.20s] a company that has published and builds\n",
            "[  8.64s →  13.20s] some of the most incredible artificial\n",
            "[ 11.20s →  16.00s] intelligence systems in the history of\n",
            "[ 13.20s →  16.88s] computing including alfred zero that\n",
            "[ 16.00s →  18.96s] learned\n",
            "[ 16.88s →  21.44s] all by itself to play the game of gold\n",
            "[ 18.96s →  24.56s] better than any human in the world and\n",
            "[ 21.44s →  25.68s] alpha fold two that solved protein\n",
            "[ 24.56s →  28.72s] folding\n",
            "[ 25.68s →  31.12s] both tasks considered nearly impossible\n",
            "[ 28.72s →  33.12s] for a very long time\n",
            "[ 31.12s →  35.60s] demus is widely considered to be one of\n",
            "[ 33.12s →  37.12s] the most brilliant and impactful humans\n",
            "[ 35.60s →  39.84s] in the history of artificial\n",
            "[ 37.12s →  41.12s] intelligence and science and engineering\n",
            "[ 39.84s →  43.76s] in general\n",
            "[ 41.12s →  46.08s] this was truly an honor and a pleasure\n",
            "[ 43.76s →  48.56s] for me to finally sit down with him for\n",
            "[ 46.08s →  51.44s] this conversation and i'm sure we will\n",
            "[ 48.56s →  53.28s] talk many times again in the future\n",
            "[ 51.44s →  55.44s] this is the lex friedman podcast to\n",
            "[ 53.28s →  58.24s] support it please check out our sponsors\n",
            "[ 55.44s →  59.60s] in the description and now dear friends\n",
            "[ 58.24s →  61.44s] here's demis\n",
            "[ 59.60s →  62.96s] hassabis\n",
            "[ 61.44s →  63.92s] let's start with a bit of a personal\n",
            "[ 62.96s →  66.80s] question\n",
            "[ 63.92s →  68.72s] am i an ai program you wrote to\n",
            "[ 66.80s →  70.96s] interview people until i get good enough\n",
            "[ 68.72s →  72.96s] to interview you\n",
            "[ 70.96s →  74.80s] well i'll be impressed if if you were\n",
            "[ 72.96s →  76.40s] i'd be impressed by myself if you were i\n",
            "[ 74.80s →  78.72s] don't think we're quite up to that yet\n",
            "[ 76.40s →  80.88s] but uh maybe you're from the future lex\n",
            "[ 78.72s →  82.56s] if you did would you tell me is that is\n",
            "[ 80.88s →  84.96s] that a good thing to tell a language\n",
            "[ 82.56s →  87.76s] model that's tasked with interviewing\n",
            "[ 84.96s →  90.24s] that it is in fact um ai maybe we're in\n",
            "[ 87.76s →  91.84s] a kind of meta turing test uh probably\n",
            "[ 90.24s →  93.20s] probably it would be a good idea not to\n",
            "[ 91.84s →  94.72s] tell you so it doesn't change your\n",
            "[ 93.20s →  96.40s] behavior right this is a kind of\n",
            "[ 94.72s →  98.08s] heisenberg uncertainty principle\n",
            "[ 96.40s →  99.52s] situation if i told you you behave\n",
            "[ 98.08s → 101.28s] differently yeah maybe that's what's\n",
            "[ 99.52s → 103.52s] happening with us of course this is a\n",
            "[101.28s → 107.84s] benchmark from the future where they\n",
            "[103.52s → 110.88s] replay 2022 as a year before ais were\n",
            "[107.84s → 113.76s] good enough yet and now we want to see\n",
            "[110.88s → 115.44s] is it going to pass exactly\n",
            "[113.76s → 117.12s] if i was such a\n",
            "[115.44s → 119.92s] program would you be able to tell do you\n",
            "[117.12s → 123.04s] think so to the touring test question\n",
            "[119.92s → 123.04s] you've talked about\n",
            "[123.20s → 127.12s] the benchmark for solving intelligence\n",
            "[125.68s → 128.64s] what would be the impressive thing\n",
            "[127.12s → 131.28s] you've talked about winning a nobel\n",
            "[128.64s → 133.36s] prize in a system winning a nobel prize\n",
            "[131.28s → 135.04s] but i still return to the touring test\n",
            "[133.36s → 137.12s] as a compelling test the spirit of the\n",
            "[135.04s → 138.80s] touring test is a compelling test\n",
            "[137.12s → 140.64s] yeah the turing test of course it's been\n",
            "[138.80s → 143.04s] unbelievably influential and turing's\n",
            "[140.64s → 144.88s] one of my all-time heroes but i think if\n",
            "[143.04s → 146.88s] you look back at the 1950 papers\n",
            "[144.88s → 148.88s] original paper and read the original\n",
            "[146.88s → 151.20s] you'll see i don't think he meant it to\n",
            "[148.88s → 153.04s] be a rigorous formal test i think it was\n",
            "[151.20s → 154.72s] more like a thought experiment almost a\n",
            "[153.04s → 156.56s] bit of philosophy he was writing if you\n",
            "[154.72s → 158.00s] look at the style of the paper and you\n",
            "[156.56s → 160.08s] can see he didn't specify it very\n",
            "[158.00s → 162.88s] rigorously so for example he didn't\n",
            "[160.08s → 165.52s] specify the knowledge that the expert or\n",
            "[162.88s → 167.68s] judge would have um not you know how\n",
            "[165.52s → 169.52s] much time would they have to investigate\n",
            "[167.68s → 172.16s] this so these important parameters if\n",
            "[169.52s → 173.44s] you were gonna make it uh a true sort of\n",
            "[172.16s → 176.48s] formal test\n",
            "[173.44s → 178.32s] um and you know some by some measures\n",
            "[176.48s → 179.84s] people claimed the turing test passed\n",
            "[178.32s → 181.52s] several you know a decade ago i remember\n",
            "[179.84s → 184.40s] someone claiming that with a with a kind\n",
            "[181.52s → 186.96s] of very bog standard normal uh\n",
            "[184.40s → 189.60s] logic model um because they pretended it\n",
            "[186.96s → 191.68s] was a it was a kid so the the judges\n",
            "[189.60s → 194.72s] thought that the machine you know was\n",
            "[191.68s → 197.20s] was a was a child so um that would be\n",
            "[194.72s → 199.04s] very different from an expert ai person\n",
            "[197.20s → 202.32s] uh interrogating a machine and knowing\n",
            "[199.04s → 203.68s] how it was built and so on so i think um\n",
            "[202.32s → 206.40s] you know we should probably move away\n",
            "[203.68s → 209.52s] from that as a formal test and move more\n",
            "[206.40s → 212.16s] towards a general test where we test the\n",
            "[209.52s → 214.64s] ai capabilities on a range of tasks and\n",
            "[212.16s → 217.28s] see if it reaches human level or above\n",
            "[214.64s → 219.28s] performance on maybe thousands perhaps\n",
            "[217.28s → 221.84s] even millions of tasks eventually and\n",
            "[219.28s → 223.36s] cover the entire sort of cognitive space\n",
            "[221.84s → 224.96s] so i think\n",
            "[223.36s → 227.28s] for its time it was an amazing thought\n",
            "[224.96s → 229.28s] experiment and also 1950s obviously it\n",
            "[227.28s → 231.36s] was barely the dawn of the computer age\n",
            "[229.28s → 233.52s] so of course he only thought about text\n",
            "[231.36s → 234.48s] and now um we have a lot more different\n",
            "[233.52s → 236.96s] inputs\n",
            "[234.48s → 238.80s] so yeah maybe the better thing to test\n",
            "[236.96s → 240.96s] is the generalizability so across\n",
            "[238.80s → 244.56s] multiple tasks but i think it's also\n",
            "[240.96s → 245.52s] possible as as systems like god show\n",
            "[244.56s → 247.44s] that\n",
            "[245.52s → 249.20s] eventually that might map right back to\n",
            "[247.44s → 251.52s] language so you might be able to\n",
            "[249.20s → 253.12s] demonstrate your ability to generalize\n",
            "[251.52s → 255.36s] across tasks\n",
            "[253.12s → 257.52s] by then communicating your ability to\n",
            "[255.36s → 259.04s] generalize across tasks which is kind of\n",
            "[257.52s → 260.72s] what we do through conversation anyway\n",
            "[259.04s → 262.56s] when we jump around\n",
            "[260.72s → 264.96s] ultimately what's in there in that\n",
            "[262.56s → 266.88s] conversation is not just you moving\n",
            "[264.96s → 269.12s] around knowledge\n",
            "[266.88s → 271.76s] it's you moving around like these\n",
            "[269.12s → 274.96s] entirely different modalities of\n",
            "[271.76s → 276.88s] understanding that ultimately map to\n",
            "[274.96s → 279.44s] your ability to\n",
            "[276.88s → 282.48s] to uh operate successfully in all these\n",
            "[279.44s → 284.96s] domains which you can think of as tasks\n",
            "[282.48s → 287.44s] yeah i think certainly we as humans use\n",
            "[284.96s → 290.00s] language as our main generalization\n",
            "[287.44s → 292.32s] communication tool so i think we end up\n",
            "[290.00s → 294.96s] thinking in language and expressing our\n",
            "[292.32s → 296.40s] solutions in language um so it's going\n",
            "[294.96s → 300.08s] to be very powerful\n",
            "[296.40s → 301.60s] uh uh mode in which to uh explain you\n",
            "[300.08s → 304.88s] know the system to explain what it's\n",
            "[301.60s → 308.16s] doing um but i don't think it's the only\n",
            "[304.88s → 309.60s] uh uh modality that matters so i think\n",
            "[308.16s → 310.88s] there's gonna be a lot of you know\n",
            "[309.60s → 313.84s] there's there's a lot of different ways\n",
            "[310.88s → 315.44s] to express uh capabilities uh other than\n",
            "[313.84s → 316.72s] just language\n",
            "[315.44s → 319.92s] yeah visual\n",
            "[316.72s → 321.04s] robotics body language\n",
            "[319.92s → 322.96s] um\n",
            "[321.04s → 324.80s] yeah action is the interactive aspect of\n",
            "[322.96s → 326.24s] all that that's all part of it but\n",
            "[324.80s → 328.88s] what's interesting with gato is that\n",
            "[326.24s → 330.72s] it's a it's it's it's sort of pushing\n",
            "[328.88s → 332.72s] prediction to the maximum in terms of\n",
            "[330.72s → 334.80s] like you know mapping arbitrary\n",
            "[332.72s → 336.08s] sequences to other sequences and sort of\n",
            "[334.80s → 338.64s] just predicting what's going to happen\n",
            "[336.08s → 340.96s] next so prediction seems to be\n",
            "[338.64s → 342.80s] fundamental to intelligence\n",
            "[340.96s → 344.96s] and what you're predicting\n",
            "[342.80s → 346.64s] doesn't so much matter yeah it seems\n",
            "[344.96s → 348.24s] like you can generalize that quite well\n",
            "[346.64s → 350.88s] so obviously language models predict the\n",
            "[348.24s → 354.24s] next word um gato predicts potentially\n",
            "[350.88s → 355.60s] any uh action or any token uh and it's\n",
            "[354.24s → 358.00s] just the beginning really it's our most\n",
            "[355.60s → 360.00s] general agent one could call it so far\n",
            "[358.00s → 361.60s] but um you know that itself can be\n",
            "[360.00s → 363.04s] scaled up massively more than we've done\n",
            "[361.60s → 365.68s] so far obviously we're in the in the\n",
            "[363.04s → 369.12s] middle of doing that but the big part of\n",
            "[365.68s → 372.16s] solving agi is creating benchmarks that\n",
            "[369.12s → 373.92s] help us get closer and closer sort of\n",
            "[372.16s → 375.76s] creating benchmarks that test the\n",
            "[373.92s → 378.80s] journalizability and it's just still\n",
            "[375.76s → 381.36s] interesting that this fella alan turing\n",
            "[378.80s → 383.76s] was one of the first and probably still\n",
            "[381.36s → 385.60s] one of the only people that was trying\n",
            "[383.76s → 387.20s] maybe philosophically but was trying to\n",
            "[385.60s → 388.80s] formulate a benchmark that could be\n",
            "[387.20s → 391.28s] followed it is\n",
            "[388.80s → 392.88s] even though it's it's fuzzy it's still\n",
            "[391.28s → 395.12s] sufficiently rigorous to where you can\n",
            "[392.88s → 397.04s] run that test and i still think\n",
            "[395.12s → 398.64s] something like the touring test will at\n",
            "[397.04s → 400.40s] the end of the day\n",
            "[398.64s → 402.48s] be the thing that truly\n",
            "[400.40s → 404.64s] impresses other humans\n",
            "[402.48s → 406.40s] so that you can have a close friend\n",
            "[404.64s → 408.24s] who's an ai system\n",
            "[406.40s → 410.40s] for that friend to be a good friend\n",
            "[408.24s → 413.04s] they're going to have to be able to\n",
            "[410.40s → 414.64s] uh play starcraft\n",
            "[413.04s → 418.08s] and they're going to have to do all of\n",
            "[414.64s → 419.92s] these tasks um get you a beer so the\n",
            "[418.08s → 423.12s] robotics tasks\n",
            "[419.92s → 425.76s] uh play games with you use language\n",
            "[423.12s → 427.92s] humor all those kinds of things but that\n",
            "[425.76s → 430.16s] ultimately can boil down to language it\n",
            "[427.92s → 432.48s] feels like not in terms of the ai\n",
            "[430.16s → 434.32s] community but in terms of the actual\n",
            "[432.48s → 436.16s] impact of general intelligence on the\n",
            "[434.32s → 438.96s] world it feels like language will be the\n",
            "[436.16s → 440.88s] place where it truly shines i think so\n",
            "[438.96s → 443.04s] because it's such an important kind of\n",
            "[440.88s → 444.88s] input output for us i think you're right\n",
            "[443.04s → 447.28s] i think the turing test that what the\n",
            "[444.88s → 450.24s] the kind of the the philosophy behind it\n",
            "[447.28s → 454.88s] which is the idea of can can a machine\n",
            "[450.24s → 457.04s] mimic the behaviors of a human and men\n",
            "[454.88s → 458.64s] and i would say wider than just language\n",
            "[457.04s → 460.56s] and text\n",
            "[458.64s → 462.24s] then you know in terms of actions and\n",
            "[460.56s → 464.64s] everything else creativity all these\n",
            "[462.24s → 467.28s] things then um if it can sort of match\n",
            "[464.64s → 469.12s] or exceed human cognitive capabilities\n",
            "[467.28s → 470.72s] then i think we have a you know true\n",
            "[469.12s → 472.48s] intelligence so i thought from that\n",
            "[470.72s → 475.84s] perspective you're right i think he did\n",
            "[472.48s → 477.84s] formulate the right uh kind of uh setup\n",
            "[475.84s → 479.20s] i just i think there'll be a kind of\n",
            "[477.84s → 481.12s] humor\n",
            "[479.20s → 483.44s] in the ai systems of the future looking\n",
            "[481.12s → 486.00s] back to this conversation\n",
            "[483.44s → 488.56s] and thinking about the touring test\n",
            "[486.00s → 490.32s] and uh also thinking about\n",
            "[488.56s → 493.20s] by that time they would know which year\n",
            "[490.32s → 494.56s] they were finally able to sort of cross\n",
            "[493.20s → 497.12s] the threshold of human level\n",
            "[494.56s → 498.88s] intelligence and think\n",
            "[497.12s → 499.84s] how funny it is that we humans were\n",
            "[498.88s → 502.32s] still\n",
            "[499.84s → 504.56s] confused about this whole problem\n",
            "[502.32s → 506.32s] that has been long ago been solved\n",
            "[504.56s → 509.36s] well hello to the ai agents of the\n",
            "[506.32s → 511.28s] future anyway so going back to your\n",
            "[509.36s → 513.60s] to your journey when did you fall in\n",
            "[511.28s → 515.44s] love with programming first\n",
            "[513.60s → 517.36s] well it's pretty uh pretty young age\n",
            "[515.44s → 519.84s] actually so um\n",
            "[517.36s → 521.84s] you know i started off uh actually games\n",
            "[519.84s → 523.60s] was my first love so starting to play\n",
            "[521.84s → 525.60s] chess when i was around four years old\n",
            "[523.60s → 527.92s] and then um it was actually with\n",
            "[525.60s → 529.60s] winnings from a chess competition that i\n",
            "[527.92s → 530.80s] managed to buy my first chess computer\n",
            "[529.60s → 533.04s] when i was about eight years old it was\n",
            "[530.80s → 534.64s] a zx spectrum which was hugely popular\n",
            "[533.04s → 537.36s] in the uk at the time\n",
            "[534.64s → 539.28s] and uh it's amazing machine because i\n",
            "[537.36s → 541.44s] think it trained a whole generation of\n",
            "[539.28s → 543.04s] programmers in the uk because it was so\n",
            "[541.44s → 544.56s] accessible you know you literally\n",
            "[543.04s → 547.04s] switched it on and there was the basic\n",
            "[544.56s → 548.80s] prompt and you could just get going and\n",
            "[547.04s → 550.64s] um my parents didn't really know\n",
            "[548.80s → 552.48s] anything about computers so but because\n",
            "[550.64s → 555.12s] it was my money from a chess competition\n",
            "[552.48s → 556.96s] i could i could say i i wanted to buy it\n",
            "[555.12s → 560.16s] uh and then you know i just went to\n",
            "[556.96s → 562.56s] bookstores got books on programming and\n",
            "[560.16s → 564.88s] um started typing in you know the\n",
            "[562.56s → 566.64s] programming code and and then of course\n",
            "[564.88s → 568.16s] um once you start doing that you start\n",
            "[566.64s → 570.08s] adjusting it and then making your own\n",
            "[568.16s → 571.52s] games and that's when i fell in love\n",
            "[570.08s → 575.20s] with computers and realized that they\n",
            "[571.52s → 576.40s] were a very magical device um in a way i\n",
            "[575.20s → 577.92s] kind of i would have been able to\n",
            "[576.40s → 579.44s] explain this at the time but i felt that\n",
            "[577.92s → 581.68s] they were sort of almost a magical\n",
            "[579.44s → 583.20s] extension of your mind i always had this\n",
            "[581.68s → 585.04s] feeling and i've always loved this about\n",
            "[583.20s → 587.44s] computers that you can set them off\n",
            "[585.04s → 589.36s] doing something some task for you you\n",
            "[587.44s → 590.40s] can go to sleep come back the next day\n",
            "[589.36s → 593.20s] and it's solved\n",
            "[590.40s → 594.80s] um you know that feels magical to me so\n",
            "[593.20s → 596.88s] i mean all machines do that to some\n",
            "[594.80s → 598.64s] extent they all enhance our natural\n",
            "[596.88s → 601.04s] capabilities obviously cars make us\n",
            "[598.64s → 603.52s] allow us to move faster than we can run\n",
            "[601.04s → 604.40s] but this was a machine to extend the\n",
            "[603.52s → 607.12s] mind\n",
            "[604.40s → 609.28s] and and then of course ai is the\n",
            "[607.12s → 612.08s] ultimate expression of what a machine\n",
            "[609.28s → 613.92s] may be able to do or learn so\n",
            "[612.08s → 615.92s] very naturally for me that thought\n",
            "[613.92s → 618.40s] extended into into ai quite quickly\n",
            "[615.92s → 619.76s] remember the the programming language\n",
            "[618.40s → 621.04s] that was first\n",
            "[619.76s → 622.48s] started\n",
            "[621.04s → 624.00s] special to the machine no it was just\n",
            "[622.48s → 626.08s] the base it was just i think it was just\n",
            "[624.00s → 627.92s] basic uh on the zx spectrum i don't know\n",
            "[626.08s → 631.12s] what specific form it was and then later\n",
            "[627.92s → 633.12s] on i got a commodore amiga which uh\n",
            "[631.12s → 635.04s] was a fantastic machine no you're just\n",
            "[633.12s → 637.12s] showing off so yeah well lots of my\n",
            "[635.04s → 638.80s] friends had atari st's and i i managed\n",
            "[637.12s → 640.96s] to get amigas it was a bit more powerful\n",
            "[638.80s → 644.00s] and uh and that was incredible and used\n",
            "[640.96s → 646.88s] to do um programming in assembler and\n",
            "[644.00s → 648.64s] and uh also amos basic this this\n",
            "[646.88s → 650.88s] specific form of basic it was incredible\n",
            "[648.64s → 653.12s] actually as well all my coding skills\n",
            "[650.88s → 655.44s] and when did you fall in love with ai so\n",
            "[653.12s → 657.04s] when did you first\n",
            "[655.44s → 659.52s] start to gain an understanding that you\n",
            "[657.04s → 661.52s] can not just write programs that\n",
            "[659.52s → 664.48s] do some mathematical operations for you\n",
            "[661.52s → 666.40s] while you sleep but something that's\n",
            "[664.48s → 668.72s] a keen to\n",
            "[666.40s → 669.60s] bringing an entity to life\n",
            "[668.72s → 671.76s] sort of\n",
            "[669.60s → 673.76s] a thing that can figure out something\n",
            "[671.76s → 675.76s] more complicated than uh\n",
            "[673.76s → 677.52s] than a simple mathematical operation\n",
            "[675.76s → 679.92s] yeah so there was a few stages for me\n",
            "[677.52s → 681.76s] all while i was very young so first of\n",
            "[679.92s → 683.36s] all as i was trying to improve at\n",
            "[681.76s → 684.96s] playing chess i was captaining various\n",
            "[683.36s → 686.64s] england junior chess teams and at the\n",
            "[684.96s → 688.40s] time when i was about you know maybe 10\n",
            "[686.64s → 689.76s] 11 years old i was gonna become a\n",
            "[688.40s → 690.64s] professional chess player that was my\n",
            "[689.76s → 694.08s] first\n",
            "[690.64s → 695.68s] thought um that dream was there sure she\n",
            "[694.08s → 698.32s] tried to get to the highest level yeah\n",
            "[695.68s → 700.00s] so i was um you know i got to when i was\n",
            "[698.32s → 701.52s] about 12 years old i got to master stand\n",
            "[700.00s → 703.28s] and i was second highest rated player in\n",
            "[701.52s → 705.68s] the world to judith polgar who obviously\n",
            "[703.28s → 709.44s] ended up being an amazing chess player\n",
            "[705.68s → 710.88s] and uh world women's champion and when i\n",
            "[709.44s → 712.40s] was trying to improve at chess where you\n",
            "[710.88s → 713.76s] know what you do is you obviously first\n",
            "[712.40s → 716.96s] of all you're trying to improve your own\n",
            "[713.76s → 718.48s] thinking processes so that leads you to\n",
            "[716.96s → 720.56s] thinking about thinking how is your\n",
            "[718.48s → 722.96s] brain coming up with these ideas why is\n",
            "[720.56s → 724.72s] it making mistakes how can you how can\n",
            "[722.96s → 726.88s] you improve that thought process but the\n",
            "[724.72s → 728.96s] second thing is that you it was just the\n",
            "[726.88s → 731.28s] beginning this was like in the in the\n",
            "[728.96s → 732.64s] early 80s mid 80s of chess computers if\n",
            "[731.28s → 734.16s] you remember they were physical boards\n",
            "[732.64s → 736.00s] like the one we have in front of us and\n",
            "[734.16s → 738.32s] you pressed down the you know the\n",
            "[736.00s → 741.28s] squares and i think kasparov had a\n",
            "[738.32s → 743.36s] branded version of it that i i i got and\n",
            "[741.28s → 744.80s] um you were you know used to they're not\n",
            "[743.36s → 746.56s] as strong as they are today but they\n",
            "[744.80s → 749.20s] were they were pretty strong and you\n",
            "[746.56s → 750.80s] used to practice against them um to try\n",
            "[749.20s → 752.40s] and improve your openings and other\n",
            "[750.80s → 753.68s] things and so i remember i think i\n",
            "[752.40s → 756.56s] probably got my first one i was around\n",
            "[753.68s → 758.00s] 11 or 12. and i remember thinking um\n",
            "[756.56s → 760.88s] this is amazing you know how how has\n",
            "[758.00s → 763.76s] someone programmed uh uh this this chess\n",
            "[760.88s → 765.84s] board to play chess uh and uh it was\n",
            "[763.76s → 767.84s] very formative book i bought which was\n",
            "[765.84s → 770.32s] called the chess computer handbook by\n",
            "[767.84s → 771.36s] david levy which came out in 1984 or\n",
            "[770.32s → 774.16s] something so i must have got it when i\n",
            "[771.36s → 776.16s] was about 11 12 and it explained fully\n",
            "[774.16s → 778.88s] how these chess programs were made i\n",
            "[776.16s → 781.28s] remember my first ai program being uh\n",
            "[778.88s → 782.88s] programming my amiga it couldn't it\n",
            "[781.28s → 784.24s] wasn't powerful enough to play chess i\n",
            "[782.88s → 786.72s] couldn't write a whole chess program but\n",
            "[784.24s → 788.24s] i wrote a program for it to play othello\n",
            "[786.72s → 790.64s] reversey it's sometimes called i think\n",
            "[788.24s → 792.56s] in the u.s and so a slightly simpler\n",
            "[790.64s → 794.48s] game than chess but i used all of the\n",
            "[792.56s → 796.48s] principles that chess programs had alpha\n",
            "[794.48s → 797.76s] beta search all of that and that was my\n",
            "[796.48s → 799.68s] first ai program i remember that very\n",
            "[797.76s → 801.84s] well was around 12 years old so that\n",
            "[799.68s → 804.24s] that that brought me into ai and then\n",
            "[801.84s → 806.56s] the second part was later on uh when i\n",
            "[804.24s → 808.72s] was around 1617 and i was writing games\n",
            "[806.56s → 810.88s] professionally designing games uh\n",
            "[808.72s → 813.92s] writing a game called theme park which\n",
            "[810.88s → 816.80s] um had ai as a core gameplay component\n",
            "[813.92s → 818.08s] as part of the simulation um and it sold\n",
            "[816.80s → 820.24s] you know millions of copies around the\n",
            "[818.08s → 822.16s] world and people loved the way that the\n",
            "[820.24s → 825.04s] ai even though it was relatively simple\n",
            "[822.16s → 826.64s] by today's ai standards um was was\n",
            "[825.04s → 828.80s] reacting to the way you as the player\n",
            "[826.64s → 830.56s] played it so it was called a sandbox\n",
            "[828.80s → 832.96s] game so it's one of the first types of\n",
            "[830.56s → 834.56s] games like that along with simcity and\n",
            "[832.96s → 835.60s] it meant that every game you played was\n",
            "[834.56s → 837.36s] unique\n",
            "[835.60s → 838.80s] is there something you could say just on\n",
            "[837.36s → 839.76s] a small tangent\n",
            "[838.80s → 844.16s] about\n",
            "[839.76s → 846.56s] really impressive ai from a game design\n",
            "[844.16s → 848.88s] human enjoyment perspective\n",
            "[846.56s → 851.04s] really impressive ai that you've seen in\n",
            "[848.88s → 853.20s] games and maybe what does it take to\n",
            "[851.04s → 856.08s] create ai system and how hard of a\n",
            "[853.20s → 858.24s] problem is that so a million questions\n",
            "[856.08s → 860.24s] just as a brief tangent\n",
            "[858.24s → 862.56s] well look i think um\n",
            "[860.24s → 864.16s] games uh games have been significant in\n",
            "[862.56s → 866.08s] my life for three reasons so first of\n",
            "[864.16s → 868.08s] all to to i was playing them and\n",
            "[866.08s → 870.32s] training myself on games when i was a\n",
            "[868.08s → 872.96s] kid then i went through a phase of\n",
            "[870.32s → 875.28s] designing games and writing ai4 games so\n",
            "[872.96s → 877.76s] all the games i i professionally wrote\n",
            "[875.28s → 880.80s] uh had ai as a core component and that\n",
            "[877.76s → 882.40s] was mostly in the in the 90s and the\n",
            "[880.80s → 884.40s] reason i was doing that in games\n",
            "[882.40s → 886.16s] industry was at the time the games\n",
            "[884.40s → 888.40s] industry i think was the cutting edge of\n",
            "[886.16s → 890.32s] technology so whether it was graphics\n",
            "[888.40s → 893.68s] with people like john carmack and quake\n",
            "[890.32s → 895.36s] and those kind of things or ai i think\n",
            "[893.68s → 897.28s] actually all the action was going on in\n",
            "[895.36s → 898.72s] games and and we've seen we're still\n",
            "[897.28s → 900.96s] reaping the benefits of that even with\n",
            "[898.72s → 902.32s] things like gpus which you know i find\n",
            "[900.96s → 903.92s] ironic was obviously invented for\n",
            "[902.32s → 906.08s] graphics computer graphics but then\n",
            "[903.92s → 907.60s] turns out to be amazingly useful for ai\n",
            "[906.08s → 909.84s] it just turns out everything's a matrix\n",
            "[907.60s → 911.04s] multiplication it appears you know in\n",
            "[909.84s → 914.08s] the whole world\n",
            "[911.04s → 916.16s] so um so i think games at the time had\n",
            "[914.08s → 918.80s] the most cutting edge ai and a lot of\n",
            "[916.16s → 920.24s] the the games uh uh we you know i was\n",
            "[918.80s → 921.60s] involved in writing so there was a game\n",
            "[920.24s → 923.04s] called black and white which was one\n",
            "[921.60s → 925.52s] game i was involved with in the early\n",
            "[923.04s → 926.80s] stages of which i still think is the\n",
            "[925.52s → 928.96s] most um\n",
            "[926.80s → 931.04s] impressive uh example of reinforcement\n",
            "[928.96s → 932.88s] learning in a computer game so in that\n",
            "[931.04s → 935.20s] game you know you trained a little pet\n",
            "[932.88s → 936.88s] animal uh and\n",
            "[935.20s → 938.40s] yeah and it sort of learned from how you\n",
            "[936.88s → 940.88s] were treating it so if you treated it\n",
            "[938.40s → 942.80s] badly then it became mean yeah and then\n",
            "[940.88s → 944.48s] it would be mean to to your villagers\n",
            "[942.80s → 946.00s] and your and your population the sort of\n",
            "[944.48s → 948.00s] uh the little tribe that you were\n",
            "[946.00s → 949.68s] running uh but if you were kind to it\n",
            "[948.00s → 951.76s] then it would be kind and people were\n",
            "[949.68s → 953.20s] fascinated by how that was and so was i\n",
            "[951.76s → 955.84s] to be honest with the way it kind of\n",
            "[953.20s → 958.16s] developed and um especially the mapping\n",
            "[955.84s → 961.12s] to good and evil yeah it made you made\n",
            "[958.16s → 963.12s] you realize made me realize that you can\n",
            "[961.12s → 965.12s] sort of in the way in the choices you\n",
            "[963.12s → 966.16s] make can define\n",
            "[965.12s → 969.20s] uh the\n",
            "[966.16s → 971.68s] where you end up and that means\n",
            "[969.20s → 974.48s] all of us are capable of the good\n",
            "[971.68s → 976.40s] uh evil it all matters in uh the\n",
            "[974.48s → 978.24s] different choices along the trajectory\n",
            "[976.40s → 980.32s] to those places that you make it's\n",
            "[978.24s → 981.92s] fascinating i mean games can do that\n",
            "[980.32s → 983.84s] philosophically to you and it's rare it\n",
            "[981.92s → 986.16s] seems rare yeah well games are i think a\n",
            "[983.84s → 987.44s] unique medium because um you as the\n",
            "[986.16s → 990.24s] player you're not just passively\n",
            "[987.44s → 992.72s] consuming the the entertainment right\n",
            "[990.24s → 995.12s] you're actually actively involved as an\n",
            "[992.72s → 996.56s] as a as an agent so i think that's what\n",
            "[995.12s → 998.48s] makes it in some ways can be more\n",
            "[996.56s → 1000.40s] visceral than other other mediums like\n",
            "[998.48s → 1002.16s] you know films and books so the second\n",
            "[1000.40s → 1005.36s] so that was you know designing ai and\n",
            "[1002.16s → 1007.60s] games and then the third use uh uh i've\n",
            "[1005.36s → 1009.76s] we've used of ai is in deep mind from\n",
            "[1007.60s → 1012.72s] the beginning which is using games as a\n",
            "[1009.76s → 1014.88s] testing ground for proving out ai\n",
            "[1012.72s → 1017.60s] algorithms and developing ai algorithms\n",
            "[1014.88s → 1019.20s] and that was a that was a sort of um a\n",
            "[1017.60s → 1021.04s] core component of our vision at the\n",
            "[1019.20s → 1023.92s] start of deepmind was that we would use\n",
            "[1021.04s → 1025.92s] games very heavily uh as our main\n",
            "[1023.92s → 1027.76s] testing ground certainly to begin with\n",
            "[1025.92s → 1030.24s] um because it's super efficient to use\n",
            "[1027.76s → 1032.80s] games and also you know it's very easy\n",
            "[1030.24s → 1034.80s] to have metrics to see how well your\n",
            "[1032.80s → 1036.08s] systems are improving and what direction\n",
            "[1034.80s → 1038.24s] your ideas are going in and whether\n",
            "[1036.08s → 1040.32s] you're making incremental improvements\n",
            "[1038.24s → 1041.92s] and because those games are often rooted\n",
            "[1040.32s → 1043.28s] in something that humans did for a long\n",
            "[1041.92s → 1045.68s] time beforehand\n",
            "[1043.28s → 1047.28s] there's already a strong\n",
            "[1045.68s → 1049.36s] set of rules like it's already a damn\n",
            "[1047.28s → 1051.20s] good benchmark yes it's really good for\n",
            "[1049.36s → 1052.88s] so many reasons because you've got\n",
            "[1051.20s → 1055.44s] you've got you've got clear measures of\n",
            "[1052.88s → 1057.04s] how good humans can be at these things\n",
            "[1055.44s → 1059.92s] and in some cases like go we've been\n",
            "[1057.04s → 1062.00s] playing it for thousands of years um and\n",
            "[1059.92s → 1064.32s] and uh often they have scores or at\n",
            "[1062.00s → 1065.92s] least win conditions so it's very easy\n",
            "[1064.32s → 1067.44s] for reward learning systems to get a\n",
            "[1065.92s → 1070.56s] reward it's very easy to specify what\n",
            "[1067.44s → 1072.80s] that reward is um and uh also at the end\n",
            "[1070.56s → 1074.48s] it's easy to you know to test uh\n",
            "[1072.80s → 1076.80s] externally you know\n",
            "[1074.48s → 1078.32s] how strong is your system by of course\n",
            "[1076.80s → 1081.04s] playing against you know the world's\n",
            "[1078.32s → 1082.64s] strongest players at those games so it's\n",
            "[1081.04s → 1084.48s] it's so good for so many reasons and\n",
            "[1082.64s → 1086.72s] it's also very efficient to run\n",
            "[1084.48s → 1089.60s] potentially millions of simulations in\n",
            "[1086.72s → 1091.60s] parallel on the cloud so um i think\n",
            "[1089.60s → 1093.84s] there's a huge reason why we were so\n",
            "[1091.60s → 1095.92s] successful back in you know starting out\n",
            "[1093.84s → 1098.80s] 2010 how come we were able to progress\n",
            "[1095.92s → 1100.96s] so quickly because we'd utilize games\n",
            "[1098.80s → 1103.28s] and um you know at the beginning of deep\n",
            "[1100.96s → 1105.84s] mind we also hired some amazing game\n",
            "[1103.28s → 1108.72s] engineers uh who i knew from my previous\n",
            "[1105.84s → 1110.24s] uh lives in the games industry and uh\n",
            "[1108.72s → 1112.72s] and that helped to bootstrap us very\n",
            "[1110.24s → 1114.96s] quickly and plus it's somehow super\n",
            "[1112.72s → 1118.24s] compelling almost at a philosophical\n",
            "[1114.96s → 1121.04s] level of man versus machine\n",
            "[1118.24s → 1122.80s] over over a chessboard or a go board\n",
            "[1121.04s → 1124.48s] and especially given that the entire\n",
            "[1122.80s → 1126.56s] history of ai is defined by people\n",
            "[1124.48s → 1128.48s] saying it's going to be impossible to\n",
            "[1126.56s → 1130.88s] make a machine that\n",
            "[1128.48s → 1133.04s] beats a human being in chess\n",
            "[1130.88s → 1135.28s] and then once that happened\n",
            "[1133.04s → 1137.20s] people were certain when i was coming up\n",
            "[1135.28s → 1138.64s] in ai that go\n",
            "[1137.20s → 1141.12s] is not a game that could be solved\n",
            "[1138.64s → 1144.16s] because of the combinatorial complexity\n",
            "[1141.12s → 1146.56s] it's just too it's it's it's you know\n",
            "[1144.16s → 1148.48s] no matter how much moore's law you have\n",
            "[1146.56s → 1151.28s] compute is just never going to be able\n",
            "[1148.48s → 1154.16s] to crack the game of go yeah and so that\n",
            "[1151.28s → 1156.24s] then there's something compelling about\n",
            "[1154.16s → 1159.28s] facing sort of taking on the\n",
            "[1156.24s → 1161.36s] impossibility of that task from the\n",
            "[1159.28s → 1162.72s] ai\n",
            "[1161.36s → 1164.40s] researcher perspective engineer\n",
            "[1162.72s → 1167.04s] perspective and then as a human being\n",
            "[1164.40s → 1168.80s] just observing this whole thing\n",
            "[1167.04s → 1170.40s] your\n",
            "[1168.80s → 1172.64s] beliefs about what you thought was\n",
            "[1170.40s → 1175.44s] impossible\n",
            "[1172.64s → 1177.60s] being broken apart\n",
            "[1175.44s → 1179.28s] it's it's uh humbling\n",
            "[1177.60s → 1180.32s] to realize we're not as smart as we\n",
            "[1179.28s → 1182.56s] thought\n",
            "[1180.32s → 1184.56s] it's humbling to realize that the things\n",
            "[1182.56s → 1185.68s] we think are impossible now perhaps will\n",
            "[1184.56s → 1188.00s] be done\n",
            "[1185.68s → 1191.36s] in the future there's something\n",
            "[1188.00s → 1193.28s] really powerful about a game ai system\n",
            "[1191.36s → 1194.88s] being a human being in a game that\n",
            "[1193.28s → 1197.12s] drives that message\n",
            "[1194.88s → 1200.32s] uh home for like millions billions of\n",
            "[1197.12s → 1202.16s] people especially in the case of go sure\n",
            "[1200.32s → 1204.08s] well look i think it's a i mean it has\n",
            "[1202.16s → 1206.96s] been a fascinating journey and and\n",
            "[1204.08s → 1208.96s] especially as i i think about it from i\n",
            "[1206.96s → 1210.48s] can understand it from both sides both\n",
            "[1208.96s → 1213.76s] as the ai\n",
            "[1210.48s → 1216.16s] you know creators of the ai um but also\n",
            "[1213.76s → 1217.60s] as a games player originally so you know\n",
            "[1216.16s → 1220.40s] it was a it was a really interesting it\n",
            "[1217.60s → 1222.08s] was i mean it was a fantastic um but\n",
            "[1220.40s → 1225.20s] also somewhat bittersweet moment the\n",
            "[1222.08s → 1227.12s] alphago match for me um uh seeing that\n",
            "[1225.20s → 1229.84s] and and and being obviously heavily\n",
            "[1227.12s → 1232.72s] heavily involved in that um but you know\n",
            "[1229.84s → 1234.32s] as you say chess has been uh the i mean\n",
            "[1232.72s → 1237.52s] kasparov i think rightly called it the\n",
            "[1234.32s → 1239.60s] drosophila of of intelligence right so\n",
            "[1237.52s → 1241.92s] it's sort of i i love that phrase and\n",
            "[1239.60s → 1244.72s] and i think he's right because chess has\n",
            "[1241.92s → 1247.28s] been um hand in hand with ai from the\n",
            "[1244.72s → 1249.52s] beginning of the the whole field right\n",
            "[1247.28s → 1251.20s] so i think every ai practitioner\n",
            "[1249.52s → 1253.36s] starting with turing and claude shannon\n",
            "[1251.20s → 1256.72s] and all those uh the sort of forefathers\n",
            "[1253.36s → 1258.72s] of of of of the field um tried their\n",
            "[1256.72s → 1260.56s] hand at writing a chess program uh i've\n",
            "[1258.72s → 1262.00s] got original audition of claude\n",
            "[1260.56s → 1265.76s] shannon's first chess program i think it\n",
            "[1262.00s → 1268.80s] was 1949 uh the the original sort of uh\n",
            "[1265.76s → 1270.56s] paper and um they all did that and\n",
            "[1268.80s → 1272.24s] turing famously wrote a chess program\n",
            "[1270.56s → 1273.84s] that but all the computers around there\n",
            "[1272.24s → 1275.68s] were obviously too slow to run it so he\n",
            "[1273.84s → 1278.00s] had to run he had to be the computer\n",
            "[1275.68s → 1280.08s] right so he literally i think spent two\n",
            "[1278.00s → 1281.76s] or three days running his own program by\n",
            "[1280.08s → 1283.76s] hand with pencil and paper and playing\n",
            "[1281.76s → 1285.92s] playing a friend of his uh with his\n",
            "[1283.76s → 1288.32s] chess program so\n",
            "[1285.92s → 1289.28s] of course deep blue was a huge moment uh\n",
            "[1288.32s → 1291.76s] beating\n",
            "[1289.28s → 1293.68s] off um but actually when that happened i\n",
            "[1291.76s → 1295.44s] remember that very very vividly of\n",
            "[1293.68s → 1297.36s] course because it was you know chess and\n",
            "[1295.44s → 1299.28s] computers and ai all the things i loved\n",
            "[1297.36s → 1300.80s] and i was at college at the time but i\n",
            "[1299.28s → 1303.12s] remember coming away from that being\n",
            "[1300.80s → 1305.28s] more impressed by kasparov's mind than i\n",
            "[1303.12s → 1307.92s] was by deep blue because here was\n",
            "[1305.28s → 1309.44s] kasparov with his human mind not only\n",
            "[1307.92s → 1311.28s] could he play chess more or less to the\n",
            "[1309.44s → 1313.68s] same level as this brute of a\n",
            "[1311.28s → 1315.28s] calculation machine um but of course\n",
            "[1313.68s → 1317.28s] kasparov can do everything else humans\n",
            "[1315.28s → 1318.96s] can do ride a bike talk many languages\n",
            "[1317.28s → 1321.52s] do politics all the rest of the amazing\n",
            "[1318.96s → 1323.76s] things that kasparov does and so with\n",
            "[1321.52s → 1326.96s] the same brain yeah and and yet deep\n",
            "[1323.76s → 1330.56s] blue uh brilliant as it was at chess it\n",
            "[1326.96s → 1333.12s] had been hand coded for chess and um\n",
            "[1330.56s → 1335.60s] actually had distilled the knowledge of\n",
            "[1333.12s → 1337.68s] chess grand masters uh into into a cool\n",
            "[1335.60s → 1339.36s] program but it couldn't do anything else\n",
            "[1337.68s → 1341.92s] like it couldn't even play a strictly\n",
            "[1339.36s → 1345.12s] simpler game like tic-tac-toe so um\n",
            "[1341.92s → 1347.20s] something to me was missing from um\n",
            "[1345.12s → 1348.72s] intelligence from that system that we\n",
            "[1347.20s → 1351.20s] would regard as intelligence and i think\n",
            "[1348.72s → 1353.92s] it was this idea of generality and and\n",
            "[1351.20s → 1356.56s] also learning yeah um so and that's what\n",
            "[1353.92s → 1358.96s] we tried to do out with alphago yeah we\n",
            "[1356.56s → 1361.68s] alphago and alpha zero mu zero and then\n",
            "[1358.96s → 1363.68s] got on all the things that uh we'll get\n",
            "[1361.68s → 1366.08s] into some parts of there's just a\n",
            "[1363.68s → 1369.04s] fascinating trajectory here but let's\n",
            "[1366.08s → 1371.84s] just stick on chess briefly uh on the\n",
            "[1369.04s → 1373.60s] human side of chess you've proposed that\n",
            "[1371.84s → 1375.04s] from a game design perspective the thing\n",
            "[1373.60s → 1377.28s] that makes chess\n",
            "[1375.04s → 1379.44s] compelling as a game\n",
            "[1377.28s → 1380.96s] uh is that there's a creative tension\n",
            "[1379.44s → 1382.80s] between a bishop\n",
            "[1380.96s → 1384.40s] and the knight\n",
            "[1382.80s → 1386.56s] can you explain this first of all it's\n",
            "[1384.40s → 1388.64s] really interesting to think about what\n",
            "[1386.56s → 1391.92s] makes the game compelling\n",
            "[1388.64s → 1393.36s] makes it stick across centuries\n",
            "[1391.92s → 1394.96s] yeah i was sort of thinking about this\n",
            "[1393.36s → 1396.72s] and actually a lot of even amazing chess\n",
            "[1394.96s → 1398.32s] players don't think about it necessarily\n",
            "[1396.72s → 1400.32s] from a games designer point of view so\n",
            "[1398.32s → 1401.92s] it's with my game design hat on that i\n",
            "[1400.32s → 1402.96s] was thinking about this why is chess so\n",
            "[1401.92s → 1406.32s] compelling\n",
            "[1402.96s → 1408.56s] and i think a critical uh reason is the\n",
            "[1406.32s → 1409.84s] the dynamicness of of of the different\n",
            "[1408.56s → 1411.44s] kind of chess positions you can have\n",
            "[1409.84s → 1413.12s] whether they're closed or open and other\n",
            "[1411.44s → 1415.52s] things comes from the bishop and the\n",
            "[1413.12s → 1418.16s] night so if you think about how\n",
            "[1415.52s → 1419.52s] different the the the capabilities of\n",
            "[1418.16s → 1422.40s] the bishop and knight are in terms of\n",
            "[1419.52s → 1424.00s] the way they move and then somehow chess\n",
            "[1422.40s → 1426.08s] has evolved to balance those two\n",
            "[1424.00s → 1428.08s] capabilities more or less equally so\n",
            "[1426.08s → 1429.92s] they're both roughly worth three points\n",
            "[1428.08s → 1431.20s] each so you think that dynamics was\n",
            "[1429.92s → 1433.36s] always there and then the rest of the\n",
            "[1431.20s → 1434.96s] rules are kind of trying to stabilize\n",
            "[1433.36s → 1436.00s] the game well maybe i mean it's sort of\n",
            "[1434.96s → 1437.52s] i don't know his chicken and egg\n",
            "[1436.00s → 1439.12s] situation probably both came together\n",
            "[1437.52s → 1441.36s] but the fact that it's got to this\n",
            "[1439.12s → 1442.72s] beautiful equilibrium where you can have\n",
            "[1441.36s → 1445.68s] the bishop and knight they're so\n",
            "[1442.72s → 1447.68s] different in power um but so equal in\n",
            "[1445.68s → 1450.16s] value across the set of the universe of\n",
            "[1447.68s → 1452.08s] all positions right somehow they've been\n",
            "[1450.16s → 1454.88s] balanced by humanity over hundreds of\n",
            "[1452.08s → 1457.12s] years um i think gives gives the game\n",
            "[1454.88s → 1459.20s] the creative tension uh that you can\n",
            "[1457.12s → 1460.88s] swap the bishop and knights uh for a\n",
            "[1459.20s → 1462.48s] bishop for a knight and you you they're\n",
            "[1460.88s → 1464.00s] more or less worth the same but now you\n",
            "[1462.48s → 1465.36s] aim for a different type of position if\n",
            "[1464.00s → 1466.88s] you have the knight you want a closed\n",
            "[1465.36s → 1468.80s] position if you have the bishop you want\n",
            "[1466.88s → 1470.80s] an open position so i think that creates\n",
            "[1468.80s → 1472.64s] a lot of the creative tension in chess\n",
            "[1470.80s → 1473.92s] so some kind of controlled creative\n",
            "[1472.64s → 1475.92s] tension\n",
            "[1473.92s → 1477.68s] from an ai perspective\n",
            "[1475.92s → 1479.44s] do you think ai systems convention\n",
            "[1477.68s → 1481.44s] design games that are optimally\n",
            "[1479.44s → 1482.72s] compelling to humans\n",
            "[1481.44s → 1484.72s] well that's an interesting question you\n",
            "[1482.72s → 1486.80s] know sometimes i get asked about\n",
            "[1484.72s → 1488.40s] ai and creativity and and this and the\n",
            "[1486.80s → 1490.00s] way i answered that is relevant to that\n",
            "[1488.40s → 1492.32s] question which is that i think they're\n",
            "[1490.00s → 1494.64s] different levels of creativity one could\n",
            "[1492.32s → 1496.16s] say so i think um if we define\n",
            "[1494.64s → 1498.24s] creativity as coming up with something\n",
            "[1496.16s → 1500.72s] original right that's that's useful for\n",
            "[1498.24s → 1502.56s] a purpose then you know i think the kind\n",
            "[1500.72s → 1505.04s] of lowest level of creativity is like an\n",
            "[1502.56s → 1507.20s] interpolation so an averaging of all the\n",
            "[1505.04s → 1508.88s] examples you see so maybe a very basic\n",
            "[1507.20s → 1510.64s] ai system could say you could have that\n",
            "[1508.88s → 1512.80s] so you show it millions of pictures of\n",
            "[1510.64s → 1514.56s] cats and then you say give me an average\n",
            "[1512.80s → 1516.00s] looking cat right generate me an average\n",
            "[1514.56s → 1518.56s] looking cat i would call that\n",
            "[1516.00s → 1520.56s] interpolation then there's extrapolation\n",
            "[1518.56s → 1522.40s] which something like alphago showed so\n",
            "[1520.56s → 1524.40s] alphago played you know millions of\n",
            "[1522.40s → 1526.00s] games of go against itself\n",
            "[1524.40s → 1528.64s] and then it came up with brilliant new\n",
            "[1526.00s → 1531.52s] ideas like move 37 in game two bringing\n",
            "[1528.64s → 1533.20s] a motif strategies and go that that no\n",
            "[1531.52s → 1534.72s] humans had ever thought of even though\n",
            "[1533.20s → 1536.48s] we've played it for thousands of years\n",
            "[1534.72s → 1538.72s] and professionally for hundreds of years\n",
            "[1536.48s → 1540.16s] so that that i call that extrapolation\n",
            "[1538.72s → 1541.92s] but then that's still there's still a\n",
            "[1540.16s → 1544.40s] level above that which is you know you\n",
            "[1541.92s → 1547.20s] could call out the box thinking or true\n",
            "[1544.40s → 1548.64s] innovation which is could you invent go\n",
            "[1547.20s → 1550.16s] right could you invent chess and not\n",
            "[1548.64s → 1552.32s] just come up with a brilliant chess move\n",
            "[1550.16s → 1554.24s] or brilliant go move but can you can you\n",
            "[1552.32s → 1557.52s] actually invent chess or something as\n",
            "[1554.24s → 1560.40s] good as chess or go and i think one day\n",
            "[1557.52s → 1563.20s] uh ai could but what's missing is how\n",
            "[1560.40s → 1565.20s] would you even specify that task to a a\n",
            "[1563.20s → 1567.36s] program right now and the way i would do\n",
            "[1565.20s → 1569.44s] it if i was best telling a human to do\n",
            "[1567.36s → 1570.72s] it or a games designer a human games\n",
            "[1569.44s → 1573.20s] designer to do it is i would say\n",
            "[1570.72s → 1574.80s] something like go i would say um\n",
            "[1573.20s → 1576.80s] come up with a game that only takes five\n",
            "[1574.80s → 1578.96s] minutes to learn which go does because\n",
            "[1576.80s → 1581.20s] it's got simple rules but many lifetimes\n",
            "[1578.96s → 1583.12s] to master right or impossible to master\n",
            "[1581.20s → 1586.08s] in one lifetime because so deep and so\n",
            "[1583.12s → 1588.96s] complex um and then it's aesthetically\n",
            "[1586.08s → 1590.80s] beautiful uh and also uh it can be\n",
            "[1588.96s → 1592.80s] completed in three or four hours of\n",
            "[1590.80s → 1595.84s] gameplay time which is you know useful\n",
            "[1592.80s → 1598.08s] for our us you know in in a human day\n",
            "[1595.84s → 1600.24s] and so um you might specify these side\n",
            "[1598.08s → 1601.92s] of high level concepts like that and\n",
            "[1600.24s → 1604.56s] then you know with that and maybe a few\n",
            "[1601.92s → 1607.84s] other things uh one could imagine that\n",
            "[1604.56s → 1609.44s] go satisfies uh those those constraints\n",
            "[1607.84s → 1612.96s] um but the problem is is that we we're\n",
            "[1609.44s → 1614.72s] not able to specify abstract notions\n",
            "[1612.96s → 1617.92s] like that high-level abstract notions\n",
            "[1614.72s → 1619.12s] like that yet to our ai systems um and i\n",
            "[1617.92s → 1621.44s] think there's still something missing\n",
            "[1619.12s → 1623.04s] there in terms of um high-level concepts\n",
            "[1621.44s → 1625.36s] or abstractions that they truly\n",
            "[1623.04s → 1629.04s] understand and that you know combinable\n",
            "[1625.36s → 1630.48s] and compositional um so for the moment\n",
            "[1629.04s → 1633.12s] i think ai is capable of doing\n",
            "[1630.48s → 1636.64s] interpolation extrapolation but not true\n",
            "[1633.12s → 1638.64s] invention so coming up with rule sets\n",
            "[1636.64s → 1640.40s] uh and optimizing\n",
            "[1638.64s → 1642.72s] with complicated objectives around those\n",
            "[1640.40s → 1645.92s] rule sets we can't currently do\n",
            "[1642.72s → 1648.16s] but you could take a specific rule set\n",
            "[1645.92s → 1650.64s] and then run a kind of self-play\n",
            "[1648.16s → 1652.72s] experiment to see how long\n",
            "[1650.64s → 1655.52s] just observe how an ai system from\n",
            "[1652.72s → 1657.44s] scratch learns how long is that journey\n",
            "[1655.52s → 1659.36s] of learning and maybe\n",
            "[1657.44s → 1660.48s] if it satisfies some of those other\n",
            "[1659.36s → 1662.56s] things you mentioned in terms of\n",
            "[1660.48s → 1664.96s] quickness to learn and so on and you\n",
            "[1662.56s → 1667.36s] could see a long journey to master for\n",
            "[1664.96s → 1669.28s] even an ai system then you could say\n",
            "[1667.36s → 1671.28s] that this is a promising game\n",
            "[1669.28s → 1674.08s] um but it would be nice to do almost\n",
            "[1671.28s → 1676.24s] like alpha codes or programming rules so\n",
            "[1674.08s → 1677.12s] generating rules that kind of\n",
            "[1676.24s → 1679.20s] uh\n",
            "[1677.12s → 1680.96s] that automate even that part of the\n",
            "[1679.20s → 1683.12s] generation of rules so i have thought\n",
            "[1680.96s → 1685.12s] about systems actually um that i think\n",
            "[1683.12s → 1687.52s] would be amazing in in for a games\n",
            "[1685.12s → 1689.84s] designer if you could have a system that\n",
            "[1687.52s → 1691.92s] um takes your game plays it tens of\n",
            "[1689.84s → 1694.00s] millions of times maybe overnight and\n",
            "[1691.92s → 1696.96s] then self balances the rules better so\n",
            "[1694.00s → 1699.28s] it tweaks the the rules and the maybe\n",
            "[1696.96s → 1702.16s] the equations and the and the and the\n",
            "[1699.28s → 1704.56s] parameters so that the game uh is more\n",
            "[1702.16s → 1706.24s] balanced the units in the game or\n",
            "[1704.56s → 1708.24s] some of the rules could be tweaked so\n",
            "[1706.24s → 1710.40s] it's a bit of like a giving a base set\n",
            "[1708.24s → 1711.92s] and then allowing a monte carlo tree\n",
            "[1710.40s → 1714.16s] search or something like that to sort of\n",
            "[1711.92s → 1717.04s] explore it right and i think that would\n",
            "[1714.16s → 1719.52s] be super super a powerful tool actually\n",
            "[1717.04s → 1721.04s] for for balancing auto balancing a game\n",
            "[1719.52s → 1722.72s] which usually takes\n",
            "[1721.04s → 1724.88s] thousands of hours from hundreds of\n",
            "[1722.72s → 1726.32s] games human games testers normally to to\n",
            "[1724.88s → 1729.12s] balance some one you know game like\n",
            "[1726.32s → 1730.72s] starcraft which is you know blizzard are\n",
            "[1729.12s → 1732.64s] amazing at balancing their games but it\n",
            "[1730.72s → 1734.16s] takes them years and years and years so\n",
            "[1732.64s → 1736.64s] one could imagine at some point when\n",
            "[1734.16s → 1737.92s] this uh this stuff becomes uh efficient\n",
            "[1736.64s → 1739.44s] enough to you know you might be able to\n",
            "[1737.92s → 1742.64s] do that like overnight\n",
            "[1739.44s → 1744.88s] do you think a game that is optimal\n",
            "[1742.64s → 1747.68s] designed by an ai system\n",
            "[1744.88s → 1749.60s] would look very much like uh planet\n",
            "[1747.68s → 1751.60s] earth\n",
            "[1749.60s → 1753.92s] maybe maybe it's only the sort of game i\n",
            "[1751.60s → 1756.00s] would love to make is is and i've tried\n",
            "[1753.92s → 1758.00s] you know my in my game's career the\n",
            "[1756.00s → 1760.24s] games design career you know my first\n",
            "[1758.00s → 1763.04s] big game was designing a theme park an\n",
            "[1760.24s → 1765.04s] amusement park then uh with games like\n",
            "[1763.04s → 1767.12s] republic i tried to you know have games\n",
            "[1765.04s → 1769.36s] where we designed whole cities and and\n",
            "[1767.12s → 1770.88s] allowed you to play in so and of course\n",
            "[1769.36s → 1772.88s] people like will wright have written\n",
            "[1770.88s → 1774.40s] games like sim earth uh trying to\n",
            "[1772.88s → 1776.72s] simulate the whole of earth pretty\n",
            "[1774.40s → 1778.32s] tricky but um i see earth i haven't\n",
            "[1776.72s → 1780.48s] actually played that one so what is it\n",
            "[1778.32s → 1782.72s] does it incorporative evolution or yeah\n",
            "[1780.48s → 1784.32s] it has evolution and it's sort of um it\n",
            "[1782.72s → 1786.00s] tries to it sort of treats it as an\n",
            "[1784.32s → 1787.20s] entire biosphere but from quite a high\n",
            "[1786.00s → 1788.16s] level\n",
            "[1787.20s → 1790.40s] so\n",
            "[1788.16s → 1792.24s] nice to be able to sort of zoom in zoom\n",
            "[1790.40s → 1793.44s] out zoom in exactly so obviously he\n",
            "[1792.24s → 1795.04s] couldn't do that was in the night i\n",
            "[1793.44s → 1796.40s] think he wrote that in the 90s so it\n",
            "[1795.04s → 1798.40s] couldn't you know it wasn't it wasn't\n",
            "[1796.40s → 1800.48s] able to do that but that that would be\n",
            "[1798.40s → 1801.36s] uh obviously the ultimate sandbox game\n",
            "[1800.48s → 1802.88s] of course\n",
            "[1801.36s → 1804.72s] on that topic do you think we're living\n",
            "[1802.88s → 1806.96s] in a simulation\n",
            "[1804.72s → 1809.20s] yes well so okay so i'm gonna jump\n",
            "[1806.96s → 1811.60s] around from the absurdly philosophical\n",
            "[1809.20s → 1813.44s] to the short term sure very very happy\n",
            "[1811.60s → 1815.76s] to so i think uh my answer to that\n",
            "[1813.44s → 1817.76s] question is a little bit complex because\n",
            "[1815.76s → 1819.44s] uh there is simulation theory which\n",
            "[1817.76s → 1821.60s] obviously nick bostrom i think famously\n",
            "[1819.44s → 1824.08s] first proposed um\n",
            "[1821.60s → 1826.88s] and uh i don't quite believe it in in\n",
            "[1824.08s → 1828.88s] that sense so um in the in the sense\n",
            "[1826.88s → 1831.68s] that uh are we in some sort of computer\n",
            "[1828.88s → 1834.48s] game or have our descendants somehow\n",
            "[1831.68s → 1836.96s] recreated uh uh earth in the you know\n",
            "[1834.48s → 1839.76s] 21st century and and some for some kind\n",
            "[1836.96s → 1842.64s] of experimental reason i think that um\n",
            "[1839.76s → 1844.56s] but i do think that we that that we\n",
            "[1842.64s → 1847.52s] might be that the best way to understand\n",
            "[1844.56s → 1849.60s] physics and the universe is from a\n",
            "[1847.52s → 1851.36s] computational perspective so\n",
            "[1849.60s → 1854.00s] understanding it as an information\n",
            "[1851.36s → 1858.24s] universe and actually information being\n",
            "[1854.00s → 1860.00s] the most fundamental unit of uh reality\n",
            "[1858.24s → 1861.84s] rather than matter or energy so a\n",
            "[1860.00s → 1863.60s] physicist would say you know matter or\n",
            "[1861.84s → 1865.60s] energy you know e equals m c squared\n",
            "[1863.60s → 1867.52s] these are the things that are are the\n",
            "[1865.60s → 1870.00s] fundamentals of the universe i'd\n",
            "[1867.52s → 1872.72s] actually say information um which of\n",
            "[1870.00s → 1874.56s] course itself can be can specify energy\n",
            "[1872.72s → 1876.24s] or matter right matter is actually just\n",
            "[1874.56s → 1878.00s] you know we're we're just out the way\n",
            "[1876.24s → 1880.32s] our bodies and all the molecules in our\n",
            "[1878.00s → 1882.80s] body arrange is information so i think\n",
            "[1880.32s → 1884.96s] information may be the most fundamental\n",
            "[1882.80s → 1887.20s] way to describe the universe and\n",
            "[1884.96s → 1889.68s] therefore you could say we're in some\n",
            "[1887.20s → 1891.36s] sort of simulation because of that um\n",
            "[1889.68s → 1893.92s] but i don't i do i'm not i'm not really\n",
            "[1891.36s → 1895.44s] a subscriber to the idea that um you\n",
            "[1893.92s → 1897.04s] know these are sort of throw away\n",
            "[1895.44s → 1899.60s] billions of simulations around i think\n",
            "[1897.04s → 1901.92s] this is actually very critical and\n",
            "[1899.60s → 1903.92s] possibly unique this simulation\n",
            "[1901.92s → 1905.20s] particular one yes so but and you just\n",
            "[1903.92s → 1906.96s] mean\n",
            "[1905.20s → 1908.72s] treating the universe\n",
            "[1906.96s → 1909.68s] as a computer\n",
            "[1908.72s → 1912.16s] that's\n",
            "[1909.68s → 1913.84s] processing and modifying information\n",
            "[1912.16s → 1917.20s] is is a good way to solve the problems\n",
            "[1913.84s → 1920.08s] of physics of chemistry of biology\n",
            "[1917.20s → 1922.88s] and perhaps of humanity and so on yes i\n",
            "[1920.08s → 1925.60s] think understanding physics in terms of\n",
            "[1922.88s → 1928.00s] information theory uh might be the best\n",
            "[1925.60s → 1929.28s] way to to really uh understand what's\n",
            "[1928.00s → 1932.32s] going on here\n",
            "[1929.28s → 1934.64s] from our understanding of a universal\n",
            "[1932.32s → 1935.76s] turing machine from our understanding of\n",
            "[1934.64s → 1938.32s] a computer do you think there's\n",
            "[1935.76s → 1940.40s] something outside of the capabilities of\n",
            "[1938.32s → 1942.56s] a computer that is present in our\n",
            "[1940.40s → 1944.08s] universe you have a disagreement with\n",
            "[1942.56s → 1946.32s] roger penrose\n",
            "[1944.08s → 1948.00s] the nature of consciousness he he thinks\n",
            "[1946.32s → 1949.60s] that consciousness is more than just a\n",
            "[1948.00s → 1951.60s] computation\n",
            "[1949.60s → 1953.92s] uh do you think all of it the whole\n",
            "[1951.60s → 1955.68s] shebang is can be can be a competition\n",
            "[1953.92s → 1958.08s] yeah i've had many fascinating debates\n",
            "[1955.68s → 1960.32s] with uh sir roger penrose and obviously\n",
            "[1958.08s → 1962.72s] he's he's famously and i read you know\n",
            "[1960.32s → 1965.12s] emperors of new mind and and um\n",
            "[1962.72s → 1966.56s] and his books uh his classical books uh\n",
            "[1965.12s → 1968.88s] and they they were pretty influential\n",
            "[1966.56s → 1970.56s] and you know in the 90s and um he\n",
            "[1968.88s → 1973.04s] believes that there's something more you\n",
            "[1970.56s → 1975.92s] know something quantum that is needed to\n",
            "[1973.04s → 1977.68s] explain consciousness in the brain um i\n",
            "[1975.92s → 1979.68s] think about what we're doing actually at\n",
            "[1977.68s → 1981.92s] deepmind and what my career is being\n",
            "[1979.68s → 1983.60s] we're almost like true rings champion so\n",
            "[1981.92s → 1986.08s] we are pushing turing machines or\n",
            "[1983.60s → 1988.00s] classical computation to the limits what\n",
            "[1986.08s → 1991.04s] are the limits of what classical\n",
            "[1988.00s → 1993.68s] computing can do now um and at the same\n",
            "[1991.04s → 1995.52s] time i've also studied neuroscience to\n",
            "[1993.68s → 1997.84s] see and that's why i did my phd in was\n",
            "[1995.52s → 1999.28s] to see also to look at you know is there\n",
            "[1997.84s → 2001.12s] anything quantum in the brain from a\n",
            "[1999.28s → 2003.60s] neuroscience or biological perspective\n",
            "[2001.12s → 2005.04s] and um and so far i think most\n",
            "[2003.60s → 2006.56s] neuroscientists and most mainstream\n",
            "[2005.04s → 2008.80s] biologists and neuroscientists would say\n",
            "[2006.56s → 2010.88s] there's no evidence of any quantum uh\n",
            "[2008.80s → 2012.48s] systems or effects in the brain as far\n",
            "[2010.88s → 2014.96s] as we can see it's it can be mostly\n",
            "[2012.48s → 2017.04s] explained by classical uh classical\n",
            "[2014.96s → 2018.88s] theories so\n",
            "[2017.04s → 2021.12s] and then so there's sort of the the\n",
            "[2018.88s → 2023.20s] search from the biology side and then at\n",
            "[2021.12s → 2025.92s] the same time there's the raising of the\n",
            "[2023.20s → 2028.88s] water uh at the bar from what classical\n",
            "[2025.92s → 2030.72s] turing machines can do uh uh and\n",
            "[2028.88s → 2034.00s] and you know including our new ai\n",
            "[2030.72s → 2036.40s] systems and uh as you alluded to earlier\n",
            "[2034.00s → 2039.12s] um you know i think ai especially in the\n",
            "[2036.40s → 2042.32s] last decade plus has been a continual\n",
            "[2039.12s → 2044.72s] story now of surprising uh events uh and\n",
            "[2042.32s → 2046.40s] surprising successes knocking over one\n",
            "[2044.72s → 2048.48s] theory after another of what was thought\n",
            "[2046.40s → 2051.52s] to be impossible you know from go to\n",
            "[2048.48s → 2052.48s] protein folding and so on and so i think\n",
            "[2051.52s → 2056.08s] um\n",
            "[2052.48s → 2059.44s] i would be very hesitant to bet against\n",
            "[2056.08s → 2062.64s] how far the uh universal turing machine\n",
            "[2059.44s → 2065.28s] and classical computation paradigm can\n",
            "[2062.64s → 2067.76s] go and and my betting would be\n",
            "[2065.28s → 2070.88s] that all of certainly what's going on in\n",
            "[2067.76s → 2073.36s] our brain uh can probably be mimicked or\n",
            "[2070.88s → 2075.92s] or approximated on a on a classical\n",
            "[2073.36s → 2078.48s] machine um not you know not requiring\n",
            "[2075.92s → 2080.24s] something metaphysical or quantum and\n",
            "[2078.48s → 2081.68s] we'll get there with some of the work\n",
            "[2080.24s → 2084.40s] with alpha fold\n",
            "[2081.68s → 2086.40s] which i think begins the journey of\n",
            "[2084.40s → 2088.80s] modeling this beautiful and complex\n",
            "[2086.40s → 2091.28s] world of biology so you think all the\n",
            "[2088.80s → 2094.16s] magic of the human mind comes from this\n",
            "[2091.28s → 2097.36s] just a few pounds of mush\n",
            "[2094.16s → 2098.24s] of a biological computational mush\n",
            "[2097.36s → 2101.44s] that's\n",
            "[2098.24s → 2104.48s] akin to some of the neural networks\n",
            "[2101.44s → 2106.56s] not directly but in spirit that deep\n",
            "[2104.48s → 2108.32s] mind has been working with well look i\n",
            "[2106.56s → 2109.92s] think it's um you say it's a few you\n",
            "[2108.32s → 2111.60s] know of course it's this is the i think\n",
            "[2109.92s → 2114.08s] the biggest miracle of the universe is\n",
            "[2111.60s → 2116.24s] that um it is just a few pounds of mush\n",
            "[2114.08s → 2118.08s] in our skulls and yet it's also our\n",
            "[2116.24s → 2120.16s] brains are the most complex objects in\n",
            "[2118.08s → 2121.68s] the in that we know of in the universe\n",
            "[2120.16s → 2123.84s] so there's something profoundly\n",
            "[2121.68s → 2124.64s] beautiful and amazing about our brains\n",
            "[2123.84s → 2125.52s] and\n",
            "[2124.64s → 2128.56s] i\n",
            "[2125.52s → 2132.00s] think that it's an incredibly uh\n",
            "[2128.56s → 2132.80s] incredible efficient machine and and uh\n",
            "[2132.00s → 2134.56s] uh\n",
            "[2132.80s → 2137.28s] and it's a is you know phenomenal\n",
            "[2134.56s → 2138.80s] basically and i think that building ai\n",
            "[2137.28s → 2140.96s] one of the reasons i want to build ai\n",
            "[2138.80s → 2143.68s] and i've always wanted to is i think by\n",
            "[2140.96s → 2145.92s] building an intelligent artifact like ai\n",
            "[2143.68s → 2148.72s] and then comparing it to the human mind\n",
            "[2145.92s → 2150.56s] um that will help us unlock the\n",
            "[2148.72s → 2152.00s] uniqueness and the true secrets of the\n",
            "[2150.56s → 2153.60s] mind that we've always wondered about\n",
            "[2152.00s → 2158.08s] since the dawn of history like\n",
            "[2153.60s → 2160.64s] consciousness dreaming uh creativity uh\n",
            "[2158.08s → 2162.48s] emotions what are all these things right\n",
            "[2160.64s → 2164.96s] we've we've wondered about them since\n",
            "[2162.48s → 2166.48s] since the dawn of humanity and i think\n",
            "[2164.96s → 2169.04s] one of the reasons and you know i love\n",
            "[2166.48s → 2170.56s] philosophy and philosophy of mind is we\n",
            "[2169.04s → 2172.24s] found it difficult is there haven't been\n",
            "[2170.56s → 2174.56s] the tools for us to really other than\n",
            "[2172.24s → 2177.04s] introspection to from very clever people\n",
            "[2174.56s → 2178.32s] in in history very clever philosophers\n",
            "[2177.04s → 2180.64s] to really investigate this\n",
            "[2178.32s → 2182.24s] scientifically but now suddenly we have\n",
            "[2180.64s → 2183.92s] a plethora of tools firstly we have all\n",
            "[2182.24s → 2185.68s] the neuroscience tools fmri machines\n",
            "[2183.92s → 2188.08s] single cell recording all of this stuff\n",
            "[2185.68s → 2191.52s] but we also have the ability computers\n",
            "[2188.08s → 2193.36s] and ai to build uh intelligent systems\n",
            "[2191.52s → 2194.24s] so i think that um\n",
            "[2193.36s → 2195.92s] uh\n",
            "[2194.24s → 2199.92s] you know i think it is amazing what the\n",
            "[2195.92s → 2202.00s] human mind does and um and and i'm kind\n",
            "[2199.92s → 2204.00s] of in awe of it really and uh and i\n",
            "[2202.00s → 2205.60s] think it's amazing that without human\n",
            "[2204.00s → 2208.16s] minds we're able to build things like\n",
            "[2205.60s → 2209.44s] computers and and actually even you know\n",
            "[2208.16s → 2210.48s] think and investigate about these\n",
            "[2209.44s → 2213.36s] questions i think that's also a\n",
            "[2210.48s → 2216.56s] testament to the human mind yeah the\n",
            "[2213.36s → 2218.64s] universe built the human mind that now\n",
            "[2216.56s → 2220.64s] is building computers that help\n",
            "[2218.64s → 2222.64s] us understand both the universe and our\n",
            "[2220.64s → 2224.00s] own human mind right that's exactly it i\n",
            "[2222.64s → 2225.68s] mean i think that's one you know one\n",
            "[2224.00s → 2227.60s] could say we we are\n",
            "[2225.68s → 2229.12s] maybe we're the mechanism by which the\n",
            "[2227.60s → 2232.08s] universe is going to try and understand\n",
            "[2229.12s → 2232.08s] itself yeah\n",
            "[2232.32s → 2237.20s] it's beautiful so let's let's go to the\n",
            "[2234.96s → 2238.16s] basic building blocks of biology that i\n",
            "[2237.20s → 2240.00s] think\n",
            "[2238.16s → 2241.68s] is another angle at which you can start\n",
            "[2240.00s → 2244.48s] to understand the human mind the human\n",
            "[2241.68s → 2246.96s] body which is quite fascinating which is\n",
            "[2244.48s → 2248.96s] from the basic building blocks start to\n",
            "[2246.96s → 2250.64s] simulate start to model\n",
            "[2248.96s → 2252.40s] how from those building blocks you can\n",
            "[2250.64s → 2254.32s] construct bigger and bigger more complex\n",
            "[2252.40s → 2257.12s] systems maybe one day the entirety of\n",
            "[2254.32s → 2259.76s] the human biology so\n",
            "[2257.12s → 2261.76s] here's another problem that thought to\n",
            "[2259.76s → 2265.20s] be impossible to solve which is protein\n",
            "[2261.76s → 2267.60s] folding and alpha fold or\n",
            "[2265.20s → 2270.16s] specific alpha fold 2\n",
            "[2267.60s → 2271.20s] did just that it solved protein folding\n",
            "[2270.16s → 2273.04s] i think it's one of the biggest\n",
            "[2271.20s → 2274.08s] breakthroughs\n",
            "[2273.04s → 2276.88s] uh certainly in the history of\n",
            "[2274.08s → 2278.80s] structural biology but uh in general in\n",
            "[2276.88s → 2280.08s] in science\n",
            "[2278.80s → 2282.16s] um\n",
            "[2280.08s → 2284.72s] maybe from a high level\n",
            "[2282.16s → 2287.12s] what is it and how does it work\n",
            "[2284.72s → 2290.40s] and then we can ask some fascinating\n",
            "[2287.12s → 2292.40s] sure questions after sure um so maybe\n",
            "[2290.40s → 2293.92s] like to explain it uh to people not\n",
            "[2292.40s → 2295.68s] familiar with protein folding is you\n",
            "[2293.92s → 2297.76s] know i first of all explain proteins\n",
            "[2295.68s → 2300.16s] which is you know proteins are essential\n",
            "[2297.76s → 2302.00s] to all life every function in your body\n",
            "[2300.16s → 2304.08s] depends on proteins sometimes they're\n",
            "[2302.00s → 2305.20s] called the workhorses of biology and if\n",
            "[2304.08s → 2306.72s] you look into them and i've you know\n",
            "[2305.20s → 2309.28s] obviously as part of alpha fold i've\n",
            "[2306.72s → 2310.72s] been researching proteins and and\n",
            "[2309.28s → 2313.12s] structural biology for the last few\n",
            "[2310.72s → 2314.72s] years you know they're amazing little\n",
            "[2313.12s → 2316.00s] bio nano machines proteins they're\n",
            "[2314.72s → 2317.68s] incredible if you actually watch little\n",
            "[2316.00s → 2318.88s] videos of how they work animations of\n",
            "[2317.68s → 2321.36s] how they work\n",
            "[2318.88s → 2323.44s] and um proteins are specified by their\n",
            "[2321.36s → 2325.36s] genetic sequence called the amino acid\n",
            "[2323.44s → 2328.96s] sequence so you can think of those their\n",
            "[2325.36s → 2331.36s] genetic makeup and then in the body uh\n",
            "[2328.96s → 2333.52s] in in nature they when they when they\n",
            "[2331.36s → 2335.28s] fold up into a 3d structure so you can\n",
            "[2333.52s → 2337.36s] think of it as a string of beads and\n",
            "[2335.28s → 2339.28s] then they fold up into a ball now the\n",
            "[2337.36s → 2340.96s] key thing is you want to know what that\n",
            "[2339.28s → 2343.12s] 3d structure is\n",
            "[2340.96s → 2344.40s] because the structure the 3d structure\n",
            "[2343.12s → 2346.32s] of a protein\n",
            "[2344.40s → 2348.56s] is what helps to determine what does it\n",
            "[2346.32s → 2350.24s] do the function it does in your body\n",
            "[2348.56s → 2352.88s] and also if you're interested in drug\n",
            "[2350.24s → 2354.80s] drugs or disease you need to understand\n",
            "[2352.88s → 2357.12s] that 3d structure because if you want to\n",
            "[2354.80s → 2358.64s] target something with a drug compound or\n",
            "[2357.12s → 2360.56s] about to block that something the\n",
            "[2358.64s → 2362.00s] protein is doing uh you need to\n",
            "[2360.56s → 2364.00s] understand where it's going to bind on\n",
            "[2362.00s → 2365.36s] the surface of the protein so obviously\n",
            "[2364.00s → 2366.80s] in order to do that you need to\n",
            "[2365.36s → 2368.48s] understand the 3d structure so the\n",
            "[2366.80s → 2369.76s] structure is mapped to the function the\n",
            "[2368.48s → 2371.68s] structure is mapped to the function and\n",
            "[2369.76s → 2374.00s] the structure is obviously somehow\n",
            "[2371.68s → 2375.76s] specified by the by the amino acid\n",
            "[2374.00s → 2378.00s] sequence and that's the in essence the\n",
            "[2375.76s → 2379.60s] protein folding problem is can you just\n",
            "[2378.00s → 2381.04s] from the amino acid sequence the\n",
            "[2379.60s → 2383.60s] one-dimensional\n",
            "[2381.04s → 2385.60s] string of letters can you\n",
            "[2383.60s → 2388.72s] immediately computationally predict the\n",
            "[2385.60s → 2390.72s] 3d structure right and this has been a\n",
            "[2388.72s → 2392.32s] grand challenge in biology for over 50\n",
            "[2390.72s → 2394.32s] years so i think it was first\n",
            "[2392.32s → 2397.44s] articulated by christian anfinsen a\n",
            "[2394.32s → 2399.36s] nobel prize winner in 1972 uh as part of\n",
            "[2397.44s → 2401.76s] his nobel prize winning lecture and he\n",
            "[2399.36s → 2404.00s] just speculated this should be possible\n",
            "[2401.76s → 2406.72s] to go from the amino acid sequence to\n",
            "[2404.00s → 2408.80s] the 3d structure we didn't say how so\n",
            "[2406.72s → 2411.20s] i you know it's been described to me as\n",
            "[2408.80s → 2413.60s] equivalent to fermat's last theorem but\n",
            "[2411.20s → 2415.36s] for biology right you should as somebody\n",
            "[2413.60s → 2418.40s] that uh very well might win the nobel\n",
            "[2415.36s → 2419.84s] prize in the future but outside of that\n",
            "[2418.40s → 2422.00s] you should do more of that kind of thing\n",
            "[2419.84s → 2424.32s] in the margins just put random things\n",
            "[2422.00s → 2426.24s] that will take like 200 years to solve\n",
            "[2424.32s → 2428.32s] set people off for 200 years it should\n",
            "[2426.24s → 2430.00s] be possible exactly and just don't give\n",
            "[2428.32s → 2432.24s] any interest exactly i think everyone's\n",
            "[2430.00s → 2434.48s] exactly should be i'll have to remember\n",
            "[2432.24s → 2436.16s] that for future so yeah so he set off\n",
            "[2434.48s → 2438.32s] you know with this one throwaway remark\n",
            "[2436.16s → 2440.48s] just like fermat you know he he set off\n",
            "[2438.32s → 2443.36s] this whole 50-year uh\n",
            "[2440.48s → 2445.44s] uh uh field really of computational\n",
            "[2443.36s → 2447.28s] biology and and they had you know they\n",
            "[2445.44s → 2450.80s] got stuck they hadn't really got very\n",
            "[2447.28s → 2452.88s] far with doing this and and um until now\n",
            "[2450.80s → 2455.44s] until alpha fold came along this is done\n",
            "[2452.88s → 2456.96s] experimentally right very painstakingly\n",
            "[2455.44s → 2458.88s] so the rule of thumb is and you have to\n",
            "[2456.96s → 2460.88s] like crystallize the protein which is\n",
            "[2458.88s → 2463.04s] really difficult some proteins can't be\n",
            "[2460.88s → 2464.64s] crystallized like membrane proteins and\n",
            "[2463.04s → 2466.56s] then you have to use very expensive\n",
            "[2464.64s → 2468.48s] electron microscopes or x-ray\n",
            "[2466.56s → 2470.56s] crystallography machines really\n",
            "[2468.48s → 2472.56s] painstaking work to get the 3d structure\n",
            "[2470.56s → 2474.72s] and visualize the 3d structure so the\n",
            "[2472.56s → 2476.96s] rule of thumb in in experimental biology\n",
            "[2474.72s → 2480.64s] is that it takes one phd student their\n",
            "[2476.96s → 2483.28s] entire phd to do one protein uh and with\n",
            "[2480.64s → 2485.92s] alpha fold two we were able to predict\n",
            "[2483.28s → 2487.92s] the 3d structure in a matter of seconds\n",
            "[2485.92s → 2489.52s] um and so we were you know over\n",
            "[2487.92s → 2491.28s] christmas we did the whole human\n",
            "[2489.52s → 2493.60s] proteome or every protein in the human\n",
            "[2491.28s → 2494.80s] body all 20 000 proteins so the human\n",
            "[2493.60s → 2498.40s] proteins like the equivalent of the\n",
            "[2494.80s → 2500.80s] human genome but on protein space and uh\n",
            "[2498.40s → 2503.52s] and sort of revolutionize really what uh\n",
            "[2500.80s → 2505.92s] a structural biologist can do because\n",
            "[2503.52s → 2507.84s] now um they don't have to worry about\n",
            "[2505.92s → 2509.28s] these painstaking experimentals you know\n",
            "[2507.84s → 2510.64s] should they put all of that effort in or\n",
            "[2509.28s → 2511.76s] not they can almost just look up the\n",
            "[2510.64s → 2513.12s] structure of their proteins like a\n",
            "[2511.76s → 2516.08s] google search\n",
            "[2513.12s → 2518.40s] and so there's a data set on which it's\n",
            "[2516.08s → 2519.60s] trained and how to map this amino acids\n",
            "[2518.40s → 2521.44s] because first of all it's incredible\n",
            "[2519.60s → 2523.12s] that a protein this little chemical\n",
            "[2521.44s → 2525.60s] computer is able to do that computation\n",
            "[2523.12s → 2527.68s] itself in some kind of distributed way\n",
            "[2525.60s → 2529.44s] and do it very quickly\n",
            "[2527.68s → 2530.48s] that's a weird thing and they evolved\n",
            "[2529.44s → 2531.52s] that way because you know in the\n",
            "[2530.48s → 2533.36s] beginning\n",
            "[2531.52s → 2535.92s] i mean that's a great invention just the\n",
            "[2533.36s → 2538.80s] protein itself yes i mean and then they\n",
            "[2535.92s → 2541.04s] there's i think probably a history of\n",
            "[2538.80s → 2542.96s] like uh they evolved\n",
            "[2541.04s → 2545.28s] to have many of these proteins and those\n",
            "[2542.96s → 2546.48s] proteins figure out how to be computers\n",
            "[2545.28s → 2547.92s] themselves\n",
            "[2546.48s → 2549.20s] in such a way that you can create\n",
            "[2547.92s → 2550.88s] structures that can interact in\n",
            "[2549.20s → 2552.96s] complexes with each other in order to\n",
            "[2550.88s → 2555.36s] form high level functions i mean it's a\n",
            "[2552.96s → 2557.04s] weird system that they figured it out\n",
            "[2555.36s → 2558.64s] well for sure i mean we you know maybe\n",
            "[2557.04s → 2560.32s] we should talk about the origins of life\n",
            "[2558.64s → 2563.76s] too but proteins themselves i think are\n",
            "[2560.32s → 2565.92s] magical and incredible uh uh uh as i\n",
            "[2563.76s → 2566.80s] said little little bio-nano machines and\n",
            "[2565.92s → 2569.52s] um\n",
            "[2566.80s → 2571.84s] and and actually levantal who is another\n",
            "[2569.52s → 2574.80s] scientist uh uh a contemporary of\n",
            "[2571.84s → 2576.16s] anfinsen uh he he coined this eleventh\n",
            "[2574.80s → 2577.92s] house what became known as levantal's\n",
            "[2576.16s → 2580.24s] paradox which is exactly what you're\n",
            "[2577.92s → 2582.64s] saying he calculated roughly a protein\n",
            "[2580.24s → 2583.92s] an average protein which is maybe 2 000\n",
            "[2582.64s → 2586.24s] amino acids\n",
            "[2583.92s → 2588.96s] bases long is um\n",
            "[2586.24s → 2591.60s] is is can fold in maybe 10 to the power\n",
            "[2588.96s → 2593.36s] 300 different conformations so there's\n",
            "[2591.60s → 2595.92s] 10 to the power 300 different ways that\n",
            "[2593.36s → 2598.96s] protein could fold up and yet somehow in\n",
            "[2595.92s → 2601.04s] nature physics solves this solves this\n",
            "[2598.96s → 2602.96s] in a matter of milliseconds so proteins\n",
            "[2601.04s → 2606.48s] fold up in your body in you know\n",
            "[2602.96s → 2608.56s] sometimes in fractions of a second so\n",
            "[2606.48s → 2610.48s] physics is somehow solving that search\n",
            "[2608.56s → 2612.16s] problem and just to be clear in many of\n",
            "[2610.48s → 2615.36s] these cases maybe you correct me if i'm\n",
            "[2612.16s → 2618.08s] wrong there's often a unique way\n",
            "[2615.36s → 2620.88s] for that sequence to form itself yes so\n",
            "[2618.08s → 2622.56s] among that huge number of possibilities\n",
            "[2620.88s → 2624.16s] yes it figures out a way how to\n",
            "[2622.56s → 2625.20s] stability\n",
            "[2624.16s → 2626.40s] uh\n",
            "[2625.20s → 2628.72s] in some cases there might be a\n",
            "[2626.40s → 2630.08s] misfunction so on which leads to a lot\n",
            "[2628.72s → 2631.92s] of the disorders and stuff like that but\n",
            "[2630.08s → 2633.92s] yes most of the time it's a unique\n",
            "[2631.92s → 2636.32s] mapping and that unique mapping is not\n",
            "[2633.92s → 2638.32s] obvious no exactly that's just what the\n",
            "[2636.32s → 2641.12s] problem is exactly so there's a unique\n",
            "[2638.32s → 2643.92s] mapping usually in a healthy in if it's\n",
            "[2641.12s → 2646.16s] healthy and as you say in disease\n",
            "[2643.92s → 2647.68s] so for example alzheimer's one one one\n",
            "[2646.16s → 2649.76s] conjecture is that it's because of a\n",
            "[2647.68s → 2652.64s] misfolded protein a protein that folds\n",
            "[2649.76s → 2654.08s] in the wrong way amyloid beta protein so\n",
            "[2652.64s → 2655.92s] um and then because it falls in the\n",
            "[2654.08s → 2658.24s] wrong way it gets tangled up right in\n",
            "[2655.92s → 2660.48s] your in your neurons so\n",
            "[2658.24s → 2663.04s] um it's super important to understand\n",
            "[2660.48s → 2665.12s] both healthy functioning and also\n",
            "[2663.04s → 2666.56s] disease is to understand uh you know\n",
            "[2665.12s → 2668.16s] what what these things are doing and how\n",
            "[2666.56s → 2670.40s] they're structuring of course the next\n",
            "[2668.16s → 2672.80s] step is sometimes proteins change shape\n",
            "[2670.40s → 2674.96s] when they interact with something so um\n",
            "[2672.80s → 2677.12s] they're not just static necessarily in\n",
            "[2674.96s → 2679.84s] in biology\n",
            "[2677.12s → 2682.40s] maybe you can give some interesting sort\n",
            "[2679.84s → 2685.52s] of beautiful things to you about these\n",
            "[2682.40s → 2686.96s] early days of alpha fold of of solving\n",
            "[2685.52s → 2688.88s] this problem because\n",
            "[2686.96s → 2692.40s] unlike games this is\n",
            "[2688.88s → 2693.92s] real physical systems that are less\n",
            "[2692.40s → 2696.24s] amenable to\n",
            "[2693.92s → 2698.32s] self-play type of mechanisms\n",
            "[2696.24s → 2699.76s] the the size of the data set is smaller\n",
            "[2698.32s → 2701.28s] that you might otherwise like so you\n",
            "[2699.76s → 2702.40s] have to be very clever about certain\n",
            "[2701.28s → 2704.72s] things is there something you could\n",
            "[2702.40s → 2707.12s] speak to um\n",
            "[2704.72s → 2709.04s] what was very hard to solve and what are\n",
            "[2707.12s → 2711.76s] some beautiful aspects about the the\n",
            "[2709.04s → 2713.68s] solution yeah i would say alpha fold is\n",
            "[2711.76s → 2716.00s] the most complex and also probably most\n",
            "[2713.68s → 2717.68s] meaningful system we've built so far so\n",
            "[2716.00s → 2719.60s] it's been an amazing time actually in\n",
            "[2717.68s → 2722.08s] the last you know two three years to see\n",
            "[2719.60s → 2723.52s] that come through because um as we\n",
            "[2722.08s → 2725.92s] talked about earlier you know games is\n",
            "[2723.52s → 2728.32s] what we started on uh building things\n",
            "[2725.92s → 2730.72s] like alphago and alpha zero but really\n",
            "[2728.32s → 2733.04s] the ultimate goal was to um not just to\n",
            "[2730.72s → 2734.80s] crack games it was just to to to build\n",
            "[2733.04s → 2736.40s] use them to bootstrap general learning\n",
            "[2734.80s → 2739.04s] systems we could then apply to real\n",
            "[2736.40s → 2741.20s] world challenges specifically my passion\n",
            "[2739.04s → 2743.28s] is scientific challenges like protein\n",
            "[2741.20s → 2746.24s] folding and then alpha fold of course is\n",
            "[2743.28s → 2749.04s] our first big proof point of that and so\n",
            "[2746.24s → 2750.40s] um you know in terms of the data uh and\n",
            "[2749.04s → 2752.40s] the amount of innovations that had to go\n",
            "[2750.40s → 2754.32s] into it we you know it was like more\n",
            "[2752.40s → 2756.16s] than 30 different component algorithms\n",
            "[2754.32s → 2758.40s] needed to be put together to crack the\n",
            "[2756.16s → 2760.72s] protein folding um i think some of the\n",
            "[2758.40s → 2763.20s] big innovations were that um\n",
            "[2760.72s → 2765.68s] kind of building in some hard coded\n",
            "[2763.20s → 2768.56s] constraints around physics and\n",
            "[2765.68s → 2771.20s] evolutionary biology um to constrain\n",
            "[2768.56s → 2773.28s] sort of things like the bond angles uh\n",
            "[2771.20s → 2775.28s] uh in the in the in the protein and\n",
            "[2773.28s → 2777.28s] things like that um\n",
            "[2775.28s → 2779.84s] a lot but not to impact the learning\n",
            "[2777.28s → 2782.48s] system so still allowing uh the system\n",
            "[2779.84s → 2785.36s] to be able to learn the physics uh\n",
            "[2782.48s → 2786.72s] itself um from the examples that we had\n",
            "[2785.36s → 2789.20s] and the examples as you say there are\n",
            "[2786.72s → 2791.28s] only about 150 000 proteins even after\n",
            "[2789.20s → 2793.84s] 40 years of experimental biology only\n",
            "[2791.28s → 2795.92s] around 150 000 proteins have been the\n",
            "[2793.84s → 2798.16s] structures have been found out about so\n",
            "[2795.92s → 2800.08s] that was our training set which is um\n",
            "[2798.16s → 2800.96s] much less than normally we would like to\n",
            "[2800.08s → 2802.64s] use\n",
            "[2800.96s → 2805.84s] but using various tricks things like\n",
            "[2802.64s → 2808.48s] self distillation so actually using\n",
            "[2805.84s → 2810.00s] alpha folds predictions um some of the\n",
            "[2808.48s → 2811.68s] best predictions that it thought was\n",
            "[2810.00s → 2813.68s] highly confident in we put them back\n",
            "[2811.68s → 2815.28s] into the training set right to make the\n",
            "[2813.68s → 2817.60s] training set bigger\n",
            "[2815.28s → 2819.68s] that was critical to to alpha fold\n",
            "[2817.60s → 2822.24s] working so there was actually a huge\n",
            "[2819.68s → 2824.24s] number of different um uh innovations\n",
            "[2822.24s → 2826.56s] like that that were required to to\n",
            "[2824.24s → 2829.92s] ultimately crack the problem after fold\n",
            "[2826.56s → 2831.36s] one what it produced was a distagram so\n",
            "[2829.92s → 2833.52s] a kind of\n",
            "[2831.36s → 2836.32s] a matrix of the pairwise distances\n",
            "[2833.52s → 2838.48s] between all of the molecules in the in\n",
            "[2836.32s → 2841.84s] the in the protein and then there had to\n",
            "[2838.48s → 2843.68s] be a separate optimization process to uh\n",
            "[2841.84s → 2845.36s] create the 3d structure\n",
            "[2843.68s → 2847.68s] and what we did for alpha volt2 is make\n",
            "[2845.36s → 2850.80s] it truly end to end so we went straight\n",
            "[2847.68s → 2852.48s] from the amino acid sequence of of of\n",
            "[2850.80s → 2854.32s] bases to\n",
            "[2852.48s → 2856.24s] the 3d structure directly without going\n",
            "[2854.32s → 2858.24s] through this intermediate step and in\n",
            "[2856.24s → 2860.40s] machine learning what we've always found\n",
            "[2858.24s → 2862.40s] is that the more end to end you can make\n",
            "[2860.40s → 2865.68s] it the better the system and it's\n",
            "[2862.40s → 2867.36s] probably because um we you know the in\n",
            "[2865.68s → 2869.36s] the end the system is better at learning\n",
            "[2867.36s → 2871.36s] what the constraints are than than we\n",
            "[2869.36s → 2873.60s] are as the human designers of specifying\n",
            "[2871.36s → 2875.12s] it so anytime you can let it flow end to\n",
            "[2873.60s → 2876.64s] end and actually just generate what it\n",
            "[2875.12s → 2878.96s] is you're really looking for in this\n",
            "[2876.64s → 2880.56s] case the 3d structure you're better off\n",
            "[2878.96s → 2882.24s] than having this intermediate step which\n",
            "[2880.56s → 2884.08s] you then have to hand craft the next\n",
            "[2882.24s → 2885.44s] step for so\n",
            "[2884.08s → 2887.04s] so it's better to let the gradients and\n",
            "[2885.44s → 2889.12s] the learning flow all the way through\n",
            "[2887.04s → 2890.96s] the system um from the end point the end\n",
            "[2889.12s → 2892.88s] output you want to the inputs so that's\n",
            "[2890.96s → 2894.80s] a good way to start a new problem\n",
            "[2892.88s → 2897.12s] handcraft a bunch of stuff add a bunch\n",
            "[2894.80s → 2899.28s] of manual constraints with a small\n",
            "[2897.12s → 2901.12s] intent learning piece or a small\n",
            "[2899.28s → 2902.80s] learning piece and grow that learning\n",
            "[2901.12s → 2905.04s] piece until it consumes the whole thing\n",
            "[2902.80s → 2906.40s] that's right and so you can also see you\n",
            "[2905.04s → 2908.40s] know this is a bit of a method we've\n",
            "[2906.40s → 2910.56s] developed over doing many sort of\n",
            "[2908.40s → 2913.28s] successful outfits we call them alpha x\n",
            "[2910.56s → 2915.52s] projects right is and the easiest way to\n",
            "[2913.28s → 2919.12s] see that is the evolution of alphago to\n",
            "[2915.52s → 2920.64s] alpha zero so alphago was um a learning\n",
            "[2919.12s → 2923.44s] system but it was specifically trained\n",
            "[2920.64s → 2925.44s] to only play go right so uh and what we\n",
            "[2923.44s → 2927.36s] wanted to do with first version of go is\n",
            "[2925.44s → 2929.44s] just get to world champion performance\n",
            "[2927.36s → 2932.16s] no matter how we did it right and then\n",
            "[2929.44s → 2934.24s] and then of course alphago zero we we we\n",
            "[2932.16s → 2936.40s] removed the need to use human games as a\n",
            "[2934.24s → 2939.12s] starting point right so it could just\n",
            "[2936.40s → 2940.72s] play against itself from random starting\n",
            "[2939.12s → 2942.64s] point from the beginning so that removed\n",
            "[2940.72s → 2944.96s] the the need for human knowledge uh\n",
            "[2942.64s → 2947.20s] about go and then finally alpha zero\n",
            "[2944.96s → 2949.20s] then generalized it so that any things\n",
            "[2947.20s → 2951.28s] we had in there the system including\n",
            "[2949.20s → 2953.20s] things like symmetry of the go board uh\n",
            "[2951.28s → 2955.44s] were removed so the alpha zero could\n",
            "[2953.20s → 2957.52s] play from scratch any two player game\n",
            "[2955.44s → 2959.68s] and then mu0 which is the final\n",
            "[2957.52s → 2961.28s] latest version of that set of things was\n",
            "[2959.68s → 2962.56s] then extending it so that you didn't\n",
            "[2961.28s → 2964.88s] even have to give it the rules of the\n",
            "[2962.56s → 2966.48s] game it would learn that for itself so\n",
            "[2964.88s → 2968.32s] it could also deal with computer games\n",
            "[2966.48s → 2971.68s] as well as board games so that line of\n",
            "[2968.32s → 2973.68s] alpha golf goes zero alpha zero mu zero\n",
            "[2971.68s → 2975.12s] that's the full trajectory of what you\n",
            "[2973.68s → 2977.12s] can take from\n",
            "[2975.12s → 2979.28s] uh imitation learning\n",
            "[2977.12s → 2981.68s] to full self\n",
            "[2979.28s → 2984.00s] supervised learning yeah exactly and\n",
            "[2981.68s → 2986.24s] learning learning uh the entire\n",
            "[2984.00s → 2988.56s] structure of the environment you put in\n",
            "[2986.24s → 2991.04s] from scratch right and and and and\n",
            "[2988.56s → 2992.48s] bootstrapping it uh through self-play uh\n",
            "[2991.04s → 2994.48s] yourself but the thing is it would have\n",
            "[2992.48s → 2997.44s] been impossible i think or very hard for\n",
            "[2994.48s → 2998.48s] us to build alpha zero or mu0 first out\n",
            "[2997.44s → 3000.88s] of the box\n",
            "[2998.48s → 3003.12s] even psychologically because you have to\n",
            "[3000.88s → 3004.48s] believe in yourself for a very long time\n",
            "[3003.12s → 3005.92s] you're constantly dealing with doubt\n",
            "[3004.48s → 3007.84s] because a lot of people say that it's\n",
            "[3005.92s → 3009.12s] impossible exactly so it was hard enough\n",
            "[3007.84s → 3010.96s] just to do go as you were saying\n",
            "[3009.12s → 3013.20s] everyone thought that was impossible or\n",
            "[3010.96s → 3016.00s] at least a decade away um from when we\n",
            "[3013.20s → 3018.56s] when we did it back in 2015 24 you know\n",
            "[3016.00s → 3020.08s] 2016 and um\n",
            "[3018.56s → 3021.92s] and so yes it would have been\n",
            "[3020.08s → 3023.60s] psychologically probably very difficult\n",
            "[3021.92s → 3026.24s] as well as the fact that of course we\n",
            "[3023.60s → 3028.08s] learnt a lot by building alphago first\n",
            "[3026.24s → 3030.08s] right so it's i think this is why i call\n",
            "[3028.08s → 3032.08s] ai in engineering science it's one of\n",
            "[3030.08s → 3033.68s] the most fascinating science disciplines\n",
            "[3032.08s → 3036.16s] but it's also an engineering science in\n",
            "[3033.68s → 3038.16s] the sense that unlike natural sciences\n",
            "[3036.16s → 3039.76s] um the phenomenon you're studying it\n",
            "[3038.16s → 3041.44s] doesn't exist out in nature you have to\n",
            "[3039.76s → 3043.60s] build it first so you have to build the\n",
            "[3041.44s → 3045.68s] artifact first and then you can study\n",
            "[3043.60s → 3049.04s] how how and pull it apart and how it\n",
            "[3045.68s → 3050.16s] works this is tough to uh\n",
            "[3049.04s → 3051.92s] ask you this question because you\n",
            "[3050.16s → 3054.08s] probably will say it's everything but\n",
            "[3051.92s → 3055.04s] let's let's try let's try to think to\n",
            "[3054.08s → 3057.20s] this because you're in a very\n",
            "[3055.04s → 3058.88s] interesting position where deepmind is\n",
            "[3057.20s → 3061.76s] the place of some of the most uh\n",
            "[3058.88s → 3063.52s] brilliant ideas in the history of ai but\n",
            "[3061.76s → 3065.76s] it's also a place of brilliant\n",
            "[3063.52s → 3068.16s] engineering\n",
            "[3065.76s → 3071.36s] so how much of solving intelligence this\n",
            "[3068.16s → 3073.52s] big goal for deepmind how much of it is\n",
            "[3071.36s → 3075.20s] science how much is engineering so how\n",
            "[3073.52s → 3077.44s] much is the algorithms how much is the\n",
            "[3075.20s → 3080.00s] data how much is the\n",
            "[3077.44s → 3081.68s] hardware compute infrastructure how much\n",
            "[3080.00s → 3084.32s] is it the software computer\n",
            "[3081.68s → 3085.68s] infrastructure yeah um what else is\n",
            "[3084.32s → 3087.12s] there how much is the human\n",
            "[3085.68s → 3089.20s] infrastructure\n",
            "[3087.12s → 3090.80s] and like just the humans interact in\n",
            "[3089.20s → 3092.40s] certain kinds of ways in all the space\n",
            "[3090.80s → 3095.04s] of all those ideas how much does maybe\n",
            "[3092.40s → 3097.04s] like philosophy how much what's the key\n",
            "[3095.04s → 3098.08s] if um\n",
            "[3097.04s → 3100.80s] uh\n",
            "[3098.08s → 3103.04s] if if you were to sort of look back like\n",
            "[3100.80s → 3105.04s] if we go forward 200 years look back\n",
            "[3103.04s → 3107.68s] what was the key thing that solved\n",
            "[3105.04s → 3109.36s] intelligence is that ideas\n",
            "[3107.68s → 3110.72s] i think it's a combination first of all\n",
            "[3109.36s → 3112.64s] of course it's a combination of all\n",
            "[3110.72s → 3114.72s] those things but the the ratios of them\n",
            "[3112.64s → 3117.28s] changed over over time\n",
            "[3114.72s → 3119.60s] so yeah so um even in the last 12 years\n",
            "[3117.28s → 3121.84s] so we started deep mine in 2010 which is\n",
            "[3119.60s → 3124.00s] hard to imagine now because 2010 it's\n",
            "[3121.84s → 3125.76s] only 12 short years ago but nobody was\n",
            "[3124.00s → 3127.44s] talking about ai uh you know if you\n",
            "[3125.76s → 3128.88s] remember back to your mit days you know\n",
            "[3127.44s → 3131.44s] no one was talking about it i did a\n",
            "[3128.88s → 3133.20s] postdoc at mit back around then and it\n",
            "[3131.44s → 3134.80s] was sort of thought of as a well look we\n",
            "[3133.20s → 3137.44s] know ai doesn't work we tried this hard\n",
            "[3134.80s → 3139.12s] in the 90s at places like mit mostly\n",
            "[3137.44s → 3140.72s] losing using logic systems and\n",
            "[3139.12s → 3142.88s] old-fashioned sort of good old-fashioned\n",
            "[3140.72s → 3145.28s] ai we would call it now um people like\n",
            "[3142.88s → 3146.96s] minsky and and and patrick winston and\n",
            "[3145.28s → 3148.40s] you know all these characters right and\n",
            "[3146.96s → 3149.92s] used to debate a few of them and they\n",
            "[3148.40s → 3151.44s] used to think i was mad thinking about\n",
            "[3149.92s → 3153.92s] that some new advance could be done with\n",
            "[3151.44s → 3155.20s] learning systems and um i was actually\n",
            "[3153.92s → 3156.88s] pleased to hear that because at least\n",
            "[3155.20s → 3158.88s] you know you're on a unique track at\n",
            "[3156.88s → 3160.56s] that point right even if every all of\n",
            "[3158.88s → 3162.32s] your you know professors are telling you\n",
            "[3160.56s → 3164.48s] you're mad that's true and of course in\n",
            "[3162.32s → 3166.16s] industry uh you can we couldn't get you\n",
            "[3164.48s → 3168.40s] know as difficult to get two cents\n",
            "[3166.16s → 3169.76s] together uh and which is hard to imagine\n",
            "[3168.40s → 3172.00s] now as well given it's the biggest sort\n",
            "[3169.76s → 3173.60s] of buzzword in in vcs and and\n",
            "[3172.00s → 3175.60s] fundraising's easy and all these kind of\n",
            "[3173.60s → 3177.68s] things today so\n",
            "[3175.60s → 3179.60s] back in 2010 it was very difficult and\n",
            "[3177.68s → 3182.32s] what we the reason we started then and\n",
            "[3179.60s → 3183.92s] shane and i used to discuss um uh uh\n",
            "[3182.32s → 3186.00s] what were the sort of founding tenets of\n",
            "[3183.92s → 3188.96s] deep mind and it was very various things\n",
            "[3186.00s → 3190.72s] one was um algorithmic advances so deep\n",
            "[3188.96s → 3192.40s] learning you know jeff hinton and cohen\n",
            "[3190.72s → 3194.08s] just had just sort of invented that in\n",
            "[3192.40s → 3196.24s] academia but no one in industry knew\n",
            "[3194.08s → 3197.68s] about it uh we love reinforcement\n",
            "[3196.24s → 3199.36s] learning we thought that could be scaled\n",
            "[3197.68s → 3201.84s] up but also understanding about the\n",
            "[3199.36s → 3204.48s] human brain had advanced um quite a lot\n",
            "[3201.84s → 3205.68s] uh in the decade prior with fmri\n",
            "[3204.48s → 3208.72s] machines and other things so we could\n",
            "[3205.68s → 3211.20s] get some good hints about architectures\n",
            "[3208.72s → 3212.80s] and algorithms and and sort of um\n",
            "[3211.20s → 3215.52s] representations maybe that the brain\n",
            "[3212.80s → 3218.00s] uses so as at a systems level not at a\n",
            "[3215.52s → 3220.64s] implementation level um and then the\n",
            "[3218.00s → 3222.96s] other big things were compute and gpus\n",
            "[3220.64s → 3224.64s] right so we could see a compute was\n",
            "[3222.96s → 3226.88s] going to be really useful and it got to\n",
            "[3224.64s → 3228.72s] a place where it became commoditized\n",
            "[3226.88s → 3230.72s] mostly through the games industry and\n",
            "[3228.72s → 3231.92s] and that could be taken advantage of and\n",
            "[3230.72s → 3233.92s] then the final thing was also\n",
            "[3231.92s → 3237.44s] mathematical and theoretical definitions\n",
            "[3233.92s → 3238.96s] of intelligence so things like ai xi aix\n",
            "[3237.44s → 3240.80s] which uh shane worked on with his\n",
            "[3238.96s → 3243.44s] supervisor marcus hutter which is a sort\n",
            "[3240.80s → 3245.44s] of theoretical uh proof really of\n",
            "[3243.44s → 3247.36s] universal intelligence um which is\n",
            "[3245.44s → 3249.12s] actually a reinforcement learning system\n",
            "[3247.36s → 3250.64s] um in the limit i mean it assumes\n",
            "[3249.12s → 3252.16s] infinite compute and infinite memory in\n",
            "[3250.64s → 3254.24s] the way you know like a turing machine\n",
            "[3252.16s → 3256.56s] proof but i was also waiting to see\n",
            "[3254.24s → 3259.04s] something like that too to you know like\n",
            "[3256.56s → 3260.40s] turing machines uh and and computation\n",
            "[3259.04s → 3262.40s] theory that people like turing and\n",
            "[3260.40s → 3264.96s] shannon came up with underpins modern\n",
            "[3262.40s → 3266.56s] computer science um uh you know i was\n",
            "[3264.96s → 3269.36s] waiting for a theory like that to sort\n",
            "[3266.56s → 3270.96s] of underpin agi research so when i you\n",
            "[3269.36s → 3272.48s] know met shane and saw he was working on\n",
            "[3270.96s → 3274.48s] something like that you know that to me\n",
            "[3272.48s → 3275.44s] was a sort of final piece of the jigsaw\n",
            "[3274.48s → 3277.68s] so\n",
            "[3275.44s → 3280.08s] in the early days i would say that\n",
            "[3277.68s → 3281.04s] ideas were the most important uh you\n",
            "[3280.08s → 3283.20s] know and for us it was deep\n",
            "[3281.04s → 3285.12s] reinforcement learning scaling up deep\n",
            "[3283.20s → 3287.76s] learning um of course we've seen\n",
            "[3285.12s → 3289.52s] transformers so huge leaps i would say\n",
            "[3287.76s → 3291.76s] you know three or four from for if you\n",
            "[3289.52s → 3295.84s] think from 2010 until now uh huge\n",
            "[3291.76s → 3297.60s] evolutions things like alphago um and um\n",
            "[3295.84s → 3302.40s] and and maybe there's a few more still\n",
            "[3297.60s → 3304.24s] needed but as we get closer to ai agi um\n",
            "[3302.40s → 3306.88s] i think engineering becomes more and\n",
            "[3304.24s → 3308.56s] more important and data because scale\n",
            "[3306.88s → 3310.56s] and of course the the recent you know\n",
            "[3308.56s → 3312.16s] results of gpt3 and all the big language\n",
            "[3310.56s → 3315.76s] models and large models including our\n",
            "[3312.16s → 3317.60s] ones uh has shown that scale is a is and\n",
            "[3315.76s → 3320.16s] large models are clearly going to be\n",
            "[3317.60s → 3323.20s] unnecessary but perhaps not sufficient\n",
            "[3320.16s → 3325.76s] part of an agi solution and\n",
            "[3323.20s → 3327.28s] throughout that like you said and i'd\n",
            "[3325.76s → 3329.92s] like to give you a big thank you you're\n",
            "[3327.28s → 3332.16s] one of the pioneers in this is\n",
            "[3329.92s → 3334.96s] sticking by ideas like reinforcement\n",
            "[3332.16s → 3336.72s] learning that this can actually work\n",
            "[3334.96s → 3338.88s] given actually\n",
            "[3336.72s → 3340.80s] limited success in the past\n",
            "[3338.88s → 3342.96s] and also\n",
            "[3340.80s → 3344.80s] which we still don't know but\n",
            "[3342.96s → 3347.12s] proudly\n",
            "[3344.80s → 3349.76s] having the best researchers in the world\n",
            "[3347.12s → 3351.36s] and talking about solving intelligence\n",
            "[3349.76s → 3353.68s] so talking about whatever you call it\n",
            "[3351.36s → 3355.92s] agi or something like this\n",
            "[3353.68s → 3358.32s] that speaking of mit that's that's just\n",
            "[3355.92s → 3362.48s] something not you wouldn't bring up no\n",
            "[3358.32s → 3364.00s] uh not not maybe you did in uh like 40\n",
            "[3362.48s → 3365.84s] 50 years ago\n",
            "[3364.00s → 3367.28s] but that was\n",
            "[3365.84s → 3369.84s] um\n",
            "[3367.28s → 3372.40s] ai was a place where you do tinkering\n",
            "[3369.84s → 3374.80s] very small scale not very ambitious\n",
            "[3372.40s → 3376.56s] projects and\n",
            "[3374.80s → 3378.16s] maybe the biggest ambitious projects\n",
            "[3376.56s → 3379.84s] were in the space of robotics and doing\n",
            "[3378.16s → 3381.92s] like the darpa challenge sure but the\n",
            "[3379.84s → 3383.60s] task of solving intelligence and\n",
            "[3381.92s → 3385.52s] believing you can\n",
            "[3383.60s → 3387.84s] that's really really powerful so\n",
            "[3385.52s → 3390.72s] in order for engineering to do its work\n",
            "[3387.84s → 3392.56s] to have great engineers build great\n",
            "[3390.72s → 3394.16s] systems you have to have that belief\n",
            "[3392.56s → 3395.52s] that threats throughout the whole thing\n",
            "[3394.16s → 3397.36s] that you can actually solve some of\n",
            "[3395.52s → 3399.68s] these impossible challenges yeah that's\n",
            "[3397.36s → 3402.00s] right and and back in 2010 you know our\n",
            "[3399.68s → 3404.24s] mission statement um and still is today\n",
            "[3402.00s → 3406.48s] you know it was used to be uh solving\n",
            "[3404.24s → 3408.00s] step one solve intelligence step two use\n",
            "[3406.48s → 3409.92s] it to solve everything else yes so if\n",
            "[3408.00s → 3412.08s] you can imagine pitching that to a vc in\n",
            "[3409.92s → 3414.40s] 2010 you know the kind of looks we we\n",
            "[3412.08s → 3416.88s] got we managed to you know find a few uh\n",
            "[3414.40s → 3418.64s] kooky people to back us but it was uh it\n",
            "[3416.88s → 3420.24s] was tricky and and i and i got to the\n",
            "[3418.64s → 3422.16s] point where we we wouldn't mention it to\n",
            "[3420.24s → 3424.24s] any of our professors because they would\n",
            "[3422.16s → 3427.04s] just eye roll and think we you know\n",
            "[3424.24s → 3428.56s] committed career suicide and and uh and\n",
            "[3427.04s → 3430.72s] and you know so it was there's a lot of\n",
            "[3428.56s → 3432.80s] things that we had to do but we always\n",
            "[3430.72s → 3434.56s] believed it and one reason you know by\n",
            "[3432.80s → 3435.68s] the way one reason we i believe i've\n",
            "[3434.56s → 3437.36s] always believed in reinforcement\n",
            "[3435.68s → 3439.44s] learning is that\n",
            "[3437.36s → 3442.16s] that if you look at neuroscience that is\n",
            "[3439.44s → 3443.92s] the way that the you know primate brain\n",
            "[3442.16s → 3445.68s] learns one of the main mechanisms is the\n",
            "[3443.92s → 3447.60s] dopamine system implement some form of\n",
            "[3445.68s → 3450.40s] td learning a very famous result in the\n",
            "[3447.60s → 3453.28s] late 90s uh where they saw this in\n",
            "[3450.40s → 3455.28s] monkeys and uh and as a you know proper\n",
            "[3453.28s → 3457.36s] game prediction error so we you know\n",
            "[3455.28s → 3459.12s] again in the limit this is this is what\n",
            "[3457.36s → 3461.44s] i think you can use neuroscience for is\n",
            "[3459.12s → 3462.56s] is you know any at mathematics you when\n",
            "[3461.44s → 3463.60s] you're when you're doing something as\n",
            "[3462.56s → 3465.28s] ambitious as trying to solve\n",
            "[3463.60s → 3466.96s] intelligence and you're you're you know\n",
            "[3465.28s → 3469.60s] it's blue sky research no one knows how\n",
            "[3466.96s → 3471.28s] to do it you you you need to use any\n",
            "[3469.60s → 3473.68s] evidence or any source of information\n",
            "[3471.28s → 3475.20s] you can to help guide you in the right\n",
            "[3473.68s → 3477.28s] direction or give you confidence you're\n",
            "[3475.20s → 3479.28s] going in the right direction so so that\n",
            "[3477.28s → 3481.04s] that was one reason we pushed so hard on\n",
            "[3479.28s → 3483.04s] that and that's and just going back to\n",
            "[3481.04s → 3484.64s] your early question about organization\n",
            "[3483.04s → 3487.20s] the other big thing that i think we\n",
            "[3484.64s → 3490.40s] innovated with at deepmind to encourage\n",
            "[3487.20s → 3492.32s] invention and and uh and innovation was\n",
            "[3490.40s → 3494.56s] the multi-disciplinary organization we\n",
            "[3492.32s → 3496.72s] built and we still have today so\n",
            "[3494.56s → 3498.32s] deepmind originally was a confluence of\n",
            "[3496.72s → 3500.88s] the of the most cutting-edge knowledge\n",
            "[3498.32s → 3503.04s] in neuroscience with machine learning\n",
            "[3500.88s → 3504.24s] engineering and mathematics right and\n",
            "[3503.04s → 3505.76s] and gaming\n",
            "[3504.24s → 3507.60s] and then since then we built that out\n",
            "[3505.76s → 3510.08s] even further so we have philosophers\n",
            "[3507.60s → 3511.60s] here and and uh by you know ethicists\n",
            "[3510.08s → 3514.08s] but also other types of scientists\n",
            "[3511.60s → 3516.00s] physicists and so on um and that's what\n",
            "[3514.08s → 3519.04s] brings together i tried to build a sort\n",
            "[3516.00s → 3521.12s] of um new type of bell labs but in this\n",
            "[3519.04s → 3523.84s] golden era right uh\n",
            "[3521.12s → 3526.64s] and and a new expression of that um to\n",
            "[3523.84s → 3528.96s] try and uh foster this incredible sort\n",
            "[3526.64s → 3530.40s] of innovation machine so talking about\n",
            "[3528.96s → 3532.80s] the humans in the machine\n",
            "[3530.40s → 3535.44s] the mind itself is a learning machine\n",
            "[3532.80s → 3537.44s] with a lots of amazing human minds in it\n",
            "[3535.44s → 3540.24s] coming together to try and build these\n",
            "[3537.44s → 3542.24s] uh learning systems\n",
            "[3540.24s → 3544.80s] if we return to\n",
            "[3542.24s → 3547.20s] the big ambitious dream of alpha fold\n",
            "[3544.80s → 3549.52s] that may be the early steps on a very\n",
            "[3547.20s → 3552.40s] long journey in um\n",
            "[3549.52s → 3552.40s] in biology\n",
            "[3552.48s → 3555.76s] do you think the same kind of approach\n",
            "[3554.08s → 3557.68s] can use to predict the structure and\n",
            "[3555.76s → 3561.36s] function of more complex biological\n",
            "[3557.68s → 3562.56s] systems so multi-protein interaction\n",
            "[3561.36s → 3564.56s] and then\n",
            "[3562.56s → 3566.72s] i mean you can go out from there just\n",
            "[3564.56s → 3568.56s] simulating bigger and bigger systems\n",
            "[3566.72s → 3571.36s] that eventually simulate something like\n",
            "[3568.56s → 3574.72s] the human brain or the human body just\n",
            "[3571.36s → 3577.60s] the big mush the mess of the beautiful\n",
            "[3574.72s → 3580.48s] resilient mesobiology do do you see that\n",
            "[3577.60s → 3581.28s] as a long-term vision i do and i think\n",
            "[3580.48s → 3582.80s] um\n",
            "[3581.28s → 3584.88s] you know if you think about what are the\n",
            "[3582.80s → 3587.52s] things top things i wanted to apply ai\n",
            "[3584.88s → 3589.92s] ai2 once we had powerful enough systems\n",
            "[3587.52s → 3592.64s] biology and curing diseases and\n",
            "[3589.92s → 3594.32s] understanding biology uh was right up\n",
            "[3592.64s → 3596.00s] there you know top of my list that's one\n",
            "[3594.32s → 3598.24s] of the reasons i personally pushed that\n",
            "[3596.00s → 3601.44s] myself and with alpha fold but i think\n",
            "[3598.24s → 3604.72s] alpha fold uh amazing as it is is just\n",
            "[3601.44s → 3607.20s] the beginning um and and and i hope it's\n",
            "[3604.72s → 3610.16s] evidence of uh what could be done with\n",
            "[3607.20s → 3612.00s] computational methods so um you know\n",
            "[3610.16s → 3614.24s] alpha fold solve this this huge problem\n",
            "[3612.00s → 3616.56s] of the structure of proteins but biology\n",
            "[3614.24s → 3618.00s] is dynamic so really what i imagine from\n",
            "[3616.56s → 3621.28s] here we're working on all these things\n",
            "[3618.00s → 3624.00s] now is protein protein interaction uh\n",
            "[3621.28s → 3626.16s] protein ligand binding so reacting with\n",
            "[3624.00s → 3628.96s] molecules um then you want to get build\n",
            "[3626.16s → 3631.52s] up to pathways and then eventually a\n",
            "[3628.96s → 3633.20s] virtual cell that's my dream uh maybe in\n",
            "[3631.52s → 3634.64s] the next 10 years and i've been talking\n",
            "[3633.20s → 3636.08s] actually to a lot of biologists friends\n",
            "[3634.64s → 3638.24s] of mine paul nurse who runs the qrik\n",
            "[3636.08s → 3639.68s] institute amazing biologist nobel prize\n",
            "[3638.24s → 3642.32s] winning biologist we've been discussing\n",
            "[3639.68s → 3644.72s] for 20 years now virtual cells could you\n",
            "[3642.32s → 3646.16s] build a virtual simulation of a cell and\n",
            "[3644.72s → 3647.92s] if you could that would be incredible\n",
            "[3646.16s → 3648.88s] for biology and disease discovery\n",
            "[3647.92s → 3651.04s] because you could do loads of\n",
            "[3648.88s → 3652.96s] experiments on the virtual cell and then\n",
            "[3651.04s → 3655.20s] only at the last stage validate it in\n",
            "[3652.96s → 3656.88s] the wet lab so you could you know in\n",
            "[3655.20s → 3658.72s] terms of the search space of discovering\n",
            "[3656.88s → 3661.36s] new drugs you know it takes 10 years\n",
            "[3658.72s → 3664.56s] roughly to go from uh uh to to go from\n",
            "[3661.36s → 3666.72s] uh you know identifying a target to uh\n",
            "[3664.56s → 3668.16s] having a drug candidate um maybe that\n",
            "[3666.72s → 3670.24s] could be shortened to you know by an\n",
            "[3668.16s → 3673.44s] order of magnitude with if you could do\n",
            "[3670.24s → 3675.60s] most of that that that work in silico so\n",
            "[3673.44s → 3678.24s] in order to get to a virtual cell\n",
            "[3675.60s → 3679.60s] we have to build up uh uh understanding\n",
            "[3678.24s → 3682.16s] of different parts of biology and the\n",
            "[3679.60s → 3684.00s] interactions and and um so you know\n",
            "[3682.16s → 3685.52s] every every few years we talk about this\n",
            "[3684.00s → 3687.68s] with i talked about this with paul and\n",
            "[3685.52s → 3690.00s] then finally last year after alpha fault\n",
            "[3687.68s → 3691.68s] i said now is the time we can finally go\n",
            "[3690.00s → 3693.60s] for it and and alpha falls the first\n",
            "[3691.68s → 3694.96s] proof point that this might be possible\n",
            "[3693.60s → 3696.64s] uh and he's very excited when we have\n",
            "[3694.96s → 3698.00s] some collaborations with his with his\n",
            "[3696.64s → 3699.84s] lab they're just across the road\n",
            "[3698.00s → 3701.04s] actually from us as you know wonderful\n",
            "[3699.84s → 3703.84s] being here in king's cross with the\n",
            "[3701.04s → 3705.84s] quick institute across the road and um\n",
            "[3703.84s → 3707.28s] and i think the next steps you know i\n",
            "[3705.84s → 3709.12s] think there's going to be some amazing\n",
            "[3707.28s → 3711.20s] advances in biology built on top of\n",
            "[3709.12s → 3712.72s] things like alpha fold uh we're already\n",
            "[3711.20s → 3714.16s] seeing that with the community doing\n",
            "[3712.72s → 3717.60s] that after we've open sourced it and\n",
            "[3714.16s → 3719.60s] released it um and uh you know i also i\n",
            "[3717.60s → 3722.40s] often say that i think\n",
            "[3719.60s → 3724.96s] uh if you think of mathematics is the\n",
            "[3722.40s → 3726.72s] perfect description language for physics\n",
            "[3724.96s → 3729.12s] i think ai might be end up being the\n",
            "[3726.72s → 3730.08s] perfect description language for biology\n",
            "[3729.12s → 3733.12s] because\n",
            "[3730.08s → 3735.84s] biology is so messy it's so emergent so\n",
            "[3733.12s → 3737.52s] dynamic and complex um i think i find it\n",
            "[3735.84s → 3739.28s] very hard to believe we'll ever get to\n",
            "[3737.52s → 3741.68s] something as elegant as newton's laws of\n",
            "[3739.28s → 3744.48s] motions to describe a cell right it's\n",
            "[3741.68s → 3746.88s] just too complicated um so i think ai is\n",
            "[3744.48s → 3748.40s] the right tool for this you have to uh\n",
            "[3746.88s → 3751.36s] you have to start at the basic building\n",
            "[3748.40s → 3754.00s] blocks and use ai to run the simulation\n",
            "[3751.36s → 3756.48s] for all those building blocks so have a\n",
            "[3754.00s → 3757.92s] very strong way to do prediction of what\n",
            "[3756.48s → 3759.20s] given these building blocks what kind of\n",
            "[3757.92s → 3760.64s] biology how the\n",
            "[3759.20s → 3762.48s] the function\n",
            "[3760.64s → 3763.44s] and the evolution of that biological\n",
            "[3762.48s → 3765.28s] system\n",
            "[3763.44s → 3767.20s] it's almost like a cellular automata you\n",
            "[3765.28s → 3769.12s] have to run you can't analyze it from a\n",
            "[3767.20s → 3771.04s] high level you have to take the basic\n",
            "[3769.12s → 3772.72s] ingredients figure out the rules yeah\n",
            "[3771.04s → 3774.48s] and let it run but in this case the\n",
            "[3772.72s → 3776.96s] rules are very difficult to figure out\n",
            "[3774.48s → 3779.20s] yes yes learn them that's exactly it so\n",
            "[3776.96s → 3781.76s] it's the biology is too complicated to\n",
            "[3779.20s → 3784.24s] figure out the rules it's it's it's too\n",
            "[3781.76s → 3785.84s] emergent too dynamic say compared to a\n",
            "[3784.24s → 3788.32s] physics system like the motion of a\n",
            "[3785.84s → 3789.84s] planet yeah right and and so you have to\n",
            "[3788.32s → 3791.92s] learn the rules and that's exactly the\n",
            "[3789.84s → 3793.36s] type of systems that we're building so\n",
            "[3791.92s → 3796.40s] you you mentioned you've open sourced\n",
            "[3793.36s → 3799.20s] alpha fold and even the data involved\n",
            "[3796.40s → 3801.04s] to me personally also\n",
            "[3799.20s → 3802.96s] really happy and a big thank you for\n",
            "[3801.04s → 3805.76s] open sourcing mijoko\n",
            "[3802.96s → 3808.00s] uh the physics simulation engine that's\n",
            "[3805.76s → 3809.84s] that's often used for robotics research\n",
            "[3808.00s → 3813.12s] and so on so i think that's a pretty\n",
            "[3809.84s → 3815.20s] gangster move uh so what what's the\n",
            "[3813.12s → 3818.24s] what's i mean this uh\n",
            "[3815.20s → 3820.08s] very few companies or people would do\n",
            "[3818.24s → 3822.32s] that kind of thing what's the philosophy\n",
            "[3820.08s → 3824.40s] behind that you know it's a case-by-case\n",
            "[3822.32s → 3826.64s] basis and in both those cases we felt\n",
            "[3824.40s → 3828.32s] that was the maximum benefit to humanity\n",
            "[3826.64s → 3831.20s] to do that and and the scientific\n",
            "[3828.32s → 3833.28s] community in one case the robotics uh\n",
            "[3831.20s → 3835.12s] physics community with mojoco so\n",
            "[3833.28s → 3837.04s] purchased it we purchased\n",
            "[3835.12s → 3839.28s] to obs we purchased it for the express\n",
            "[3837.04s → 3840.88s] principle to open source it so\n",
            "[3839.28s → 3842.32s] um so\n",
            "[3840.88s → 3844.32s] you know i hope people appreciate that\n",
            "[3842.32s → 3846.48s] it's great to hear that you do and then\n",
            "[3844.32s → 3848.80s] the second thing was and mostly we did\n",
            "[3846.48s → 3850.72s] it because the person building it is uh\n",
            "[3848.80s → 3852.00s] uh would not it was not able to cope\n",
            "[3850.72s → 3854.00s] with supporting it anymore because it\n",
            "[3852.00s → 3856.16s] was it got too big for him his amazing\n",
            "[3854.00s → 3857.52s] professor uh who who built it in the\n",
            "[3856.16s → 3859.12s] first place so we helped him out with\n",
            "[3857.52s → 3861.20s] that and then with alpha folds even\n",
            "[3859.12s → 3864.00s] bigger i would say and i think in that\n",
            "[3861.20s → 3867.28s] case we decided that there were so many\n",
            "[3864.00s → 3869.28s] downstream applications of alpha fold um\n",
            "[3867.28s → 3871.68s] that we couldn't possibly even imagine\n",
            "[3869.28s → 3874.88s] what they all were so the best way to\n",
            "[3871.68s → 3878.16s] accelerate uh drug discovery and also\n",
            "[3874.88s → 3880.40s] fundamental research would be to to um\n",
            "[3878.16s → 3883.20s] give all that data away and and and the\n",
            "[3880.40s → 3885.28s] and the and the system itself um you\n",
            "[3883.20s → 3886.72s] know it's been so gratifying to see what\n",
            "[3885.28s → 3888.32s] people have done that within just one\n",
            "[3886.72s → 3891.52s] year which is a short amount of time in\n",
            "[3888.32s → 3894.16s] science and uh it's been used by\n",
            "[3891.52s → 3895.76s] over 500 000 researchers have used it we\n",
            "[3894.16s → 3897.60s] think that's almost every biologist in\n",
            "[3895.76s → 3899.12s] the world i think there's roughly 500\n",
            "[3897.60s → 3901.36s] 000 biologists in the world professional\n",
            "[3899.12s → 3904.32s] biologists have used it to to look at\n",
            "[3901.36s → 3906.16s] their proteins of interest\n",
            "[3904.32s → 3908.48s] we've seen amazing fundamental research\n",
            "[3906.16s → 3910.16s] done so a couple of weeks ago front\n",
            "[3908.48s → 3912.08s] cover there was a whole special issue of\n",
            "[3910.16s → 3914.08s] science including the front cover which\n",
            "[3912.08s → 3915.36s] had the nuclear pore complex on it which\n",
            "[3914.08s → 3917.52s] is one of the biggest proteins in the\n",
            "[3915.36s → 3919.68s] body the nuclear poor complex is a\n",
            "[3917.52s → 3922.08s] protein that governs all the nutrients\n",
            "[3919.68s → 3923.60s] going in and out of your cell nucleus so\n",
            "[3922.08s → 3925.84s] they're like little hole gateways that\n",
            "[3923.60s → 3927.44s] open and close to let things go in and\n",
            "[3925.84s → 3929.20s] out of your cell nucleus so they're\n",
            "[3927.44s → 3930.64s] really important but they're huge\n",
            "[3929.20s → 3932.56s] because they're massive doughnut rings\n",
            "[3930.64s → 3934.00s] shaped things and they've been looking\n",
            "[3932.56s → 3936.08s] to try and figure out that structure for\n",
            "[3934.00s → 3937.76s] decades and they have lots of you know\n",
            "[3936.08s → 3939.68s] experimental data but it's too low\n",
            "[3937.76s → 3942.24s] resolution there's bits missing and they\n",
            "[3939.68s → 3944.80s] were able to like a giant lego jigsaw\n",
            "[3942.24s → 3947.60s] puzzle use alpha fold predictions plus\n",
            "[3944.80s → 3949.68s] experimental data and combined those two\n",
            "[3947.60s → 3950.88s] independent sources of information uh\n",
            "[3949.68s → 3952.64s] actually four different groups around\n",
            "[3950.88s → 3954.56s] the world were able to put it together\n",
            "[3952.64s → 3956.40s] the sec more or less simultaneously\n",
            "[3954.56s → 3958.16s] using alpha fault predictions so that's\n",
            "[3956.40s → 3960.24s] been amazing to see and pretty much\n",
            "[3958.16s → 3961.76s] every pharma company every drug company\n",
            "[3960.24s → 3963.84s] executive i've spoken to has said that\n",
            "[3961.76s → 3966.88s] their teams are using alpha fold to\n",
            "[3963.84s → 3968.48s] accelerate whatever drugs uh uh they're\n",
            "[3966.88s → 3971.52s] trying to discover so i think the\n",
            "[3968.48s → 3974.16s] knock-on effect has been enormous in\n",
            "[3971.52s → 3975.60s] terms of uh the impact that uh\n",
            "[3974.16s → 3977.68s] alpha-fold has made and it's probably\n",
            "[3975.60s → 3979.92s] bringing in it's creating biologists\n",
            "[3977.68s → 3980.72s] it's bringing more people into the field\n",
            "[3979.92s → 3982.40s] um\n",
            "[3980.72s → 3984.40s] both on the excitement and both on the\n",
            "[3982.40s → 3985.44s] technical skills involved\n",
            "[3984.40s → 3987.92s] and um\n",
            "[3985.44s → 3990.00s] it's almost like uh a gateway drug to\n",
            "[3987.92s → 3991.60s] biology yes it is you get more\n",
            "[3990.00s → 3993.92s] computational people involved too\n",
            "[3991.60s → 3995.76s] hopefully and and i think for us you\n",
            "[3993.92s → 3997.04s] know the next stage as i said you know\n",
            "[3995.76s → 3998.72s] in future we have to have other\n",
            "[3997.04s → 4000.48s] considerations too we're building on top\n",
            "[3998.72s → 4002.00s] of alpha fold and these other ideas i\n",
            "[4000.48s → 4004.16s] discussed with you about protein protein\n",
            "[4002.00s → 4005.84s] interactions and and genomics and other\n",
            "[4004.16s → 4007.28s] things and not everything will be open\n",
            "[4005.84s → 4008.48s] source some of it will will do\n",
            "[4007.28s → 4009.84s] commercially because that will be the\n",
            "[4008.48s → 4011.92s] best way to actually get the most\n",
            "[4009.84s → 4013.76s] resources and impact behind it in other\n",
            "[4011.92s → 4016.40s] ways some other projects will do\n",
            "[4013.76s → 4018.48s] non-profit style um and also we have to\n",
            "[4016.40s → 4020.08s] consider for future things as well\n",
            "[4018.48s → 4022.08s] safety and ethics as well like but you\n",
            "[4020.08s → 4024.08s] know synthetic biology there are you\n",
            "[4022.08s → 4025.76s] know there is dual use and we have to\n",
            "[4024.08s → 4027.44s] think about that as well with alpha fold\n",
            "[4025.76s → 4029.12s] we you know we consulted with 30\n",
            "[4027.44s → 4030.56s] different bioethicists and and other\n",
            "[4029.12s → 4033.60s] people expert in this field to make sure\n",
            "[4030.56s → 4034.88s] it was safe before um we released it so\n",
            "[4033.60s → 4036.24s] there'll be other considerations in\n",
            "[4034.88s → 4038.24s] future but for right now you know i\n",
            "[4036.24s → 4040.08s] think alpha fold is a kind of a gift\n",
            "[4038.24s → 4042.08s] from us to to to the scientific\n",
            "[4040.08s → 4042.88s] community so i'm pretty sure\n",
            "[4042.08s → 4045.20s] that\n",
            "[4042.88s → 4047.84s] something like alpha fold\n",
            "[4045.20s → 4049.04s] uh would be part of nobel prizes in the\n",
            "[4047.84s → 4051.36s] future\n",
            "[4049.04s → 4052.88s] but us humans of course are horrible\n",
            "[4051.36s → 4055.52s] with credit assignment so we'll of\n",
            "[4052.88s → 4057.52s] course give it to the humans\n",
            "[4055.52s → 4060.72s] do you think there will be a day\n",
            "[4057.52s → 4062.48s] when ai system\n",
            "[4060.72s → 4065.20s] can't be denied\n",
            "[4062.48s → 4067.44s] that it earned that nobel prize do you\n",
            "[4065.20s → 4069.20s] think we'll see that in 21st century it\n",
            "[4067.44s → 4072.08s] depends what type of ais we end up\n",
            "[4069.20s → 4073.68s] building right whether they're um\n",
            "[4072.08s → 4076.40s] you know goal seeking agents who\n",
            "[4073.68s → 4077.76s] specifies the goals uh who comes up with\n",
            "[4076.40s → 4079.04s] the hypotheses\n",
            "[4077.76s → 4081.28s] who you know who determines which\n",
            "[4079.04s → 4082.96s] problems to tackle right so i think it's\n",
            "[4081.28s → 4084.88s] about an announcement yeah so it's\n",
            "[4082.96s → 4087.68s] announcing the results exactly as part\n",
            "[4084.88s → 4090.24s] of it um so i think right now of course\n",
            "[4087.68s → 4092.08s] it's it's it's it's amazing human\n",
            "[4090.24s → 4093.60s] ingenuity that's behind these systems\n",
            "[4092.08s → 4095.68s] and then the system in my opinion is\n",
            "[4093.60s → 4098.00s] just a tool you know it'd be a bit like\n",
            "[4095.68s → 4099.68s] saying with galileo and his telescope\n",
            "[4098.00s → 4101.36s] you know the ingenuity the the the\n",
            "[4099.68s → 4103.44s] credit should go to the telescope i mean\n",
            "[4101.36s → 4105.12s] it's clearly galileo building the tool\n",
            "[4103.44s → 4106.88s] which he then uses\n",
            "[4105.12s → 4108.96s] so i still see that in the same way\n",
            "[4106.88s → 4111.84s] today even though these tools learn for\n",
            "[4108.96s → 4113.52s] themselves um they're i think i think of\n",
            "[4111.84s → 4115.12s] things like alpha fold and that the\n",
            "[4113.52s → 4118.16s] things we're building as the ultimate\n",
            "[4115.12s → 4119.68s] tools for science and for acquiring new\n",
            "[4118.16s → 4122.08s] knowledge to help us as scientists\n",
            "[4119.68s → 4124.32s] acquire new knowledge i think one day\n",
            "[4122.08s → 4126.88s] there will come a point where\n",
            "[4124.32s → 4129.04s] an ai system may solve or come up with\n",
            "[4126.88s → 4131.12s] something like general relativity of its\n",
            "[4129.04s → 4132.64s] own bat not just by\n",
            "[4131.12s → 4135.04s] averaging everything on the internet or\n",
            "[4132.64s → 4136.00s] averaging everything on pubmed\n",
            "[4135.04s → 4138.48s] although that would be interesting to\n",
            "[4136.00s → 4140.00s] see what that would come up with um so\n",
            "[4138.48s → 4142.00s] that to me is a bit like our earlier\n",
            "[4140.00s → 4144.64s] debate about creativity you know\n",
            "[4142.00s → 4148.24s] inventing go rather than just coming up\n",
            "[4144.64s → 4150.48s] with a good go move and um so i think uh\n",
            "[4148.24s → 4152.32s] solving i think to to you know if we\n",
            "[4150.48s → 4153.92s] wanted to give it the credit of like a\n",
            "[4152.32s → 4156.64s] nobel type of thing then it would need\n",
            "[4153.92s → 4159.60s] to invent go uh and sort of invent that\n",
            "[4156.64s → 4162.08s] new conjecture out of the blue um rather\n",
            "[4159.60s → 4163.68s] than being specified by the the human\n",
            "[4162.08s → 4165.44s] scientists or the human creators so i\n",
            "[4163.68s → 4167.12s] think right now that's it's definitely\n",
            "[4165.44s → 4168.72s] just a tool although it is interesting\n",
            "[4167.12s → 4170.48s] how far you get by averaging everything\n",
            "[4168.72s → 4171.52s] on the internet like you said because\n",
            "[4170.48s → 4173.60s] you know\n",
            "[4171.52s → 4174.72s] a lot of people do see science as you're\n",
            "[4173.60s → 4176.40s] always standing on the shoulders of\n",
            "[4174.72s → 4178.64s] giants and\n",
            "[4176.40s → 4180.00s] the question is how much are you really\n",
            "[4178.64s → 4182.24s] reaching\n",
            "[4180.00s → 4184.56s] up above the shoulders of giants maybe\n",
            "[4182.24s → 4185.52s] it's just assimilating different kinds\n",
            "[4184.56s → 4187.44s] of\n",
            "[4185.52s → 4189.20s] results of the past\n",
            "[4187.44s → 4190.96s] with ultimately this new perspective\n",
            "[4189.20s → 4193.60s] that gives you this breakthrough idea\n",
            "[4190.96s → 4195.28s] but that idea may not be\n",
            "[4193.60s → 4196.88s] novel in the way that we can't be\n",
            "[4195.28s → 4198.64s] already discovered on the internet maybe\n",
            "[4196.88s → 4200.72s] the nobel prizes\n",
            "[4198.64s → 4203.12s] of the next 100 years are already all\n",
            "[4200.72s → 4205.12s] there on the internet to be discovered\n",
            "[4203.12s → 4207.28s] they could be they could be i mean i\n",
            "[4205.12s → 4208.88s] think um\n",
            "[4207.28s → 4210.16s] this is one of the big mysteries i think\n",
            "[4208.88s → 4212.40s] is that uh\n",
            "[4210.16s → 4213.92s] uh i i first of all i believe a lot of\n",
            "[4212.40s → 4215.52s] the big new breakthroughs that are going\n",
            "[4213.92s → 4217.36s] to come in the next few decades and even\n",
            "[4215.52s → 4218.80s] in the last decade are going to come at\n",
            "[4217.36s → 4221.52s] the intersection between different\n",
            "[4218.80s → 4224.32s] subject areas where um there'll be some\n",
            "[4221.52s → 4226.40s] new connection that's found between what\n",
            "[4224.32s → 4228.16s] seemingly with disparate areas and and\n",
            "[4226.40s → 4229.52s] one can even think of deep mind as i\n",
            "[4228.16s → 4231.20s] said earlier as a sort of\n",
            "[4229.52s → 4234.00s] interdisciplinary between neuroscience\n",
            "[4231.20s → 4237.20s] ideas and ai engineering ideas uh\n",
            "[4234.00s → 4239.28s] originally and so um so i think there's\n",
            "[4237.20s → 4241.04s] that and then one of the things we can't\n",
            "[4239.28s → 4242.72s] imagine today is and one of the reasons\n",
            "[4241.04s → 4244.96s] i think people we were so surprised by\n",
            "[4242.72s → 4246.00s] how well large models worked is that\n",
            "[4244.96s → 4247.84s] actually\n",
            "[4246.00s → 4249.44s] it's very hard for our human minds our\n",
            "[4247.84s → 4250.88s] limited human minds to understand what\n",
            "[4249.44s → 4252.56s] it would be like to read the whole\n",
            "[4250.88s → 4254.24s] internet right i think we can do a\n",
            "[4252.56s → 4256.00s] thought experiment and i used to do this\n",
            "[4254.24s → 4257.36s] of like well what if i read the whole of\n",
            "[4256.00s → 4259.12s] wikipedia\n",
            "[4257.36s → 4260.80s] what would i know and i think our minds\n",
            "[4259.12s → 4262.48s] can just about comprehend maybe what\n",
            "[4260.80s → 4264.72s] that would be like but the whole\n",
            "[4262.48s → 4266.32s] internet is beyond comprehension so i\n",
            "[4264.72s → 4268.64s] think we just don't understand what it\n",
            "[4266.32s → 4271.20s] would be like to be able to hold all of\n",
            "[4268.64s → 4273.76s] that in mind potentially right and then\n",
            "[4271.20s → 4275.60s] active at once and then maybe what are\n",
            "[4273.76s → 4277.12s] the connections that are available there\n",
            "[4275.60s → 4279.12s] so i think no doubt there are huge\n",
            "[4277.12s → 4281.36s] things to be discovered just like that\n",
            "[4279.12s → 4283.84s] but i do think there is this other type\n",
            "[4281.36s → 4286.16s] of creativity of true spark of new\n",
            "[4283.84s → 4288.00s] knowledge new idea never thought before\n",
            "[4286.16s → 4290.72s] about can't be average from things that\n",
            "[4288.00s → 4292.64s] are known um that really of course\n",
            "[4290.72s → 4294.48s] everything come you know nobody creates\n",
            "[4292.64s → 4296.96s] in a vacuum so there must be clues\n",
            "[4294.48s → 4298.72s] somewhere but just a unique way of\n",
            "[4296.96s → 4299.92s] putting those things together i think\n",
            "[4298.72s → 4302.00s] some of the greatest scientists in\n",
            "[4299.92s → 4304.08s] history have displayed that i would say\n",
            "[4302.00s → 4305.84s] although it's very hard to know going\n",
            "[4304.08s → 4307.76s] back to their time what was exactly\n",
            "[4305.84s → 4310.08s] known uh when they came up with those\n",
            "[4307.76s → 4311.68s] things although\n",
            "[4310.08s → 4313.92s] you're making me really think because\n",
            "[4311.68s → 4317.20s] just the thought experiment of deeply\n",
            "[4313.92s → 4319.04s] knowing a hundred wikipedia pages\n",
            "[4317.20s → 4321.28s] i don't think i can um\n",
            "[4319.04s → 4323.68s] i've been really impressed by wikipedia\n",
            "[4321.28s → 4326.88s] for for technical topics yeah so if you\n",
            "[4323.68s → 4329.20s] know a hundred pages or a thousand pages\n",
            "[4326.88s → 4331.20s] i don't think who can visually truly\n",
            "[4329.20s → 4333.28s] comprehend what's\n",
            "[4331.20s → 4334.88s] what kind of intelligence that is that's\n",
            "[4333.28s → 4336.80s] a pretty powerful intelligence if you\n",
            "[4334.88s → 4338.48s] know how to use that and integrate that\n",
            "[4336.80s → 4340.40s] information correctly yes i think you\n",
            "[4338.48s → 4342.56s] can go really far you can probably\n",
            "[4340.40s → 4343.60s] construct thought experiments based on\n",
            "[4342.56s → 4346.24s] that\n",
            "[4343.60s → 4348.16s] like simulate different ideas so if this\n",
            "[4346.24s → 4350.16s] is true let me run this thought\n",
            "[4348.16s → 4352.40s] experiment then maybe this is true it's\n",
            "[4350.16s → 4355.20s] not really invention it's like just\n",
            "[4352.40s → 4357.12s] taking literally the knowledge and using\n",
            "[4355.20s → 4359.04s] it to construct a very basic simulation\n",
            "[4357.12s → 4361.04s] of the world i mean some argue it's\n",
            "[4359.04s → 4363.04s] romantic in part but einstein would do\n",
            "[4361.04s → 4365.04s] the same kind of things with a thought\n",
            "[4363.04s → 4367.20s] experiment yeah one could imagine doing\n",
            "[4365.04s → 4369.52s] that systematically across millions of\n",
            "[4367.20s → 4372.00s] wikipedia pages plus pubmed all these\n",
            "[4369.52s → 4373.68s] things i think there are\n",
            "[4372.00s → 4375.44s] many many things to be discovered like\n",
            "[4373.68s → 4377.04s] that they're hugely useful you know you\n",
            "[4375.44s → 4378.48s] could imagine and i want us to do some\n",
            "[4377.04s → 4380.00s] of those things in material science like\n",
            "[4378.48s → 4382.08s] room temperature superconductors or\n",
            "[4380.00s → 4384.16s] something on my list one day i'd like to\n",
            "[4382.08s → 4386.72s] like you know have an ai system to help\n",
            "[4384.16s → 4388.96s] build better optimized batteries all of\n",
            "[4386.72s → 4391.68s] these sort of mechanical things mr i\n",
            "[4388.96s → 4393.04s] think a systematic sort of search could\n",
            "[4391.68s → 4395.60s] be uh\n",
            "[4393.04s → 4398.00s] guided by a model could be um could be\n",
            "[4395.60s → 4400.88s] extremely powerful so speaking of which\n",
            "[4398.00s → 4402.96s] you have a paper on nuclear fusion\n",
            "[4400.88s → 4406.32s] uh magnetic control of tokamak plasmas\n",
            "[4402.96s → 4408.08s] to deep reinforcement learning so you uh\n",
            "[4406.32s → 4409.60s] you're seeking to solve nuclear fusion\n",
            "[4408.08s → 4410.72s] with deep rl\n",
            "[4409.60s → 4412.48s] so it's doing control of high\n",
            "[4410.72s → 4413.44s] temperature plasmas can you explain this\n",
            "[4412.48s → 4415.84s] work\n",
            "[4413.44s → 4417.12s] and uh can ai eventually solve nuclear\n",
            "[4415.84s → 4419.28s] fusion\n",
            "[4417.12s → 4420.56s] it's been very fun last year or two and\n",
            "[4419.28s → 4422.32s] very productive because we've been\n",
            "[4420.56s → 4424.08s] taking off a lot of my\n",
            "[4422.32s → 4425.92s] dream projects if you like of things\n",
            "[4424.08s → 4428.08s] that i've collected over the years of\n",
            "[4425.92s → 4429.84s] areas of science that i would like to i\n",
            "[4428.08s → 4432.32s] think could be very transformative if we\n",
            "[4429.84s → 4433.92s] helped accelerate and uh really\n",
            "[4432.32s → 4435.76s] interesting problems scientific\n",
            "[4433.92s → 4438.56s] challenges in of themselves\n",
            "[4435.76s → 4440.56s] this is energy so energy yes exactly so\n",
            "[4438.56s → 4442.24s] energy and climate so we talked about\n",
            "[4440.56s → 4444.40s] disease and biology as being one of the\n",
            "[4442.24s → 4446.64s] biggest places i think ai can help with\n",
            "[4444.40s → 4449.44s] i think energy and climate uh is another\n",
            "[4446.64s → 4451.60s] one so maybe they would be my top two um\n",
            "[4449.44s → 4454.40s] and fusion is one one area i think ai\n",
            "[4451.60s → 4456.56s] can help with now fusion has many\n",
            "[4454.40s → 4458.16s] challenges mostly physics material\n",
            "[4456.56s → 4459.84s] science and engineering challenges as\n",
            "[4458.16s → 4461.92s] well to build these massive fusion\n",
            "[4459.84s → 4463.68s] reactors and contain the plasma and what\n",
            "[4461.92s → 4464.96s] we try to do whenever we go into a new\n",
            "[4463.68s → 4467.52s] field\n",
            "[4464.96s → 4469.44s] to apply our systems is we look for um\n",
            "[4467.52s → 4470.64s] we talk to domain experts we try and\n",
            "[4469.44s → 4472.80s] find the best people in the world to\n",
            "[4470.64s → 4474.40s] collaborate with um\n",
            "[4472.80s → 4476.16s] in this case in fusion we we\n",
            "[4474.40s → 4477.44s] collaborated with epfl in switzerland\n",
            "[4476.16s → 4479.68s] the swiss technical institute who are\n",
            "[4477.44s → 4481.44s] amazing they have a test reactor that\n",
            "[4479.68s → 4483.12s] they were willing to let us use which\n",
            "[4481.44s → 4484.56s] you know i double checked with the team\n",
            "[4483.12s → 4485.84s] we were going to use carefully and\n",
            "[4484.56s → 4487.36s] safely\n",
            "[4485.84s → 4490.56s] i was impressed they managed to persuade\n",
            "[4487.36s → 4492.64s] them to let us use it and um and it's a\n",
            "[4490.56s → 4495.12s] it's an amazing test reactor they have\n",
            "[4492.64s → 4498.16s] there and they try all sorts of pretty\n",
            "[4495.12s → 4499.92s] crazy experiments on it and um the the\n",
            "[4498.16s → 4502.00s] the what we tend to look at is if we go\n",
            "[4499.92s → 4504.24s] into a new domain like fusion what are\n",
            "[4502.00s → 4505.76s] all the bottleneck problems uh like\n",
            "[4504.24s → 4506.80s] thinking from first principles you know\n",
            "[4505.76s → 4508.32s] what are all the bottleneck problems\n",
            "[4506.80s → 4510.32s] that are still stopping fusion working\n",
            "[4508.32s → 4512.16s] today and then we look at we you know we\n",
            "[4510.32s → 4513.92s] get a fusion expert to tell us and then\n",
            "[4512.16s → 4516.24s] we look at those bottlenecks and we look\n",
            "[4513.92s → 4519.44s] at the ones which ones are amenable to\n",
            "[4516.24s → 4521.12s] our ai methods today yes right and and\n",
            "[4519.44s → 4522.72s] and then and would be interesting from a\n",
            "[4521.12s → 4524.48s] research perspective from our point of\n",
            "[4522.72s → 4526.56s] view from an ai point of view and that\n",
            "[4524.48s → 4528.80s] would address one of their bottlenecks\n",
            "[4526.56s → 4531.20s] and in this case plasma control was was\n",
            "[4528.80s → 4532.80s] perfect so you know the plasma it's a\n",
            "[4531.20s → 4534.88s] million degrees celsius something like\n",
            "[4532.80s → 4536.48s] that it's hotter than the sun\n",
            "[4534.88s → 4538.08s] and there's obviously no material that\n",
            "[4536.48s → 4540.16s] can contain it so they have to be\n",
            "[4538.08s → 4542.56s] containing these magnetic very powerful\n",
            "[4540.16s → 4544.80s] superconducting magnetic fields but the\n",
            "[4542.56s → 4546.32s] problem is plasma is pretty unstable as\n",
            "[4544.80s → 4549.60s] you imagine you're kind of holding a\n",
            "[4546.32s → 4551.36s] mini sun mini star in a reactor so you\n",
            "[4549.60s → 4552.40s] know you you kind of want to predict\n",
            "[4551.36s → 4554.56s] ahead of time\n",
            "[4552.40s → 4556.80s] what the plasma's going to do so you can\n",
            "[4554.56s → 4559.04s] move the magnetic field within a few\n",
            "[4556.80s → 4561.04s] milliseconds you know to to basically\n",
            "[4559.04s → 4562.48s] contain what it's going to do next so it\n",
            "[4561.04s → 4564.24s] seems like a perfect problem if you\n",
            "[4562.48s → 4566.88s] think of it for like a reinforcement\n",
            "[4564.24s → 4568.40s] learning prediction problem so uh you\n",
            "[4566.88s → 4570.72s] know your controller you're gonna move\n",
            "[4568.40s → 4572.08s] the magnetic field and until we came\n",
            "[4570.72s → 4574.40s] along you know they were they were doing\n",
            "[4572.08s → 4576.96s] it with with traditional operational uh\n",
            "[4574.40s → 4578.64s] research type of uh controllers uh which\n",
            "[4576.96s → 4580.00s] are kind of handcrafted and the problem\n",
            "[4578.64s → 4581.44s] is of course they can't react in the\n",
            "[4580.00s → 4583.12s] moment to something the plasma's doing\n",
            "[4581.44s → 4585.04s] that they have to be hard-coded and\n",
            "[4583.12s → 4586.88s] again knowing that that's normally our\n",
            "[4585.04s → 4588.48s] go-to solution is we would like to learn\n",
            "[4586.88s → 4590.48s] that instead and they also had a\n",
            "[4588.48s → 4592.48s] simulator of these plasma so there were\n",
            "[4590.48s → 4594.72s] lots of criteria that matched what we we\n",
            "[4592.48s → 4597.60s] like to to to use\n",
            "[4594.72s → 4599.76s] so can ai eventually solve nuclear\n",
            "[4597.60s → 4601.28s] fusion well so we with this problem and\n",
            "[4599.76s → 4604.08s] we published it in a nature paper last\n",
            "[4601.28s → 4606.16s] year uh we held the fusion that we held\n",
            "[4604.08s → 4607.84s] the plasma in specific shapes so\n",
            "[4606.16s → 4610.00s] actually it's almost like carving the\n",
            "[4607.84s → 4612.00s] plasma into different shapes and control\n",
            "[4610.00s → 4614.48s] and hold it there for the record amount\n",
            "[4612.00s → 4617.44s] of time so um so that's one of the\n",
            "[4614.48s → 4619.84s] problems of of fusion sort of um solved\n",
            "[4617.44s → 4622.32s] so i have a controller that's able to no\n",
            "[4619.84s → 4624.08s] matter the shape uh contain it continue\n",
            "[4622.32s → 4625.36s] yeah contain it and hold it in structure\n",
            "[4624.08s → 4627.68s] and there's different shapes that are\n",
            "[4625.36s → 4630.64s] better for for the energy productions\n",
            "[4627.68s → 4632.56s] called droplets and and and so on so um\n",
            "[4630.64s → 4634.32s] so that was huge and now we're looking\n",
            "[4632.56s → 4636.24s] we're talking to lots of fusion startups\n",
            "[4634.32s → 4639.28s] to see what's the next problem we can\n",
            "[4636.24s → 4642.16s] tackle uh in the fusion area\n",
            "[4639.28s → 4643.92s] so another fascinating place\n",
            "[4642.16s → 4645.68s] in a paper title pushing the frontiers\n",
            "[4643.92s → 4647.76s] of density functionals by solving the\n",
            "[4645.68s → 4649.28s] fractional electron problem so you're\n",
            "[4647.76s → 4651.44s] taking on\n",
            "[4649.28s → 4654.88s] modeling and simulating the quantum\n",
            "[4651.44s → 4655.92s] mechanical behavior of electrons yes\n",
            "[4654.88s → 4658.48s] um\n",
            "[4655.92s → 4660.64s] can you explain this work and can ai\n",
            "[4658.48s → 4662.40s] model and simulate arbitrary quantum\n",
            "[4660.64s → 4664.00s] mechanical systems in the future yeah so\n",
            "[4662.40s → 4667.36s] this is another problem i've had my eye\n",
            "[4664.00s → 4668.48s] on for you know a decade or more which\n",
            "[4667.36s → 4670.48s] is um\n",
            "[4668.48s → 4672.64s] uh sort of simulating the properties of\n",
            "[4670.48s → 4675.36s] electrons if you can do that you can\n",
            "[4672.64s → 4678.72s] basically describe how elements and\n",
            "[4675.36s → 4680.40s] materials and substances work so it's\n",
            "[4678.72s → 4683.68s] kind of like fundamental if you want to\n",
            "[4680.40s → 4685.20s] advance material science um and uh you\n",
            "[4683.68s → 4686.72s] know we have schrodinger's equation and\n",
            "[4685.20s → 4688.88s] then we have approximations to that\n",
            "[4686.72s → 4691.44s] density functional theory these things\n",
            "[4688.88s → 4694.00s] are you know are famous and um people\n",
            "[4691.44s → 4696.32s] try and write approximations to to these\n",
            "[4694.00s → 4698.80s] uh uh to these functionals and and kind\n",
            "[4696.32s → 4700.56s] of come up with descriptions of the\n",
            "[4698.80s → 4702.48s] electron clouds where they're gonna go\n",
            "[4700.56s → 4704.96s] how they're gonna interact when you put\n",
            "[4702.48s → 4707.60s] two elements together uh and what we try\n",
            "[4704.96s → 4709.76s] to do is learn a simulation uh uh\n",
            "[4707.60s → 4712.88s] learner functional that will describe\n",
            "[4709.76s → 4714.72s] more chemistry types of chemistry so um\n",
            "[4712.88s → 4716.24s] until now you know you can run expensive\n",
            "[4714.72s → 4718.96s] simulations but then you can only\n",
            "[4716.24s → 4720.64s] simulate very small uh molecules very\n",
            "[4718.96s → 4723.92s] simple molecules we would like to\n",
            "[4720.64s → 4725.76s] simulate large materials um and so uh\n",
            "[4723.92s → 4727.84s] today there's no way of doing that and\n",
            "[4725.76s → 4729.76s] we're building up towards uh building\n",
            "[4727.84s → 4732.00s] functionals that approximate\n",
            "[4729.76s → 4734.64s] schrodinger's equation and then allow\n",
            "[4732.00s → 4735.68s] you to describe uh what the electrons\n",
            "[4734.64s → 4737.44s] are doing\n",
            "[4735.68s → 4739.20s] and all materials sort of science and\n",
            "[4737.44s → 4742.32s] material properties are governed by the\n",
            "[4739.20s → 4744.48s] electrons and and how they interact so\n",
            "[4742.32s → 4747.36s] have a good summarization of the\n",
            "[4744.48s → 4748.64s] simulation through the functional\n",
            "[4747.36s → 4750.88s] um\n",
            "[4748.64s → 4752.40s] but one that is still\n",
            "[4750.88s → 4755.52s] close to what the actual simulation\n",
            "[4752.40s → 4756.80s] would come out with so what um\n",
            "[4755.52s → 4758.24s] how difficult is that to ask what's\n",
            "[4756.80s → 4758.96s] involved in that task is it running\n",
            "[4758.24s → 4761.20s] those\n",
            "[4758.96s → 4763.52s] those complicated simulations yeah and\n",
            "[4761.20s → 4765.20s] learning the task of mapping from the\n",
            "[4763.52s → 4766.80s] initial conditions and the parameters of\n",
            "[4765.20s → 4768.80s] the simulation learning what the\n",
            "[4766.80s → 4771.04s] functional would be yeah so it's pretty\n",
            "[4768.80s → 4772.88s] tricky and we've done it with um you\n",
            "[4771.04s → 4775.20s] know the nice thing is we there are we\n",
            "[4772.88s → 4777.44s] can run a lot of the simulations that\n",
            "[4775.20s → 4779.60s] the molecular dynamics simulations on\n",
            "[4777.44s → 4781.36s] our compute clusters and so that\n",
            "[4779.60s → 4784.00s] generates a lot of data so in this case\n",
            "[4781.36s → 4785.44s] the data is generated so we like those\n",
            "[4784.00s → 4788.32s] sort of systems and that's why we use\n",
            "[4785.44s → 4789.68s] games simulator generated data\n",
            "[4788.32s → 4792.08s] and we can kind of create as much of it\n",
            "[4789.68s → 4794.00s] as we want really um and just let's\n",
            "[4792.08s → 4796.24s] leave some you know if any computers are\n",
            "[4794.00s → 4798.16s] free in the cloud we just run we run\n",
            "[4796.24s → 4800.08s] some of these calculations right compute\n",
            "[4798.16s → 4801.76s] cluster calculation that's all the the\n",
            "[4800.08s → 4803.36s] free compute times used up on quantum\n",
            "[4801.76s → 4805.36s] mechanics quantum mechanics exactly\n",
            "[4803.36s → 4808.32s] simulations and protein simulations and\n",
            "[4805.36s → 4810.16s] other things and so um and so you know\n",
            "[4808.32s → 4811.84s] when you're not searching on youtube for\n",
            "[4810.16s → 4813.60s] video cat videos we're using those\n",
            "[4811.84s → 4814.80s] computers usefully and quantum chemistry\n",
            "[4813.60s → 4817.04s] that's the idea\n",
            "[4814.80s → 4818.48s] and and putting them for good use and\n",
            "[4817.04s → 4820.88s] then yeah and then all of that\n",
            "[4818.48s → 4822.64s] computational data that's generated we\n",
            "[4820.88s → 4824.48s] can then try and learn the functionals\n",
            "[4822.64s → 4825.52s] from that which of course are way more\n",
            "[4824.48s → 4828.08s] efficient\n",
            "[4825.52s → 4830.40s] once we learn the functional than um\n",
            "[4828.08s → 4833.12s] running those simulations would be\n",
            "[4830.40s → 4835.84s] do you think one day ai may allow us to\n",
            "[4833.12s → 4837.84s] do something like basically crack open\n",
            "[4835.84s → 4839.44s] physics so do something like travel\n",
            "[4837.84s → 4841.60s] faster than the speed of light\n",
            "[4839.44s → 4842.40s] my ultimate aim has always been with ai\n",
            "[4841.60s → 4845.12s] is\n",
            "[4842.40s → 4847.68s] um the reason i am personally working on\n",
            "[4845.12s → 4849.76s] ai for my whole life it was to build a\n",
            "[4847.68s → 4852.56s] tool to help us understand stand the\n",
            "[4849.76s → 4854.88s] universe so i wanted to and that means\n",
            "[4852.56s → 4855.60s] physics really and the nature of reality\n",
            "[4854.88s → 4856.56s] so\n",
            "[4855.60s → 4858.00s] um\n",
            "[4856.56s → 4859.76s] uh i don't think we have systems that\n",
            "[4858.00s → 4862.00s] are capable of doing that yet but when\n",
            "[4859.76s → 4863.44s] we get towards agi i think um that's one\n",
            "[4862.00s → 4865.20s] of the first things i think we should\n",
            "[4863.44s → 4866.56s] apply agi to\n",
            "[4865.20s → 4868.40s] i would like to test the limits of\n",
            "[4866.56s → 4869.92s] physics and our knowledge of physics\n",
            "[4868.40s → 4871.52s] there's so many things we don't know\n",
            "[4869.92s → 4873.36s] there's one thing i find fascinating\n",
            "[4871.52s → 4875.12s] about science and you know as a huge\n",
            "[4873.36s → 4876.40s] proponent of the scientific method as\n",
            "[4875.12s → 4878.48s] being one of the greatest ideas\n",
            "[4876.40s → 4880.16s] humanity's ever had and allowed us to\n",
            "[4878.48s → 4882.16s] progress with our knowledge\n",
            "[4880.16s → 4884.48s] but i think as a true scientist i think\n",
            "[4882.16s → 4886.24s] what you find is the more you find out\n",
            "[4884.48s → 4886.96s] uh you the more you realize we don't\n",
            "[4886.24s → 4889.04s] know\n",
            "[4886.96s → 4890.96s] and and i always think that it's\n",
            "[4889.04s → 4892.72s] surprising that more people don't aren't\n",
            "[4890.96s → 4894.56s] troubled you know every night i think\n",
            "[4892.72s → 4896.08s] about all these things we interact with\n",
            "[4894.56s → 4897.84s] all the time that we have no idea how\n",
            "[4896.08s → 4900.08s] they work time\n",
            "[4897.84s → 4902.08s] consciousness gravity\n",
            "[4900.08s → 4904.16s] life we can't i mean these are all the\n",
            "[4902.08s → 4907.28s] fundamental things of nature i think the\n",
            "[4904.16s → 4910.32s] way we don't really know what they are\n",
            "[4907.28s → 4912.72s] to live life we uh pin certain\n",
            "[4910.32s → 4914.64s] assumptions on them and kind of treat\n",
            "[4912.72s → 4916.96s] our assumptions as if they're a fact\n",
            "[4914.64s → 4918.88s] yeah that allows us to sort of box them\n",
            "[4916.96s → 4921.12s] off somehow yeah box them off\n",
            "[4918.88s → 4922.24s] but the reality is when you think of\n",
            "[4921.12s → 4924.40s] time\n",
            "[4922.24s → 4925.68s] you should remind yourself you should\n",
            "[4924.40s → 4927.52s] put it off the sh\n",
            "[4925.68s → 4928.88s] take it off the shelf and realize like\n",
            "[4927.52s → 4930.72s] no we have a bunch of assumptions\n",
            "[4928.88s → 4931.92s] there's still a lot of there's even now\n",
            "[4930.72s → 4935.12s] a lot of debate there's a lot of\n",
            "[4931.92s → 4937.60s] uncertainty about exactly what is time\n",
            "[4935.12s → 4939.04s] uh is there an error of time you know\n",
            "[4937.60s → 4940.16s] there's there's a lot of fundamental\n",
            "[4939.04s → 4942.64s] questions you can't just make\n",
            "[4940.16s → 4945.60s] assumptions about and maybe\n",
            "[4942.64s → 4947.68s] ai allows you to um\n",
            "[4945.60s → 4950.16s] not put anything on the shelf\n",
            "[4947.68s → 4951.92s] yeah not make any uh hard assumptions\n",
            "[4950.16s → 4953.36s] and really open it up and see what\n",
            "[4951.92s → 4956.08s] exactly i think we should be truly\n",
            "[4953.36s → 4958.24s] open-minded about that and uh exactly\n",
            "[4956.08s → 4959.20s] that not be dogmatic to a particular\n",
            "[4958.24s → 4962.32s] theory\n",
            "[4959.20s → 4965.36s] um it'll also allow us to build better\n",
            "[4962.32s → 4967.28s] tools experimental tools eventually\n",
            "[4965.36s → 4969.52s] that can then test certain theories that\n",
            "[4967.28s → 4970.80s] may not be testable today about as\n",
            "[4969.52s → 4972.08s] things about like\n",
            "[4970.80s → 4973.60s] what we spoke about at the beginning\n",
            "[4972.08s → 4976.16s] about the computational nature of the\n",
            "[4973.60s → 4978.00s] universe how one might if that was true\n",
            "[4976.16s → 4980.32s] how one might go about testing that\n",
            "[4978.00s → 4981.68s] right and and how much uh you know there\n",
            "[4980.32s → 4984.08s] are people who've conjectured people\n",
            "[4981.68s → 4986.16s] like uh scott aronson and others about\n",
            "[4984.08s → 4988.96s] uh you know how much information can a\n",
            "[4986.16s → 4990.88s] specific planck unit of space and time\n",
            "[4988.96s → 4993.28s] contain right so one might be able to\n",
            "[4990.88s → 4994.72s] think about testing those ideas if you\n",
            "[4993.28s → 4998.08s] had um\n",
            "[4994.72s → 5000.88s] ai helping you build some new exquisite\n",
            "[4998.08s → 5002.80s] uh uh experimental tools this is what i\n",
            "[5000.88s → 5004.08s] imagine you know many decades from now\n",
            "[5002.80s → 5005.68s] we'll be able to do\n",
            "[5004.08s → 5006.88s] and what kind of\n",
            "[5005.68s → 5008.56s] questions can be answered through\n",
            "[5006.88s → 5011.12s] running a simulation\n",
            "[5008.56s → 5012.56s] of of them so there's a bunch of physics\n",
            "[5011.12s → 5013.52s] simulations you can imagine that could\n",
            "[5012.56s → 5016.56s] be run\n",
            "[5013.52s → 5018.40s] in an uh so some kind of efficient way\n",
            "[5016.56s → 5021.12s] much like you're doing in the quantum\n",
            "[5018.40s → 5023.12s] simulation work\n",
            "[5021.12s → 5024.80s] and perhaps even the origin of life so\n",
            "[5023.12s → 5027.68s] figuring out how\n",
            "[5024.80s → 5029.76s] going even back before the work of alpha\n",
            "[5027.68s → 5031.36s] fault begins of how this whole whole\n",
            "[5029.76s → 5034.64s] thing\n",
            "[5031.36s → 5036.64s] um emerges from a rock yes from a static\n",
            "[5034.64s → 5038.56s] thing would what do you do you think ai\n",
            "[5036.64s → 5040.96s] will allow us to is that something you\n",
            "[5038.56s → 5042.56s] have your eye on it's trying to\n",
            "[5040.96s → 5043.68s] understand the origin of life first of\n",
            "[5042.56s → 5045.20s] all yourself\n",
            "[5043.68s → 5046.24s] what do you think\n",
            "[5045.20s → 5048.64s] um\n",
            "[5046.24s → 5050.56s] how the heck did life originate on earth\n",
            "[5048.64s → 5052.88s] yeah well maybe we i'll come to that in\n",
            "[5050.56s → 5054.88s] a second but i think the ultimate\n",
            "[5052.88s → 5057.04s] use of ai is to\n",
            "[5054.88s → 5059.44s] kind of use it to accelerate science to\n",
            "[5057.04s → 5061.28s] the maximum so i\n",
            "[5059.44s → 5062.96s] um think of it a little bit like the\n",
            "[5061.28s → 5064.24s] tree of all knowledge if you imagine\n",
            "[5062.96s → 5065.76s] that's all the knowledge there is in the\n",
            "[5064.24s → 5067.68s] universe to attain\n",
            "[5065.76s → 5070.08s] and we sort of barely scratched the\n",
            "[5067.68s → 5071.84s] surface of that so far in even though\n",
            "[5070.08s → 5073.20s] you know we've we've done pretty well\n",
            "[5071.84s → 5075.92s] since the enlightenment right as\n",
            "[5073.20s → 5077.44s] humanity and i think ai will turbo\n",
            "[5075.92s → 5080.16s] charge all of that like we've seen with\n",
            "[5077.44s → 5081.60s] alpha fold and i want to explore as much\n",
            "[5080.16s → 5084.80s] of that tree of knowledge as it's\n",
            "[5081.60s → 5087.20s] possible to do and um and i think that\n",
            "[5084.80s → 5089.68s] involves ai helping us with with with\n",
            "[5087.20s → 5091.60s] understanding or finding patterns um but\n",
            "[5089.68s → 5093.84s] also potentially designing and building\n",
            "[5091.60s → 5095.92s] new tools experimental tools so i think\n",
            "[5093.84s → 5097.52s] that's all uh\n",
            "[5095.92s → 5099.52s] and also running simulations and\n",
            "[5097.52s → 5102.40s] learning simulations all of that we're\n",
            "[5099.52s → 5105.04s] already we're sort of doing it at a at a\n",
            "[5102.40s → 5107.68s] at a you know baby steps level here but\n",
            "[5105.04s → 5110.32s] i can imagine that in in in the decades\n",
            "[5107.68s → 5112.80s] to come as uh you know what's the full\n",
            "[5110.32s → 5114.40s] flourishing of of that line of thinking\n",
            "[5112.80s → 5116.32s] it's going to be truly incredible i\n",
            "[5114.40s → 5118.64s] would say if i visualize this tree of\n",
            "[5116.32s → 5120.32s] knowledge something tells me that that\n",
            "[5118.64s → 5122.80s] knowledge for tree of knowledge for\n",
            "[5120.32s → 5124.48s] humans is much smaller\n",
            "[5122.80s → 5127.12s] in the set of all possible trees of\n",
            "[5124.48s → 5128.88s] knowledge is actually quite small giving\n",
            "[5127.12s → 5131.60s] our cognitive\n",
            "[5128.88s → 5134.08s] limitations\n",
            "[5131.60s → 5135.92s] limited cognitive capabilities that even\n",
            "[5134.08s → 5137.28s] with with the tools we build we still\n",
            "[5135.92s → 5140.56s] won't be able to understand a lot of\n",
            "[5137.28s → 5142.72s] things and that's perhaps what non-human\n",
            "[5140.56s → 5144.80s] systems might be able to reach farther\n",
            "[5142.72s → 5146.64s] not just as tools\n",
            "[5144.80s → 5148.88s] but in themselves understanding\n",
            "[5146.64s → 5151.04s] something that they can bring back yeah\n",
            "[5148.88s → 5153.28s] it could well be so i mean there's so\n",
            "[5151.04s → 5154.88s] many things that that are sort of\n",
            "[5153.28s → 5157.20s] encapsulated in what you just said there\n",
            "[5154.88s → 5158.16s] i think first of all um\n",
            "[5157.20s → 5159.92s] there's there's two different things\n",
            "[5158.16s → 5161.68s] there's like what do we understand today\n",
            "[5159.92s → 5163.92s] yeah what could the human mind\n",
            "[5161.68s → 5165.76s] understand and what is the totality of\n",
            "[5163.92s → 5168.40s] what is there to be understood yeah\n",
            "[5165.76s → 5169.60s] right and so there's three consensus you\n",
            "[5168.40s → 5171.12s] know you can think of them as three\n",
            "[5169.60s → 5173.44s] larger and larger trees or exploring\n",
            "[5171.12s → 5174.96s] more branches of that tree and i i think\n",
            "[5173.44s → 5177.84s] with ai we're going to explore that\n",
            "[5174.96s → 5179.76s] whole lot now the question is is uh you\n",
            "[5177.84s → 5182.56s] know if you think about what is the\n",
            "[5179.76s → 5184.32s] totality of what could be understood um\n",
            "[5182.56s → 5185.76s] there may be some fundamental physics\n",
            "[5184.32s → 5187.12s] reasons why certain things can't be\n",
            "[5185.76s → 5189.44s] understood like what's outside the\n",
            "[5187.12s → 5191.12s] simulation or outside the universe maybe\n",
            "[5189.44s → 5192.16s] it's not understandable from within the\n",
            "[5191.12s → 5193.52s] universe\n",
            "[5192.16s → 5194.96s] so that's there may be some hard\n",
            "[5193.52s → 5196.88s] constraints like that you know it could\n",
            "[5194.96s → 5200.16s] be smaller constraints like\n",
            "[5196.88s → 5202.24s] um we think of space time as fundamental\n",
            "[5200.16s → 5203.92s] us our human brains are really used to\n",
            "[5202.24s → 5205.28s] this idea of a three-dimensional world\n",
            "[5203.92s → 5207.68s] with time right\n",
            "[5205.28s → 5209.20s] maybe but our tools could go beyond that\n",
            "[5207.68s → 5210.64s] they wouldn't have that limitation\n",
            "[5209.20s → 5212.16s] necessary they could think in 11\n",
            "[5210.64s → 5214.56s] dimensions 12 dimensions whatever is\n",
            "[5212.16s → 5216.32s] needed but um we could still maybe\n",
            "[5214.56s → 5218.88s] understand that in several different\n",
            "[5216.32s → 5220.80s] ways the example i always give is um\n",
            "[5218.88s → 5222.56s] when i you know play gary kasparov at\n",
            "[5220.80s → 5224.80s] speed chess or we've talked about chess\n",
            "[5222.56s → 5226.56s] and these kind of things um you know he\n",
            "[5224.80s → 5229.52s] if you if you if you're reasonably good\n",
            "[5226.56s → 5231.44s] at chess you can um you can't come up\n",
            "[5229.52s → 5233.36s] with the move gary comes up with in his\n",
            "[5231.44s → 5234.32s] move but he can explain it to you and\n",
            "[5233.36s → 5236.72s] you can understand and you can\n",
            "[5234.32s → 5238.48s] understand post hoc the reasoning yeah\n",
            "[5236.72s → 5239.92s] so so i think there's a there's an even\n",
            "[5238.48s → 5241.76s] further level of like well maybe you\n",
            "[5239.92s → 5243.28s] couldn't have invented that thing but\n",
            "[5241.76s → 5244.96s] but using like going back to using\n",
            "[5243.28s → 5247.36s] language again perhaps you can\n",
            "[5244.96s → 5249.44s] understand and appreciate that same way\n",
            "[5247.36s → 5251.36s] like you can appreciate you know vivaldi\n",
            "[5249.44s → 5253.52s] or mozart or something without you can\n",
            "[5251.36s → 5255.52s] appreciate the beauty of that without um\n",
            "[5253.52s → 5257.52s] being able to to construct it yourself\n",
            "[5255.52s → 5259.20s] right invent the music yourself so i\n",
            "[5257.52s → 5261.52s] think we see this in all forms of life\n",
            "[5259.20s → 5263.76s] so it'll be that times you know\n",
            "[5261.52s → 5266.08s] a million but it would you can imagine\n",
            "[5263.76s → 5268.08s] also one sign of intelligence is the\n",
            "[5266.08s → 5269.76s] ability to explain things clearly and\n",
            "[5268.08s → 5270.88s] simply right you know people like\n",
            "[5269.76s → 5272.32s] richard feynman another one of my\n",
            "[5270.88s → 5274.08s] all-time heroes used to say that right\n",
            "[5272.32s → 5276.16s] if you can't you know if you can explain\n",
            "[5274.08s → 5278.16s] it something simply then you that's a\n",
            "[5276.16s → 5279.44s] that's the best sign a complex topic\n",
            "[5278.16s → 5281.60s] simply then that's one of the best signs\n",
            "[5279.44s → 5283.28s] of you understanding it yeah so i can\n",
            "[5281.60s → 5285.60s] see myself talking trash in the ai\n",
            "[5283.28s → 5288.24s] system in that way yes uh\n",
            "[5285.60s → 5289.92s] it gets frustrated how dumb i am and\n",
            "[5288.24s → 5290.96s] trying to explain something to me i was\n",
            "[5289.92s → 5292.08s] like well that means you're not\n",
            "[5290.96s → 5293.60s] intelligent because if you were\n",
            "[5292.08s → 5295.76s] intelligent you'd be able to explain it\n",
            "[5293.60s → 5297.20s] simply yeah of course you know there's\n",
            "[5295.76s → 5298.96s] also the other option of course we could\n",
            "[5297.20s → 5301.04s] enhance ourselves and and without\n",
            "[5298.96s → 5303.20s] devices we we are already sort of\n",
            "[5301.04s → 5305.04s] symbiotic with our compute devices right\n",
            "[5303.20s → 5307.04s] with our phones and other things and you\n",
            "[5305.04s → 5308.72s] know this stuff like neural link and etc\n",
            "[5307.04s → 5311.28s] that could be could could advance that\n",
            "[5308.72s → 5313.52s] further um so i think there's lots of\n",
            "[5311.28s → 5315.52s] lots of really amazing possibilities uh\n",
            "[5313.52s → 5317.28s] that i could foresee from here well let\n",
            "[5315.52s → 5318.08s] me ask you some wild questions so out\n",
            "[5317.28s → 5319.84s] there\n",
            "[5318.08s → 5321.20s] looking for friends\n",
            "[5319.84s → 5323.04s] do you think there's a lot of alien\n",
            "[5321.20s → 5325.12s] civilizations out there\n",
            "[5323.04s → 5326.88s] so i guess this also goes back to your\n",
            "[5325.12s → 5328.32s] origin of life question too because i\n",
            "[5326.88s → 5329.28s] think that that's key\n",
            "[5328.32s → 5331.36s] um\n",
            "[5329.28s → 5332.80s] my personal opinion looking at all this\n",
            "[5331.36s → 5335.76s] and and you know it's one of my hobbies\n",
            "[5332.80s → 5337.12s] physics i guess so so i i you know it's\n",
            "[5335.76s → 5339.60s] something i think about a lot and talk\n",
            "[5337.12s → 5342.08s] to a lot of experts on and and and read\n",
            "[5339.60s → 5344.32s] a lot of books on and i think\n",
            "[5342.08s → 5346.64s] my feeling currently is that that we are\n",
            "[5344.32s → 5348.48s] alone i think that's the most likely\n",
            "[5346.64s → 5351.52s] scenario given what what evidence we\n",
            "[5348.48s → 5352.88s] have so um and the reasoning is i think\n",
            "[5351.52s → 5354.96s] that\n",
            "[5352.88s → 5357.12s] you know we've tried since uh things\n",
            "[5354.96s → 5360.08s] like seti program and i guess since the\n",
            "[5357.12s → 5361.76s] dawning of the the space age uh we've\n",
            "[5360.08s → 5364.08s] you know had telescopes open radio\n",
            "[5361.76s → 5367.20s] telescopes and other things and if you\n",
            "[5364.08s → 5368.88s] think about um and try to detect signals\n",
            "[5367.20s → 5371.20s] now if you think about the evolution of\n",
            "[5368.88s → 5374.40s] humans on earth we could have easily\n",
            "[5371.20s → 5376.48s] been um a million years ahead of our\n",
            "[5374.40s → 5378.72s] time now or million years behind quite\n",
            "[5376.48s → 5380.64s] easily with just some slightly different\n",
            "[5378.72s → 5382.56s] quirk thing happening hundreds of\n",
            "[5380.64s → 5383.68s] thousands years ago uh you know things\n",
            "[5382.56s → 5385.60s] could have been slightly different if\n",
            "[5383.68s → 5386.80s] the bto had hit the dinosaurs a million\n",
            "[5385.60s → 5389.60s] years earlier maybe things would have\n",
            "[5386.80s → 5391.28s] evolved uh we'd be a million years\n",
            "[5389.60s → 5393.36s] ahead of where we are now so what that\n",
            "[5391.28s → 5395.84s] means is if you imagine where humanity\n",
            "[5393.36s → 5397.92s] will be in a few hundred years let alone\n",
            "[5395.84s → 5399.52s] a million years especially if we\n",
            "[5397.92s → 5400.80s] hopefully um\n",
            "[5399.52s → 5402.80s] you know solve things like climate\n",
            "[5400.80s → 5404.08s] change and other things and we continue\n",
            "[5402.80s → 5406.00s] to flourish\n",
            "[5404.08s → 5407.84s] and we build things like ai and we do\n",
            "[5406.00s → 5410.00s] space traveling and all of the stuff\n",
            "[5407.84s → 5411.76s] that that humans have dreamed of for\n",
            "[5410.00s → 5414.32s] forever right and sci-fi has talked\n",
            "[5411.76s → 5416.40s] about forever um\n",
            "[5414.32s → 5418.16s] we will be spreading across the stars\n",
            "[5416.40s → 5419.84s] right and void neumann famously\n",
            "[5418.16s → 5421.28s] calculated you know it would only take\n",
            "[5419.84s → 5423.28s] about a million years if you send out\n",
            "[5421.28s → 5425.28s] von neumann probes to the nearest you\n",
            "[5423.28s → 5427.52s] know the nearest uh uh other solar\n",
            "[5425.28s → 5429.04s] systems and and then they built all they\n",
            "[5427.52s → 5430.56s] did was build two more versions of\n",
            "[5429.04s → 5432.56s] themselves and set those two out to the\n",
            "[5430.56s → 5433.92s] next nearest systems uh you you know\n",
            "[5432.56s → 5435.76s] within a million years i think you would\n",
            "[5433.92s → 5438.32s] have one of these probes in every system\n",
            "[5435.76s → 5440.32s] in the galaxy so it's not actually in\n",
            "[5438.32s → 5442.00s] cosmo cosmological time that's actually\n",
            "[5440.32s → 5443.76s] a very short amount of time\n",
            "[5442.00s → 5445.52s] so and and you know we've people like\n",
            "[5443.76s → 5447.68s] dyson have thought about constructing\n",
            "[5445.52s → 5449.68s] dyson spheres around stars to collect\n",
            "[5447.68s → 5450.80s] all the energy coming out of the star\n",
            "[5449.68s → 5452.40s] you know that there would be\n",
            "[5450.80s → 5455.04s] constructions like that would be visible\n",
            "[5452.40s → 5457.60s] across base um probably even across a\n",
            "[5455.04s → 5460.16s] galaxy so and then you know if you think\n",
            "[5457.60s → 5462.16s] about all of our radio television uh\n",
            "[5460.16s → 5465.52s] emissions that have gone out since since\n",
            "[5462.16s → 5468.32s] the you know 30s and 40s um imagine a\n",
            "[5465.52s → 5470.24s] million years of that and now hundreds\n",
            "[5468.32s → 5472.64s] of civilizations doing that when we\n",
            "[5470.24s → 5474.80s] opened our ears at the point we got\n",
            "[5472.64s → 5477.12s] technologically sophisticated enough in\n",
            "[5474.80s → 5479.20s] the space age we should have\n",
            "[5477.12s → 5480.88s] heard a cacophony of voices we should\n",
            "[5479.20s → 5482.96s] have joined that cacophony of voices and\n",
            "[5480.88s → 5484.40s] what we did we opened our ears and we\n",
            "[5482.96s → 5486.56s] heard nothing\n",
            "[5484.40s → 5488.24s] and many people who argue that there are\n",
            "[5486.56s → 5490.40s] aliens would say well we haven't really\n",
            "[5488.24s → 5492.40s] done exhaustive search yet and maybe\n",
            "[5490.40s → 5493.84s] we're looking in the wrong bands and and\n",
            "[5492.40s → 5495.76s] we've got the wrong devices and we\n",
            "[5493.84s → 5497.28s] wouldn't notice what an alien form was\n",
            "[5495.76s → 5499.44s] like to be so different to what we're\n",
            "[5497.28s → 5501.52s] used to but you know i'm not i don't\n",
            "[5499.44s → 5503.36s] really buy that that it shouldn't be as\n",
            "[5501.52s → 5504.96s] difficult as that like we i think we've\n",
            "[5503.36s → 5506.48s] searched enough there should be if it\n",
            "[5504.96s → 5508.56s] were everywhere if it was it should be\n",
            "[5506.48s → 5510.48s] everywhere we should see dyson's fears\n",
            "[5508.56s → 5511.52s] being put up sun's blinking in and out\n",
            "[5510.48s → 5513.12s] you know there should be a lot of\n",
            "[5511.52s → 5514.80s] evidence for those things and then there\n",
            "[5513.12s → 5516.56s] are other people argue well the sort of\n",
            "[5514.80s → 5517.84s] safari view of like well we're a\n",
            "[5516.56s → 5520.00s] primitive species still because we're\n",
            "[5517.84s → 5521.52s] not space faring yet and and and we're\n",
            "[5520.00s → 5523.68s] you know there's some kind of globe like\n",
            "[5521.52s → 5525.76s] universal rule not to interfere star\n",
            "[5523.68s → 5527.68s] trek rule but like look look we can't\n",
            "[5525.76s → 5530.24s] even coordinate humans to deal with\n",
            "[5527.68s → 5532.00s] climate change and we're one species\n",
            "[5530.24s → 5533.68s] what is the chance that of all of these\n",
            "[5532.00s → 5535.28s] different human civilization you know\n",
            "[5533.68s → 5538.08s] alien civilizations they would have the\n",
            "[5535.28s → 5540.08s] same priorities and and and and agree\n",
            "[5538.08s → 5542.32s] across you know these kind of matters\n",
            "[5540.08s → 5545.12s] and even if that was true and we were in\n",
            "[5542.32s → 5546.40s] some sort of safari for our own good to\n",
            "[5545.12s → 5548.00s] me that's not much different from the\n",
            "[5546.40s → 5549.76s] simulation hypothesis because what does\n",
            "[5548.00s → 5551.36s] it mean the simulation hypothesis i\n",
            "[5549.76s → 5553.76s] think in its most fundamental level it\n",
            "[5551.36s → 5555.60s] means what we're seeing is not quite\n",
            "[5553.76s → 5557.60s] reality right it's something there's\n",
            "[5555.60s → 5560.16s] something more deeper underlying it\n",
            "[5557.60s → 5562.64s] maybe computational now if we were in a\n",
            "[5560.16s → 5564.24s] if we were in a sort of safari park and\n",
            "[5562.64s → 5565.92s] everything we were seeing was a hologram\n",
            "[5564.24s → 5567.28s] and it was projected by the aliens or\n",
            "[5565.92s → 5569.12s] whatever that to me is not much\n",
            "[5567.28s → 5570.88s] different than thinking we're inside of\n",
            "[5569.12s → 5573.44s] another universe because we still can't\n",
            "[5570.88s → 5575.52s] see true reality right i mean there's\n",
            "[5573.44s → 5576.72s] there's other explanations it could be\n",
            "[5575.52s → 5578.08s] that\n",
            "[5576.72s → 5579.76s] the way they're communicating is just\n",
            "[5578.08s → 5581.92s] fundamentally different that we're too\n",
            "[5579.76s → 5583.92s] dumb to understand the much better\n",
            "[5581.92s → 5586.48s] methods of communication they have it\n",
            "[5583.92s → 5587.36s] could be i mean i mean it's silly to say\n",
            "[5586.48s → 5590.00s] but\n",
            "[5587.36s → 5591.92s] our own thoughts could be the methods by\n",
            "[5590.00s → 5593.68s] which they're communicating like the\n",
            "[5591.92s → 5597.20s] place from which our ideas writers talk\n",
            "[5593.68s → 5600.24s] about this like the muse yeah\n",
            "[5597.20s → 5602.24s] it sounds like very kind of uh\n",
            "[5600.24s → 5602.96s] wild but it could be thoughts it could\n",
            "[5602.24s → 5605.44s] be\n",
            "[5602.96s → 5607.44s] some interactions with our mind that we\n",
            "[5605.44s → 5610.72s] think are originating from\n",
            "[5607.44s → 5612.48s] us is actually something that uh\n",
            "[5610.72s → 5614.40s] is coming from other life forms\n",
            "[5612.48s → 5616.40s] elsewhere consciousness itself might be\n",
            "[5614.40s → 5618.40s] that it could be but i don't see any\n",
            "[5616.40s → 5621.20s] sensible argument to the why why would\n",
            "[5618.40s → 5622.56s] all of the alien species be using this\n",
            "[5621.20s → 5623.92s] way yes some of them will be more\n",
            "[5622.56s → 5625.76s] primitive they would be close to our\n",
            "[5623.92s → 5627.60s] level you know there would there should\n",
            "[5625.76s → 5629.04s] be a whole sort of normal distribution\n",
            "[5627.60s → 5631.44s] of these things right some would be\n",
            "[5629.04s → 5634.24s] aggressive some would be you know\n",
            "[5631.44s → 5636.08s] curious others would be very stoical and\n",
            "[5634.24s → 5637.92s] philosophical because you know maybe\n",
            "[5636.08s → 5640.16s] they're a million years older than us\n",
            "[5637.92s → 5642.40s] but it's not it shouldn't be like what i\n",
            "[5640.16s → 5643.84s] mean one one alien civilization might be\n",
            "[5642.40s → 5645.68s] like that communicating thoughts and\n",
            "[5643.84s → 5647.68s] others but i don't see why you know\n",
            "[5645.68s → 5650.00s] potentially the hundreds there should be\n",
            "[5647.68s → 5652.08s] would be uniform in this way right it\n",
            "[5650.00s → 5655.20s] could be a violent dictatorship that the\n",
            "[5652.08s → 5657.68s] the people the alien civilizations that\n",
            "[5655.20s → 5658.77s] uh become successful\n",
            "[5657.68s → 5660.56s] become um\n",
            "[5658.77s → 5663.20s] [Music]\n",
            "[5660.56s → 5665.92s] gain the ability to be destructive an\n",
            "[5663.20s → 5669.84s] order of magnitude more destructive\n",
            "[5665.92s → 5670.64s] but of course the the sad thought\n",
            "[5669.84s → 5673.20s] well\n",
            "[5670.64s → 5675.68s] either humans are very special we took a\n",
            "[5673.20s → 5677.76s] lot of leaps that arrived at what it\n",
            "[5675.68s → 5678.64s] means to be human yeah\n",
            "[5677.76s → 5680.48s] um\n",
            "[5678.64s → 5682.80s] there's a question there which was the\n",
            "[5680.48s → 5685.12s] hardest which was the most special but\n",
            "[5682.80s → 5686.64s] also if others have reached this level\n",
            "[5685.12s → 5687.76s] and maybe many others have reached this\n",
            "[5686.64s → 5690.32s] level\n",
            "[5687.76s → 5692.80s] the great filter\n",
            "[5690.32s → 5695.12s] that prevented them from going farther\n",
            "[5692.80s → 5697.68s] to becoming a multi-planetary species or\n",
            "[5695.12s → 5699.60s] reaching out into the stars\n",
            "[5697.68s → 5701.36s] and those are really important questions\n",
            "[5699.60s → 5702.32s] for us whether\n",
            "[5701.36s → 5703.44s] um\n",
            "[5702.32s → 5705.12s] whether there's other alien\n",
            "[5703.44s → 5707.44s] civilizations out there or not this is\n",
            "[5705.12s → 5709.12s] very useful for us to think about if we\n",
            "[5707.44s → 5711.60s] destroy ourselves\n",
            "[5709.12s → 5713.92s] how will we do it and how easy is it to\n",
            "[5711.60s → 5715.28s] do yeah well you know these are big\n",
            "[5713.92s → 5717.12s] questions and i've thought about these a\n",
            "[5715.28s → 5719.68s] lot but the the the interesting thing is\n",
            "[5717.12s → 5721.04s] that if we're if we're alone\n",
            "[5719.68s → 5722.64s] that's somewhat comforting from the\n",
            "[5721.04s → 5724.32s] great filter perspective because it\n",
            "[5722.64s → 5726.40s] probably means the great filters were\n",
            "[5724.32s → 5728.08s] are past us and i'm pretty sure they are\n",
            "[5726.40s → 5729.84s] so that by in going back to your origin\n",
            "[5728.08s → 5731.60s] of life question there are some\n",
            "[5729.84s → 5733.44s] incredible things that no one knows how\n",
            "[5731.60s → 5736.08s] happened like obviously the first\n",
            "[5733.44s → 5738.00s] life form from chemical soup that seems\n",
            "[5736.08s → 5739.60s] pretty hard but i would guess the\n",
            "[5738.00s → 5741.76s] multicellular i wouldn't be that\n",
            "[5739.60s → 5743.92s] surprised if we saw single\n",
            "[5741.76s → 5745.92s] single cell sort of life forms elsewhere\n",
            "[5743.92s → 5748.16s] uh bacteria type things but\n",
            "[5745.92s → 5749.52s] multicellular life seems incredibly hard\n",
            "[5748.16s → 5751.92s] that step of you know capturing\n",
            "[5749.52s → 5753.60s] mitochondria and then sort of using that\n",
            "[5751.92s → 5755.04s] as part of yourself you know when you've\n",
            "[5753.60s → 5756.40s] just eaten it would you say that's the\n",
            "[5755.04s → 5759.12s] biggest\n",
            "[5756.40s → 5761.52s] the most uh like\n",
            "[5759.12s → 5763.28s] if if you had to choose one sort of uh\n",
            "[5761.52s → 5766.16s] hitchhiker's got this galaxy one\n",
            "[5763.28s → 5767.92s] sentence summary of like oh those clever\n",
            "[5766.16s → 5769.60s] creatures did this that would be the\n",
            "[5767.92s → 5770.96s] multilist i think that was probably the\n",
            "[5769.60s → 5772.56s] one that that's the biggest i mean\n",
            "[5770.96s → 5774.64s] there's a great book called the 10 grand\n",
            "[5772.56s → 5777.20s] great inventions of evolution by nick\n",
            "[5774.64s → 5779.92s] lane and he speculates on 10 10 of these\n",
            "[5777.20s → 5781.52s] you know what could be great filters um\n",
            "[5779.92s → 5784.24s] i think that's one i think the the\n",
            "[5781.52s → 5786.00s] advent of of intelligence and and\n",
            "[5784.24s → 5787.52s] conscious intelligence and in order you\n",
            "[5786.00s → 5790.00s] know to us to be able to do science and\n",
            "[5787.52s → 5791.92s] things like that is huge as well i mean\n",
            "[5790.00s → 5795.36s] it's only evolved once as far as you\n",
            "[5791.92s → 5797.68s] know uh in in earth history so that\n",
            "[5795.36s → 5799.04s] would be a later candidate but there's\n",
            "[5797.68s → 5801.28s] certainly for the early candidates i\n",
            "[5799.04s → 5802.80s] think multicellular life forms is huge\n",
            "[5801.28s → 5805.68s] by the way what it's interesting to ask\n",
            "[5802.80s → 5808.40s] you if you can hypothesize about\n",
            "[5805.68s → 5809.44s] what is the origin of intelligence is it\n",
            "[5808.40s → 5811.04s] uh\n",
            "[5809.44s → 5813.52s] that we started\n",
            "[5811.04s → 5815.52s] cooking meat over fire\n",
            "[5813.52s → 5817.36s] is it that we somehow figured out that\n",
            "[5815.52s → 5820.80s] we could be very powerful when we start\n",
            "[5817.36s → 5823.44s] collaborating so cooperation between\n",
            "[5820.80s → 5826.24s] um our ancestors\n",
            "[5823.44s → 5828.00s] so that we can overthrow the alpha male\n",
            "[5826.24s → 5829.60s] uh what is it richard i talked to\n",
            "[5828.00s → 5831.44s] richard randham who thinks we're all\n",
            "[5829.60s → 5833.84s] just beta males who figured out how to\n",
            "[5831.44s → 5836.72s] collaborate to defeat the one the\n",
            "[5833.84s → 5839.36s] dictator the authoritarian alpha male\n",
            "[5836.72s → 5842.72s] um that control the tribe um is there\n",
            "[5839.36s → 5844.80s] other explanation did was there um 2001\n",
            "[5842.72s → 5847.12s] space out any type of monolith yeah that\n",
            "[5844.80s → 5848.32s] came down to earth well i i think um i\n",
            "[5847.12s → 5850.48s] think all of those things you suggest\n",
            "[5848.32s → 5852.32s] for good candidates fire and and and\n",
            "[5850.48s → 5854.16s] cooking right so that's clearly\n",
            "[5852.32s → 5856.40s] important\n",
            "[5854.16s → 5858.88s] you know energy efficiency yeah cooking\n",
            "[5856.40s → 5860.88s] our meat and then and then being able to\n",
            "[5858.88s → 5863.36s] to to be more efficient about eating it\n",
            "[5860.88s → 5865.12s] and getting it consuming the energy um i\n",
            "[5863.36s → 5866.88s] think that's huge and then utilizing\n",
            "[5865.12s → 5869.04s] fire and tools i think you're right\n",
            "[5866.88s → 5870.64s] about the the tribal cooperation aspects\n",
            "[5869.04s → 5872.40s] and probably language as part of that\n",
            "[5870.64s → 5874.08s] yes um because probably that's what\n",
            "[5872.40s → 5876.64s] allowed us to outcompete neanderthals\n",
            "[5874.08s → 5879.44s] and and perhaps less cooperative species\n",
            "[5876.64s → 5882.88s] so um so that may be the case tool\n",
            "[5879.44s → 5884.48s] making spears axes i think that let us i\n",
            "[5882.88s → 5886.00s] mean i think it's pretty clear now that\n",
            "[5884.48s → 5888.64s] humans were responsible for a lot of the\n",
            "[5886.00s → 5891.28s] extinctions of megafauna um especially\n",
            "[5888.64s → 5894.08s] in in the americas when humans arrived\n",
            "[5891.28s → 5895.84s] so uh you can imagine once you discover\n",
            "[5894.08s → 5898.08s] tool usage how powerful that would have\n",
            "[5895.84s → 5899.52s] been and how scary for animals so i\n",
            "[5898.08s → 5901.28s] think all of those could have been\n",
            "[5899.52s → 5903.12s] explanations for it you know the\n",
            "[5901.28s → 5905.04s] interesting thing is that it's a bit\n",
            "[5903.12s → 5907.44s] like general intelligence too is it's\n",
            "[5905.04s → 5908.40s] very costly to begin with to have a\n",
            "[5907.44s → 5909.84s] brain\n",
            "[5908.40s → 5911.20s] and especially a general purpose brain\n",
            "[5909.84s → 5912.48s] rather than a special purpose one\n",
            "[5911.20s → 5914.08s] because the amount of energy our brains\n",
            "[5912.48s → 5916.32s] use i think it's like 20 of the body's\n",
            "[5914.08s → 5917.84s] energy and it's it's massive and when\n",
            "[5916.32s → 5919.84s] you're thinking chest one of the funny\n",
            "[5917.84s → 5922.48s] things that that we used to say is as\n",
            "[5919.84s → 5924.08s] much as a racing driver uses for a whole\n",
            "[5922.48s → 5925.68s] you know formula one race if just\n",
            "[5924.08s → 5926.88s] playing a game of you know serious high\n",
            "[5925.68s → 5929.12s] level chess which you you know you\n",
            "[5926.88s → 5931.20s] wouldn't think just sitting there um\n",
            "[5929.12s → 5933.20s] because the brain's using so much uh\n",
            "[5931.20s → 5935.76s] energy so in order for an animal an\n",
            "[5933.20s → 5939.12s] organism to justify that there has to be\n",
            "[5935.76s → 5941.92s] a huge payoff and the problem with with\n",
            "[5939.12s → 5945.20s] half a brain or half you know\n",
            "[5941.92s → 5947.52s] intelligence saying iqs of you know\n",
            "[5945.20s → 5949.52s] of like a monkey brain it's\n",
            "[5947.52s → 5951.28s] it's not clear you can justify that\n",
            "[5949.52s → 5953.52s] evolutionary until you get to the human\n",
            "[5951.28s → 5955.28s] level brain and so but how do you how do\n",
            "[5953.52s → 5956.72s] you do that jump it's very difficult\n",
            "[5955.28s → 5958.48s] which is why i think it's only been done\n",
            "[5956.72s → 5960.64s] once from the sort of specialized brains\n",
            "[5958.48s → 5963.76s] that you see in animals to this sort of\n",
            "[5960.64s → 5967.20s] general purpose chewing powerful brains\n",
            "[5963.76s → 5970.16s] that humans have um and which allows us\n",
            "[5967.20s → 5972.72s] to invent the modern modern world um and\n",
            "[5970.16s → 5974.32s] uh you know it takes a lot to to cross\n",
            "[5972.72s → 5976.56s] that barrier and i think we've seen the\n",
            "[5974.32s → 5978.64s] same with ai systems which is that uh\n",
            "[5976.56s → 5980.80s] maybe until very recently it's always\n",
            "[5978.64s → 5982.88s] been easier to craft a specific solution\n",
            "[5980.80s → 5984.48s] to a problem like chess than it has been\n",
            "[5982.88s → 5986.32s] to build a general learning system that\n",
            "[5984.48s → 5988.64s] could potentially do many things because\n",
            "[5986.32s → 5991.04s] initially uh that system will be way\n",
            "[5988.64s → 5992.64s] worse than uh less efficient than the\n",
            "[5991.04s → 5993.76s] specialized system so one of the\n",
            "[5992.64s → 5997.60s] interesting\n",
            "[5993.76s → 5999.84s] quirks of the human mind of this evolved\n",
            "[5997.60s → 6001.20s] system is that it appears to be\n",
            "[5999.84s → 6002.32s] conscious\n",
            "[6001.20s → 6005.44s] this thing that we don't quite\n",
            "[6002.32s → 6007.60s] understand but it seems very\n",
            "[6005.44s → 6009.52s] very special its ability to have a\n",
            "[6007.60s → 6010.96s] subjective experience that it feels like\n",
            "[6009.52s → 6013.36s] something\n",
            "[6010.96s → 6015.52s] to eat a cookie the deliciousness of it\n",
            "[6013.36s → 6017.84s] or see a color and that kind of stuff do\n",
            "[6015.52s → 6019.60s] you think in order to solve intelligence\n",
            "[6017.84s → 6022.24s] we also need to solve consciousness\n",
            "[6019.60s → 6025.28s] along the way do you think agi systems\n",
            "[6022.24s → 6026.32s] need to have consciousness in order to\n",
            "[6025.28s → 6028.64s] be\n",
            "[6026.32s → 6031.76s] truly intelligent yeah we thought about\n",
            "[6028.64s → 6033.44s] this a lot actually and um i think that\n",
            "[6031.76s → 6035.84s] my guess is that consciousness and\n",
            "[6033.44s → 6037.44s] intelligence are double dissociable so\n",
            "[6035.84s → 6040.16s] you can have one without the other both\n",
            "[6037.44s → 6042.08s] ways and i think you can see that with\n",
            "[6040.16s → 6044.96s] consciousness in that i think some\n",
            "[6042.08s → 6046.88s] animals and pets if you have a pet dog\n",
            "[6044.96s → 6048.40s] or something like that you can see some\n",
            "[6046.88s → 6050.32s] of the higher animals and dolphins\n",
            "[6048.40s → 6054.56s] things like that are uh have\n",
            "[6050.32s → 6057.20s] self-awareness and uh very sociable um\n",
            "[6054.56s → 6059.04s] seem to dream um you know those kinds of\n",
            "[6057.20s → 6061.68s] a lot of the traits one would regard as\n",
            "[6059.04s → 6064.24s] being kind of conscious and self-aware\n",
            "[6061.68s → 6066.24s] um and but yet they're not that smart\n",
            "[6064.24s → 6068.56s] right uh so they're not that intelligent\n",
            "[6066.24s → 6070.48s] by by say iq standards or something like\n",
            "[6068.56s → 6072.80s] that yeah it's also possible that our\n",
            "[6070.48s → 6075.28s] understanding of intelligence is flawed\n",
            "[6072.80s → 6077.28s] like putting an iq to it sure maybe the\n",
            "[6075.28s → 6079.84s] thing that a dog can do\n",
            "[6077.28s → 6081.44s] is actually gone very far along the path\n",
            "[6079.84s → 6082.40s] of intelligence and we humans are just\n",
            "[6081.44s → 6084.96s] able to\n",
            "[6082.40s → 6086.96s] play chess and maybe write poems right\n",
            "[6084.96s → 6088.40s] but if we go back to the idea of agi and\n",
            "[6086.96s → 6090.00s] general intelligence you know dogs are\n",
            "[6088.40s → 6091.44s] very specialized right most animals are\n",
            "[6090.00s → 6093.20s] pretty specialized they can be amazing\n",
            "[6091.44s → 6095.52s] at what they do but they're like kind of\n",
            "[6093.20s → 6097.68s] elite sports sports people or something\n",
            "[6095.52s → 6099.44s] right so they do one thing extremely\n",
            "[6097.68s → 6101.20s] well because their entire brain is is\n",
            "[6099.44s → 6103.04s] optimized they have somehow convinced\n",
            "[6101.20s → 6104.96s] the entirety of the human population to\n",
            "[6103.04s → 6107.12s] feed them and service them so in some\n",
            "[6104.96s → 6109.60s] way they're controlling yes exactly well\n",
            "[6107.12s → 6111.60s] we co-evolved to some crazy degree right\n",
            "[6109.60s → 6113.84s] uh including the the way the dogs you\n",
            "[6111.60s → 6115.60s] know even even wag their tails and\n",
            "[6113.84s → 6118.80s] twitch their noses right we find we're\n",
            "[6115.60s → 6121.04s] finding inexorably cute yeah um but i\n",
            "[6118.80s → 6122.64s] think um you can also see intelligence\n",
            "[6121.04s → 6125.36s] on the other side so systems like\n",
            "[6122.64s → 6127.52s] artificial systems that are amazingly\n",
            "[6125.36s → 6129.60s] smart at certain things like maybe\n",
            "[6127.52s → 6132.32s] playing go and chess and other things\n",
            "[6129.60s → 6134.56s] but they don't feel at all in any shape\n",
            "[6132.32s → 6138.56s] or form conscious in the way that you\n",
            "[6134.56s → 6140.00s] know you do to me or i do to you and um\n",
            "[6138.56s → 6141.36s] and i think actually\n",
            "[6140.00s → 6144.24s] building ai\n",
            "[6141.36s → 6145.84s] is uh these intelligent constructs uh is\n",
            "[6144.24s → 6147.28s] one of the best ways to explore the\n",
            "[6145.84s → 6150.16s] mystery of consciousness to break it\n",
            "[6147.28s → 6152.24s] down because um we're going to have\n",
            "[6150.16s → 6154.48s] devices that are\n",
            "[6152.24s → 6156.64s] pretty smart at certain things or\n",
            "[6154.48s → 6159.12s] capable of certain things but\n",
            "[6156.64s → 6160.96s] potentially won't have any semblance of\n",
            "[6159.12s → 6162.56s] self-awareness or other things and in\n",
            "[6160.96s → 6164.80s] fact i would advocate\n",
            "[6162.56s → 6166.96s] if there's a choice building systems in\n",
            "[6164.80s → 6169.28s] the first place ai systems that are not\n",
            "[6166.96s → 6172.32s] conscious to begin with uh are just\n",
            "[6169.28s → 6174.32s] tools um until we understand them better\n",
            "[6172.32s → 6176.48s] and the capabilities better so on that\n",
            "[6174.32s → 6179.28s] topic just not\n",
            "[6176.48s → 6180.80s] as the ceo of deep mind\n",
            "[6179.28s → 6182.88s] just as a human being let me ask you\n",
            "[6180.80s → 6185.20s] about this one particular anecdotal\n",
            "[6182.88s → 6187.12s] evidence of the google engineer\n",
            "[6185.20s → 6188.00s] who made a comment\n",
            "[6187.12s → 6190.16s] or\n",
            "[6188.00s → 6191.68s] believed that there's some aspect of a\n",
            "[6190.16s → 6194.40s] language model\n",
            "[6191.68s → 6195.84s] the lambda language model that exhibited\n",
            "[6194.40s → 6197.60s] sentience\n",
            "[6195.84s → 6199.44s] so you said you believe there might be a\n",
            "[6197.60s → 6202.40s] responsibility to build systems that are\n",
            "[6199.44s → 6204.72s] not essential and this experience of a\n",
            "[6202.40s → 6206.16s] particular engineer i think i'd love to\n",
            "[6204.72s → 6208.08s] get your general opinion on this kind of\n",
            "[6206.16s → 6209.44s] thing but i think it will happen more\n",
            "[6208.08s → 6211.92s] and more and more\n",
            "[6209.44s → 6213.04s] which uh not when engineers but when\n",
            "[6211.92s → 6214.64s] people out there that don't have an\n",
            "[6213.04s → 6217.04s] engineering background start interacting\n",
            "[6214.64s → 6219.92s] with increasingly intelligent systems\n",
            "[6217.04s → 6223.04s] we anthropomorphize them they they start\n",
            "[6219.92s → 6225.44s] to have deep impactful\n",
            "[6223.04s → 6227.92s] um interactions with us in a way that we\n",
            "[6225.44s → 6228.64s] miss them yeah when they're gone\n",
            "[6227.92s → 6230.80s] and\n",
            "[6228.64s → 6233.28s] we sure feel like they're\n",
            "[6230.80s → 6235.44s] living entities self-aware entities and\n",
            "[6233.28s → 6237.44s] maybe even we project sentience onto\n",
            "[6235.44s → 6238.88s] them so what what's your thought about\n",
            "[6237.44s → 6241.20s] this particular\n",
            "[6238.88s → 6242.96s] uh system was is uh\n",
            "[6241.20s → 6244.48s] have you ever met a language model\n",
            "[6242.96s → 6247.52s] that's sentient\n",
            "[6244.48s → 6248.96s] no i no no what do you make of the case\n",
            "[6247.52s → 6250.00s] of when you kind of\n",
            "[6248.96s → 6251.68s] feel\n",
            "[6250.00s → 6253.84s] that there's some elements of sentience\n",
            "[6251.68s → 6255.76s] to this system yeah so this is you know\n",
            "[6253.84s → 6257.84s] an interesting question and uh uh\n",
            "[6255.76s → 6259.92s] obviously a very fundamental one so\n",
            "[6257.84s → 6261.60s] first thing to say is i think that\n",
            "[6259.92s → 6264.32s] none of the systems we have today i i\n",
            "[6261.60s → 6266.16s] would say even have one iota of uh\n",
            "[6264.32s → 6268.32s] semblance of consciousness or sentience\n",
            "[6266.16s → 6270.24s] that's my personal feeling interacting\n",
            "[6268.32s → 6272.64s] with them every day so i think that's\n",
            "[6270.24s → 6274.56s] way premature to be discussing what that\n",
            "[6272.64s → 6275.84s] engineer talked about i appreciate i\n",
            "[6274.56s → 6277.76s] think at the moment it's more of a\n",
            "[6275.84s → 6279.20s] projection of the way our own minds work\n",
            "[6277.76s → 6282.96s] which is to see\n",
            "[6279.20s → 6284.64s] uh uh uh sort of purpose and direction\n",
            "[6282.96s → 6287.36s] in almost anything that we you know our\n",
            "[6284.64s → 6290.08s] brains are trained to interpret uh\n",
            "[6287.36s → 6292.48s] agency basically in things uh even the\n",
            "[6290.08s → 6294.88s] an inanimate thing sometimes and of\n",
            "[6292.48s → 6296.40s] course with a a language system because\n",
            "[6294.88s → 6297.76s] language is so fundamental to\n",
            "[6296.40s → 6300.24s] intelligence that's going to be easy for\n",
            "[6297.76s → 6303.44s] us to anthropomorphize that\n",
            "[6300.24s → 6304.96s] i mean back in the day even the first uh\n",
            "[6303.44s → 6307.60s] you know the dumbest sort of template\n",
            "[6304.96s → 6309.52s] chatbots ever eliza and and and and the\n",
            "[6307.60s → 6311.52s] ilk of the original chatbots back in the\n",
            "[6309.52s → 6313.20s] 60s fooled some people under certain\n",
            "[6311.52s → 6315.44s] circumstances right they pretended to be\n",
            "[6313.20s → 6317.04s] a psychologist so just basically rabbit\n",
            "[6315.44s → 6319.12s] back to you the same question you asked\n",
            "[6317.04s → 6321.36s] it back to you um\n",
            "[6319.12s → 6323.12s] and uh some people believe that so i\n",
            "[6321.36s → 6324.48s] don't think we can this is why i think\n",
            "[6323.12s → 6326.24s] the turing test is a little bit flawed\n",
            "[6324.48s → 6328.64s] as a formal test because it depends on\n",
            "[6326.24s → 6331.60s] the sophistication of the of the judge\n",
            "[6328.64s → 6334.16s] um whether or not they are qualified to\n",
            "[6331.60s → 6336.64s] make that distinction so\n",
            "[6334.16s → 6338.16s] i think we should uh talk to you know\n",
            "[6336.64s → 6340.24s] the the top philosophers about this\n",
            "[6338.16s → 6341.76s] people like daniel dennett and uh david\n",
            "[6340.24s → 6343.60s] chalmers and others who've obviously\n",
            "[6341.76s → 6345.28s] thought deeply about consciousness of\n",
            "[6343.60s → 6347.84s] course consciousness itself hasn't been\n",
            "[6345.28s → 6351.12s] well there's no agreed definition if i\n",
            "[6347.84s → 6353.20s] was to you know uh speculate about that\n",
            "[6351.12s → 6355.20s] uh you know i kind of the definite the\n",
            "[6353.20s → 6357.12s] working definition i like is it's the\n",
            "[6355.20s → 6359.12s] way information feels when you know it\n",
            "[6357.12s → 6360.88s] gets processed i think maybe max tegmark\n",
            "[6359.12s → 6362.08s] came up with that i like that idea i\n",
            "[6360.88s → 6364.48s] don't know if it helps us get towards\n",
            "[6362.08s → 6366.16s] any more operational thing but but it's\n",
            "[6364.48s → 6368.80s] it's it's i think it's a nice way of\n",
            "[6366.16s → 6370.16s] viewing it um i think we can obviously\n",
            "[6368.80s → 6371.76s] see from neuroscience certain\n",
            "[6370.16s → 6374.48s] prerequisites that are required like\n",
            "[6371.76s → 6376.72s] self-awareness i think is necessary but\n",
            "[6374.48s → 6379.44s] not sufficient component this idea of a\n",
            "[6376.72s → 6382.32s] self and other and set of coherent\n",
            "[6379.44s → 6384.32s] preferences that are coherent over time\n",
            "[6382.32s → 6386.56s] you know these things are maybe memory\n",
            "[6384.32s → 6389.60s] um these things are probably needed for\n",
            "[6386.56s → 6391.12s] a sentient or conscious being um but but\n",
            "[6389.60s → 6392.40s] the reason that the difficult thing i\n",
            "[6391.12s → 6393.28s] think for us when we get and i think\n",
            "[6392.40s → 6395.68s] this is a really interesting\n",
            "[6393.28s → 6398.88s] philosophical debate is when we get\n",
            "[6395.68s → 6400.64s] closer to agi and and and you know\n",
            "[6398.88s → 6401.84s] and and much more powerful systems than\n",
            "[6400.64s → 6403.44s] we have today\n",
            "[6401.84s → 6406.56s] um how are we going to make this\n",
            "[6403.44s → 6409.04s] judgment and one way which is the turing\n",
            "[6406.56s → 6410.64s] test is sort of a behavioral judgment is\n",
            "[6409.04s → 6414.08s] is the system exhibiting all the\n",
            "[6410.64s → 6415.60s] behaviors um that a human sentient uh or\n",
            "[6414.08s → 6417.60s] a sentient being would would would\n",
            "[6415.60s → 6419.04s] exhibit um is it answering the right\n",
            "[6417.60s → 6421.84s] questions is it saying the right things\n",
            "[6419.04s → 6423.28s] is it indistinguishable from a human um\n",
            "[6421.84s → 6425.92s] and so on\n",
            "[6423.28s → 6428.48s] but i think there's a second thing that\n",
            "[6425.92s → 6430.64s] makes us as humans regard each other as\n",
            "[6428.48s → 6432.00s] sentient right why do we why do we think\n",
            "[6430.64s → 6433.44s] this and i debated this with daniel\n",
            "[6432.00s → 6435.76s] dennett and i think there's a second\n",
            "[6433.44s → 6437.92s] reason that's often overlooked which is\n",
            "[6435.76s → 6439.76s] that we're running on the same substrate\n",
            "[6437.92s → 6442.80s] right so if we're exhibiting the same\n",
            "[6439.76s → 6444.32s] behavior uh more or less as humans and\n",
            "[6442.80s → 6446.16s] we're running on the same you know\n",
            "[6444.32s → 6448.32s] carbon-based biological substrate the\n",
            "[6446.16s → 6451.04s] squishy you know few pounds of of flesh\n",
            "[6448.32s → 6453.36s] in our skulls then the most parsimonious\n",
            "[6451.04s → 6454.88s] i think explanation is that you're\n",
            "[6453.36s → 6457.28s] feeling the same thing as i'm feeling\n",
            "[6454.88s → 6459.68s] right but we will never have that second\n",
            "[6457.28s → 6460.64s] part the substrate equivalence with a\n",
            "[6459.68s → 6462.64s] machine\n",
            "[6460.64s → 6464.48s] right so we will have to only judge\n",
            "[6462.64s → 6466.72s] based on the behavior and i think the\n",
            "[6464.48s → 6468.48s] substrate equivalence is a critical part\n",
            "[6466.72s → 6470.24s] of why we make assumptions that we're\n",
            "[6468.48s → 6472.00s] conscious and in fact even with with\n",
            "[6470.24s → 6473.28s] animals high-level animals why we think\n",
            "[6472.00s → 6474.56s] they might be because they're exhibiting\n",
            "[6473.28s → 6476.32s] some of the behaviors we would expect\n",
            "[6474.56s → 6477.44s] from a sentient animal and we know\n",
            "[6476.32s → 6479.04s] they're made of the same things\n",
            "[6477.44s → 6481.12s] biological neurons so we're gonna have\n",
            "[6479.04s → 6483.92s] to come up with\n",
            "[6481.12s → 6486.56s] explanations uh or models of the gap\n",
            "[6483.92s → 6489.28s] between substrate differences between\n",
            "[6486.56s → 6491.76s] machines and humans did to get anywhere\n",
            "[6489.28s → 6493.84s] beyond the behavioral but to me sort of\n",
            "[6491.76s → 6496.08s] the practical question is\n",
            "[6493.84s → 6498.24s] very interesting and very important when\n",
            "[6496.08s → 6500.00s] you have millions perhaps billions of\n",
            "[6498.24s → 6502.32s] people believing that you have ascension\n",
            "[6500.00s → 6503.92s] ai believing what that google engineer\n",
            "[6502.32s → 6506.40s] believed\n",
            "[6503.92s → 6509.20s] which i just see is an obvious\n",
            "[6506.40s → 6511.12s] very near-term future thing certainly on\n",
            "[6509.20s → 6513.04s] the path to agi\n",
            "[6511.12s → 6514.80s] how does that change the world\n",
            "[6513.04s → 6518.08s] what's the responsibility of the ai\n",
            "[6514.80s → 6519.68s] system to help those millions of people\n",
            "[6518.08s → 6520.88s] and also what's the ethical thing\n",
            "[6519.68s → 6523.52s] because\n",
            "[6520.88s → 6524.96s] you can you can make a lot of people\n",
            "[6523.52s → 6528.24s] happy\n",
            "[6524.96s → 6529.92s] by creating a meaningful deep experience\n",
            "[6528.24s → 6532.96s] with a system\n",
            "[6529.92s → 6534.40s] that's faking it before it makes it yeah\n",
            "[6532.96s → 6537.84s] and i i don't\n",
            "[6534.40s → 6540.72s] is a are we the right or who is to say\n",
            "[6537.84s → 6543.84s] what's the right thing to do should ai\n",
            "[6540.72s → 6546.08s] always be tools like why why why are we\n",
            "[6543.84s → 6547.20s] constraining ais to always be tools as\n",
            "[6546.08s → 6549.60s] opposed to\n",
            "[6547.20s → 6551.44s] friends yeah i think well i mean these\n",
            "[6549.60s → 6554.48s] are you know you know fantastic\n",
            "[6551.44s → 6556.56s] questions and and also critical ones and\n",
            "[6554.48s → 6558.40s] we've been thinking about this uh since\n",
            "[6556.56s → 6560.80s] the start of d minor before that because\n",
            "[6558.40s → 6562.64s] we planned for success and you know how\n",
            "[6560.80s → 6565.04s] how you know you know however remote\n",
            "[6562.64s → 6566.24s] that looked like back in 2010 and we've\n",
            "[6565.04s → 6567.92s] always had sort of these ethical\n",
            "[6566.24s → 6571.04s] considerations as fundamental at\n",
            "[6567.92s → 6572.80s] deepmind um and my current thinking on\n",
            "[6571.04s → 6574.40s] the language models is and and large\n",
            "[6572.80s → 6577.12s] models is they're not ready we don't\n",
            "[6574.40s → 6579.36s] understand them well enough yet um and\n",
            "[6577.12s → 6581.28s] you know in terms of analysis tools and\n",
            "[6579.36s → 6583.84s] and guard rails what they can and can't\n",
            "[6581.28s → 6586.08s] do and so on to deploy them at scale\n",
            "[6583.84s → 6587.52s] because i think you know there are big\n",
            "[6586.08s → 6589.60s] still ethical questions like should an\n",
            "[6587.52s → 6592.72s] ai system always announce that it is an\n",
            "[6589.60s → 6594.40s] ai system to begin with probably yes um\n",
            "[6592.72s → 6596.32s] it what what do you do about answering\n",
            "[6594.40s → 6598.48s] those philosophical questions about the\n",
            "[6596.32s → 6600.88s] feelings uh people may have about ai\n",
            "[6598.48s → 6602.48s] systems perhaps incorrectly attributed\n",
            "[6600.88s → 6605.28s] so i think there's a whole bunch of\n",
            "[6602.48s → 6607.12s] research that needs to be done first um\n",
            "[6605.28s → 6608.96s] to responsibly before you know you can\n",
            "[6607.12s → 6611.04s] responsibly deploy these systems at\n",
            "[6608.96s → 6612.40s] scale that would be at least be my\n",
            "[6611.04s → 6614.40s] current position\n",
            "[6612.40s → 6616.32s] over time i'm very confident we'll have\n",
            "[6614.40s → 6618.40s] those tools like interpretability\n",
            "[6616.32s → 6621.60s] questions um\n",
            "[6618.40s → 6623.52s] and uh analysis questions uh and then\n",
            "[6621.60s → 6624.88s] with the ethical quandary you know i\n",
            "[6623.52s → 6626.64s] think there\n",
            "[6624.88s → 6629.04s] it's important to\n",
            "[6626.64s → 6631.92s] uh look beyond just science that's why i\n",
            "[6629.04s → 6633.92s] think philosophy social sciences even\n",
            "[6631.92s → 6636.32s] theology other things like that come\n",
            "[6633.92s → 6638.64s] into it where um what you know arts and\n",
            "[6636.32s → 6640.40s] humanities what what does it mean to be\n",
            "[6638.64s → 6642.72s] human and the spirit of being human and\n",
            "[6640.40s → 6644.24s] and to enhance that and and the human\n",
            "[6642.72s → 6645.44s] condition right and allow us to\n",
            "[6644.24s → 6647.36s] experience things we could never\n",
            "[6645.44s → 6649.60s] experience before and improve the the\n",
            "[6647.36s → 6651.52s] overall human condition and humanity\n",
            "[6649.60s → 6653.20s] overall you know get radical abundance\n",
            "[6651.52s → 6655.28s] solve many scientific problems solve\n",
            "[6653.20s → 6657.12s] disease so this is the era i think this\n",
            "[6655.28s → 6659.76s] is the amazing era i think we're heading\n",
            "[6657.12s → 6661.44s] into if we do it right um but we've got\n",
            "[6659.76s → 6663.52s] to be careful we've already seen with\n",
            "[6661.44s → 6666.56s] things like social media how dual use\n",
            "[6663.52s → 6669.92s] technologies can be misused by firstly\n",
            "[6666.56s → 6672.24s] by by by bad you know p bad actors or\n",
            "[6669.92s → 6674.08s] naive actors or crazy actors right so\n",
            "[6672.24s → 6676.88s] there's that set of just the common or\n",
            "[6674.08s → 6679.12s] garden misuse of existing dual use\n",
            "[6676.88s → 6681.12s] technology and then of course there's an\n",
            "[6679.12s → 6683.04s] additional uh uh thing that has to be\n",
            "[6681.12s → 6686.00s] overcome with ai that eventually it may\n",
            "[6683.04s → 6688.80s] have its own agency so it could be uh uh\n",
            "[6686.00s → 6690.56s] uh good or bad in in in of itself so i\n",
            "[6688.80s → 6693.68s] think these questions have to be\n",
            "[6690.56s → 6695.60s] approached very carefully um using the\n",
            "[6693.68s → 6697.84s] scientific method i would say in terms\n",
            "[6695.60s → 6700.24s] of hypothesis generation careful control\n",
            "[6697.84s → 6702.32s] testing not live a b testing out in the\n",
            "[6700.24s → 6704.24s] world because with powerful dual\n",
            "[6702.32s → 6706.40s] technologies like ai\n",
            "[6704.24s → 6708.72s] if something goes wrong it may cause you\n",
            "[6706.40s → 6710.48s] know a lot of harm before you can fix it\n",
            "[6708.72s → 6713.20s] um it's not like a you know an imaging\n",
            "[6710.48s → 6715.20s] app or game app where you know that if\n",
            "[6713.20s → 6716.72s] if something goes wrong it's relatively\n",
            "[6715.20s → 6718.80s] easy to fix and and the harm's\n",
            "[6716.72s → 6721.36s] relatively small so i think\n",
            "[6718.80s → 6723.92s] it comes with you know the the the usual\n",
            "[6721.36s → 6725.28s] uh cliche of like with a lot of power\n",
            "[6723.92s → 6727.04s] comes a lot of responsibility and i\n",
            "[6725.28s → 6729.04s] think that's the case here with things\n",
            "[6727.04s → 6731.84s] like ai given the the enormous\n",
            "[6729.04s → 6734.64s] opportunity in front of us and i think\n",
            "[6731.84s → 6737.12s] we need a lot of voices uh and as many\n",
            "[6734.64s → 6739.12s] inputs into things like the design of\n",
            "[6737.12s → 6740.56s] the systems and the values\n",
            "[6739.12s → 6743.12s] they should have and what goals should\n",
            "[6740.56s → 6744.96s] they be put to um i think as wide a\n",
            "[6743.12s → 6747.12s] group of voices as possible beyond just\n",
            "[6744.96s → 6748.96s] the technologies is needed uh to input\n",
            "[6747.12s → 6750.56s] into that and to have a say in that\n",
            "[6748.96s → 6752.24s] especially when it comes to deployment\n",
            "[6750.56s → 6753.60s] of these systems which is when the\n",
            "[6752.24s → 6755.28s] rubber really hits the road it really\n",
            "[6753.60s → 6757.36s] affects the general person in the street\n",
            "[6755.28s → 6759.04s] rather than fundamental research and\n",
            "[6757.36s → 6760.56s] that's why i say\n",
            "[6759.04s → 6762.88s] i think as a first step it would be\n",
            "[6760.56s → 6765.52s] better if we have the choice to build\n",
            "[6762.88s → 6766.72s] these systems as tools to give and i'm\n",
            "[6765.52s → 6768.00s] not saying that it should never they\n",
            "[6766.72s → 6770.40s] should never go beyond tools because of\n",
            "[6768.00s → 6773.84s] course the potential is there um for it\n",
            "[6770.40s → 6775.84s] to go way beyond just tools uh but um i\n",
            "[6773.84s → 6777.84s] think that would be a good first step\n",
            "[6775.84s → 6779.52s] in order for us to you know allow us to\n",
            "[6777.84s → 6782.08s] carefully experiment understand what\n",
            "[6779.52s → 6786.08s] these things can do so the leap between\n",
            "[6782.08s → 6788.08s] tool to sentient entity being is one\n",
            "[6786.08s → 6790.96s] should take very careful yes\n",
            "[6788.08s → 6793.04s] let me ask a dark personal question\n",
            "[6790.96s → 6794.64s] so you're one of the most brilliant\n",
            "[6793.04s → 6795.60s] people in the ag community also one of\n",
            "[6794.64s → 6796.72s] the most\n",
            "[6795.60s → 6799.52s] kind\n",
            "[6796.72s → 6802.96s] and uh if i may say sort of loved people\n",
            "[6799.52s → 6804.16s] in the community that said\n",
            "[6802.96s → 6806.16s] uh\n",
            "[6804.16s → 6807.68s] creation of a super intelligent ai\n",
            "[6806.16s → 6809.60s] system\n",
            "[6807.68s → 6810.96s] would be one of the most\n",
            "[6809.60s → 6814.72s] powerful\n",
            "[6810.96s → 6817.76s] things in the world tools or otherwise\n",
            "[6814.72s → 6819.60s] and again as the old saying goes power\n",
            "[6817.76s → 6821.60s] corrupts and absolute power crops\n",
            "[6819.60s → 6823.36s] absolutely\n",
            "[6821.60s → 6825.12s] you are\n",
            "[6823.36s → 6827.44s] likely\n",
            "[6825.12s → 6829.76s] to be one of the people\n",
            "[6827.44s → 6831.84s] i would say probably the most likely\n",
            "[6829.76s → 6833.20s] person to be in the control of such a\n",
            "[6831.84s → 6835.04s] system\n",
            "[6833.20s → 6837.28s] do you think about\n",
            "[6835.04s → 6840.32s] the corrupting nature of power when you\n",
            "[6837.28s → 6842.96s] talk about these kinds of systems that\n",
            "[6840.32s → 6845.04s] um as all dictators\n",
            "[6842.96s → 6848.00s] and people have caused atrocities in the\n",
            "[6845.04s → 6849.92s] past always think they're doing good\n",
            "[6848.00s → 6852.16s] but they don't do good because the\n",
            "[6849.92s → 6854.24s] powers polluted their mind about what is\n",
            "[6852.16s → 6855.60s] good and what is evil do you think about\n",
            "[6854.24s → 6857.68s] this stuff or are we just focused on\n",
            "[6855.60s → 6860.48s] language modeling no i think about them\n",
            "[6857.68s → 6862.48s] all the time and you know i think\n",
            "[6860.48s → 6864.24s] what are the defenses against that i\n",
            "[6862.48s → 6866.56s] think one thing is to remain very\n",
            "[6864.24s → 6869.44s] grounded and sort of humble uh no matter\n",
            "[6866.56s → 6871.04s] what you do or achieve and i try to do\n",
            "[6869.44s → 6872.64s] that i might you know my best friends\n",
            "[6871.04s → 6875.36s] are still my set of friends from my\n",
            "[6872.64s → 6877.12s] undergraduate cambridge days my family's\n",
            "[6875.36s → 6878.24s] you know and and friends are very\n",
            "[6877.12s → 6879.12s] important\n",
            "[6878.24s → 6880.64s] um\n",
            "[6879.12s → 6882.96s] i've always i think trying to be a\n",
            "[6880.64s → 6884.40s] multi-disciplinary person it helps to\n",
            "[6882.96s → 6886.16s] keep you humble because no matter how\n",
            "[6884.40s → 6888.00s] good you are at one topic someone will\n",
            "[6886.16s → 6890.00s] be better than you at that and it and\n",
            "[6888.00s → 6892.96s] always relearning a new topic again from\n",
            "[6890.00s → 6894.96s] scratch is or new field is very humbling\n",
            "[6892.96s → 6897.28s] right so for me that's been biology over\n",
            "[6894.96s → 6899.44s] the last five years you know huge area\n",
            "[6897.28s → 6901.04s] topic and and and it's been and i just\n",
            "[6899.44s → 6904.24s] love doing that but it helps to keep you\n",
            "[6901.04s → 6905.04s] grounded like it keeps you open-minded\n",
            "[6904.24s → 6906.48s] and\n",
            "[6905.04s → 6909.12s] and then the other important thing is to\n",
            "[6906.48s → 6910.80s] have a really good amazing set of uh\n",
            "[6909.12s → 6912.96s] people around you at your company or\n",
            "[6910.80s → 6915.20s] your organization who are also very\n",
            "[6912.96s → 6916.96s] ethical and grounded themselves and help\n",
            "[6915.20s → 6918.40s] to keep you that way\n",
            "[6916.96s → 6920.00s] and then ultimately just to answer your\n",
            "[6918.40s → 6922.72s] question i hope we're going to be a big\n",
            "[6920.00s → 6924.64s] part of of birthing ai and that being\n",
            "[6922.72s → 6927.44s] the greatest benefit to humanity of any\n",
            "[6924.64s → 6929.92s] tool or technology ever and and getting\n",
            "[6927.44s → 6931.68s] us into a world of radical abundance and\n",
            "[6929.92s → 6933.36s] curing diseases and\n",
            "[6931.68s → 6934.80s] and and solving many of the big\n",
            "[6933.36s → 6936.64s] challenges we have in front of us and\n",
            "[6934.80s → 6938.32s] then ultimately you know help the\n",
            "[6936.64s → 6940.32s] ultimate flourishing of humanity to\n",
            "[6938.32s → 6941.60s] travel the stars and find those aliens\n",
            "[6940.32s → 6943.36s] if they are there and if they're not\n",
            "[6941.60s → 6944.84s] there find out why they're not there\n",
            "[6943.36s → 6947.68s] what what is going on here in the\n",
            "[6944.84s → 6950.56s] universe um this is all to come and and\n",
            "[6947.68s → 6952.32s] that's what i've always dreamed about um\n",
            "[6950.56s → 6954.80s] but i don't think i think ai is too big\n",
            "[6952.32s → 6956.32s] an idea it's not going to be uh there'll\n",
            "[6954.80s → 6957.68s] be a certain set of pioneers who get\n",
            "[6956.32s → 6958.88s] there first i hope\n",
            "[6957.68s → 6960.80s] we're in the vanguard so we can\n",
            "[6958.88s → 6963.44s] influence how that goes and i think it\n",
            "[6960.80s → 6965.20s] matters who builds who which which\n",
            "[6963.44s → 6967.68s] cultures they come from and what values\n",
            "[6965.20s → 6968.88s] they have uh the builders of ai systems\n",
            "[6967.68s → 6970.40s] because i think even though the ai\n",
            "[6968.88s → 6972.80s] system is going to learn for itself most\n",
            "[6970.40s → 6974.80s] of its knowledge there'll be a residue\n",
            "[6972.80s → 6977.52s] in the system of the culture and the\n",
            "[6974.80s → 6979.12s] values of the creators of the system um\n",
            "[6977.52s → 6981.28s] and there's interesting questions to to\n",
            "[6979.12s → 6982.72s] discuss about that geopolitically you\n",
            "[6981.28s → 6984.08s] know different cultures as we're in a\n",
            "[6982.72s → 6985.92s] more fragmented world than ever\n",
            "[6984.08s → 6987.36s] unfortunately i think in terms of global\n",
            "[6985.92s → 6989.28s] cooperation\n",
            "[6987.36s → 6991.36s] we see that in things like climate where\n",
            "[6989.28s → 6993.28s] we can't seem to get our act together uh\n",
            "[6991.36s → 6995.20s] globally to cooperate on these pressing\n",
            "[6993.28s → 6997.20s] matters i hope that will change over\n",
            "[6995.20s → 6998.96s] time perhaps you know if we get to an\n",
            "[6997.20s → 7000.64s] era of radical abundance we don't have\n",
            "[6998.96s → 7002.56s] to be so competitive anymore maybe we\n",
            "[7000.64s → 7004.64s] can be more cooperative\n",
            "[7002.56s → 7005.84s] if resources aren't so scarce it's true\n",
            "[7004.64s → 7006.80s] that\n",
            "[7005.84s → 7008.88s] in terms of\n",
            "[7006.80s → 7011.36s] power corrupting and leading to\n",
            "[7008.88s → 7013.20s] destructive things it seems that some of\n",
            "[7011.36s → 7015.12s] the atrocities of the past happen when\n",
            "[7013.20s → 7016.96s] there's a significant\n",
            "[7015.12s → 7017.92s] constraint on resources i think that's\n",
            "[7016.96s → 7019.60s] the first thing i don't think that's\n",
            "[7017.92s → 7021.92s] enough i think scarcity is one thing\n",
            "[7019.60s → 7023.92s] that's led to competition destruct you\n",
            "[7021.92s → 7025.44s] know sort of zero sum game thinking i\n",
            "[7023.92s → 7027.04s] would like us to all be in a positive\n",
            "[7025.44s → 7028.88s] sum world and i think for that you have\n",
            "[7027.04s → 7030.72s] to remove scarcity i don't think that's\n",
            "[7028.88s → 7032.40s] enough unfortunately to get world peace\n",
            "[7030.72s → 7034.48s] because there's also other corrupting\n",
            "[7032.40s → 7035.92s] things like wanting power over people\n",
            "[7034.48s → 7038.00s] and this kind of stuff which is not\n",
            "[7035.92s → 7041.04s] necessarily satisfied by by just\n",
            "[7038.00s → 7043.60s] abundance but i think it will help um\n",
            "[7041.04s → 7045.68s] and i think uh but i think ultimately ai\n",
            "[7043.60s → 7047.04s] is not going to be run by any one person\n",
            "[7045.68s → 7049.44s] or one organization i think it should\n",
            "[7047.04s → 7051.36s] belong to the world belong to humanity\n",
            "[7049.44s → 7053.12s] um and i think maybe many there'll be\n",
            "[7051.36s → 7055.20s] many ways this will happen and\n",
            "[7053.12s → 7057.52s] ultimately um\n",
            "[7055.20s → 7059.28s] everybody should have a say in that\n",
            "[7057.52s → 7062.00s] do you have advice\n",
            "[7059.28s → 7064.40s] for uh young people in high school and\n",
            "[7062.00s → 7066.96s] college maybe um\n",
            "[7064.40s → 7068.88s] if they're interested in ai or\n",
            "[7066.96s → 7071.12s] interested in having a\n",
            "[7068.88s → 7073.04s] big impact on the world what they should\n",
            "[7071.12s → 7074.88s] do to have a career they can be proud of\n",
            "[7073.04s → 7076.24s] her to have a life they can be proud of\n",
            "[7074.88s → 7078.16s] i love giving talks to the next\n",
            "[7076.24s → 7080.16s] generation what i say to them is\n",
            "[7078.16s → 7082.48s] actually two things i i think the most\n",
            "[7080.16s → 7083.84s] important things to learn about and to\n",
            "[7082.48s → 7086.24s] find out about when you're when you're\n",
            "[7083.84s → 7088.16s] young is what are your true passions is\n",
            "[7086.24s → 7090.56s] first of all there's two things one is\n",
            "[7088.16s → 7092.64s] find your true passions and i think you\n",
            "[7090.56s → 7094.64s] can do that by the way to do that is to\n",
            "[7092.64s → 7096.40s] explore as many things as possible when\n",
            "[7094.64s → 7098.96s] you're young and you you have the time\n",
            "[7096.40s → 7100.72s] and you and you can take those risks um\n",
            "[7098.96s → 7102.48s] i would also encourage people to look at\n",
            "[7100.72s → 7103.44s] the finding the connections between\n",
            "[7102.48s → 7105.44s] things\n",
            "[7103.44s → 7107.68s] in a unique way i think that's a really\n",
            "[7105.44s → 7111.04s] great way to find a passion second thing\n",
            "[7107.68s → 7113.12s] i would say advise is know yourself so\n",
            "[7111.04s → 7115.92s] spend a lot of time\n",
            "[7113.12s → 7117.68s] understanding how you work best like\n",
            "[7115.92s → 7119.76s] what are the optimal times to work what\n",
            "[7117.68s → 7121.04s] are the optimal ways that you study um\n",
            "[7119.76s → 7122.16s] what are your how do you deal with\n",
            "[7121.04s → 7123.76s] pressure\n",
            "[7122.16s → 7125.92s] sort of test yourself in various\n",
            "[7123.76s → 7128.72s] scenarios and try and improve your\n",
            "[7125.92s → 7131.04s] weaknesses but also find out what your\n",
            "[7128.72s → 7133.52s] unique skills and strengths are and then\n",
            "[7131.04s → 7135.76s] hone those so then that's what will be\n",
            "[7133.52s → 7137.36s] your super value in the world later on\n",
            "[7135.76s → 7139.20s] and if you can then combine those two\n",
            "[7137.36s → 7142.32s] things and find passions that you're\n",
            "[7139.20s → 7145.28s] genuinely excited about that intersect\n",
            "[7142.32s → 7146.80s] with what your unique strong skills are\n",
            "[7145.28s → 7148.56s] then you're you know you're on to\n",
            "[7146.80s → 7150.16s] something incredible and and you know i\n",
            "[7148.56s → 7152.08s] think you can make a huge difference in\n",
            "[7150.16s → 7154.40s] the world so let me ask about know\n",
            "[7152.08s → 7157.12s] yourself this is fun this is fun quick\n",
            "[7154.40s → 7159.20s] questions about day in the life the\n",
            "[7157.12s → 7161.52s] perfect day the perfect productive day\n",
            "[7159.20s → 7164.88s] in the life of demise's house yeah maybe\n",
            "[7161.52s → 7166.88s] uh maybe these days you're um\n",
            "[7164.88s → 7168.96s] there's a lot involved yeah it may be a\n",
            "[7166.88s → 7170.16s] slightly younger\n",
            "[7168.96s → 7173.12s] you could focus on a demonstration\n",
            "[7170.16s → 7174.88s] project maybe um\n",
            "[7173.12s → 7176.64s] how early do you wake up are you night\n",
            "[7174.88s → 7178.72s] owl do you wake up early in the morning\n",
            "[7176.64s → 7181.04s] what are some interesting habits\n",
            "[7178.72s → 7184.48s] uh how many dozens of cups of coffees do\n",
            "[7181.04s → 7185.92s] you drink a day what's the computer um\n",
            "[7184.48s → 7187.76s] that you use\n",
            "[7185.92s → 7190.32s] uh what's the setup how many screens\n",
            "[7187.76s → 7192.48s] what kind of keyboard are we talking uh\n",
            "[7190.32s → 7194.00s] emacs vim are we talking something more\n",
            "[7192.48s → 7196.88s] modern so it's a bunch of those\n",
            "[7194.00s → 7198.80s] questions so maybe uh day in the life\n",
            "[7196.88s → 7200.80s] what what's the perfect day involved\n",
            "[7198.80s → 7203.28s] well these days it's quite different\n",
            "[7200.80s → 7205.44s] from say 10 20 years ago back 10 20\n",
            "[7203.28s → 7208.16s] years ago it would have been you know a\n",
            "[7205.44s → 7210.08s] whole day of\n",
            "[7208.16s → 7211.84s] research individual research or\n",
            "[7210.08s → 7213.92s] programming doing some experiment\n",
            "[7211.84s → 7216.56s] neuroscience computer science experiment\n",
            "[7213.92s → 7219.60s] reading lots of research papers uh and\n",
            "[7216.56s → 7223.20s] then perhaps at night time you know um\n",
            "[7219.60s → 7226.32s] reading science fiction books or or uh\n",
            "[7223.20s → 7228.64s] playing uh some games but lots of focus\n",
            "[7226.32s → 7229.84s] so like deep focused work on whether\n",
            "[7228.64s → 7231.68s] it's uh\n",
            "[7229.84s → 7233.28s] programming or reading research paper\n",
            "[7231.68s → 7235.44s] yes yes so that would be a lot of\n",
            "[7233.28s → 7237.76s] debrief you know uh focused work these\n",
            "[7235.44s → 7240.08s] days for the last sort of i guess you\n",
            "[7237.76s → 7241.60s] know five to ten years i've actually got\n",
            "[7240.08s → 7244.16s] quite a structure that works very well\n",
            "[7241.60s → 7246.32s] for me now which is that um i'm a night\n",
            "[7244.16s → 7248.88s] complete night out always have been so i\n",
            "[7246.32s → 7250.56s] optimized for that so you know i get you\n",
            "[7248.88s → 7252.96s] know i basically do a normal day's work\n",
            "[7250.56s → 7255.12s] get into work about 11 o'clock and sort\n",
            "[7252.96s → 7257.68s] of do work to about seven uh in the\n",
            "[7255.12s → 7259.60s] office uh and i will arrange\n",
            "[7257.68s → 7262.32s] back-to-back meetings for the entire\n",
            "[7259.60s → 7263.52s] time of that and with as many me as many\n",
            "[7262.32s → 7266.40s] people as possible so that's my\n",
            "[7263.52s → 7268.56s] collaboration management part of the day\n",
            "[7266.40s → 7272.32s] then i go home uh spend time with the\n",
            "[7268.56s → 7274.16s] family and friends uh have dinner uh uh\n",
            "[7272.32s → 7275.76s] relax a little bit and then i start a\n",
            "[7274.16s → 7279.04s] second day of work i call it my second\n",
            "[7275.76s → 7280.72s] day work around 10 pm 11 p.m and that's\n",
            "[7279.04s → 7282.40s] the time till about the small hours of\n",
            "[7280.72s → 7285.76s] the morning four five in the morning\n",
            "[7282.40s → 7288.88s] where i will do my thinking and reading\n",
            "[7285.76s → 7290.80s] a research writing research papers um\n",
            "[7288.88s → 7292.72s] sadly don't have time to code anymore\n",
            "[7290.80s → 7295.20s] but it's it's not efficient to to do\n",
            "[7292.72s → 7297.92s] that uh these days uh given the amount\n",
            "[7295.20s → 7300.00s] of time i have um but that's when i do\n",
            "[7297.92s → 7302.32s] you know maybe do the long kind of\n",
            "[7300.00s → 7304.08s] stretches of of thinking and planning\n",
            "[7302.32s → 7305.84s] and then probably you know using using\n",
            "[7304.08s → 7307.28s] email or other things i would set i\n",
            "[7305.84s → 7309.44s] would fire off a lot of things to my\n",
            "[7307.28s → 7311.52s] team to deal with the next morning for\n",
            "[7309.44s → 7313.44s] actually thinking about this overnight\n",
            "[7311.52s → 7314.96s] we should go for this project or arrange\n",
            "[7313.44s → 7316.08s] this meeting the next day when you're\n",
            "[7314.96s → 7317.44s] thinking through a problem are you\n",
            "[7316.08s → 7319.20s] talking about a sheet of paper or the\n",
            "[7317.44s → 7321.44s] patent pen is there some independent\n",
            "[7319.20s → 7323.68s] structure yeah i like processes i still\n",
            "[7321.44s → 7326.00s] like pencil and paper best for working\n",
            "[7323.68s → 7327.68s] out things but um these days it's just\n",
            "[7326.00s → 7329.44s] so efficient to read research papers\n",
            "[7327.68s → 7331.44s] just on the screen i still often print\n",
            "[7329.44s → 7333.44s] them out actually i still prefer to\n",
            "[7331.44s → 7335.28s] mark out things and i find it goes into\n",
            "[7333.44s → 7337.36s] the brain quick better and sticks in the\n",
            "[7335.28s → 7339.36s] brain better when you're you're still\n",
            "[7337.36s → 7341.12s] using physical pen and pencil and paper\n",
            "[7339.36s → 7343.44s] so you take notes with the i have lots\n",
            "[7341.12s → 7345.44s] of nodes electronic ones and also um\n",
            "[7343.44s → 7347.84s] whole stacks of notebooks that\n",
            "[7345.44s → 7349.84s] um that i use at home yeah on some of\n",
            "[7347.84s → 7351.44s] these most challenging next steps for\n",
            "[7349.84s → 7352.80s] example stuff\n",
            "[7351.44s → 7355.36s] none of us know about that you're\n",
            "[7352.80s → 7356.96s] working on you're thinking\n",
            "[7355.36s → 7358.72s] there's some deep thinking required\n",
            "[7356.96s → 7361.28s] there right like what what is the right\n",
            "[7358.72s → 7362.80s] problem what is the right approach\n",
            "[7361.28s → 7364.64s] because you're gonna have to invest a\n",
            "[7362.80s → 7366.00s] huge amount of time for the whole team\n",
            "[7364.64s → 7368.40s] they're going to have to pursue this\n",
            "[7366.00s → 7371.76s] thing what's the right way to do it is\n",
            "[7368.40s → 7373.36s] is rl going to work here or not yes um\n",
            "[7371.76s → 7375.28s] what's the right thing to try what's the\n",
            "[7373.36s → 7377.28s] right benchmark to use yeah we need to\n",
            "[7375.28s → 7379.20s] construct a benchmark from scratch all\n",
            "[7377.28s → 7380.80s] those kinds of things yes so i think all\n",
            "[7379.20s → 7384.24s] those kind of things in the night time\n",
            "[7380.80s → 7386.16s] phase but also much more um i find i've\n",
            "[7384.24s → 7389.20s] always found the quiet hours of the\n",
            "[7386.16s → 7392.08s] morning um when everyone's asleep it's\n",
            "[7389.20s → 7394.24s] super quiet outside um i love that time\n",
            "[7392.08s → 7396.64s] it's the golden hours like between like\n",
            "[7394.24s → 7398.96s] one and three in the morning um put some\n",
            "[7396.64s → 7401.52s] music on some inspiring music on and\n",
            "[7398.96s → 7403.12s] then um think these deep thoughts so\n",
            "[7401.52s → 7406.32s] that's when i would read you know my\n",
            "[7403.12s → 7408.08s] philosophy books and uh spinoza's my you\n",
            "[7406.32s → 7411.12s] know recent favorite can all these\n",
            "[7408.08s → 7412.24s] things i i i you know read about a great\n",
            "[7411.12s → 7414.00s] uh uh\n",
            "[7412.24s → 7416.08s] a scientist of history how they did\n",
            "[7414.00s → 7417.44s] things how they thought things so that's\n",
            "[7416.08s → 7419.28s] when you do all your create that's when\n",
            "[7417.44s → 7421.68s] i do all my creative thinking and it's\n",
            "[7419.28s → 7423.52s] good i think i think people recommend\n",
            "[7421.68s → 7425.60s] you know you do your your your sort of\n",
            "[7423.52s → 7427.60s] creative thinking in one block and the\n",
            "[7425.60s → 7429.12s] way i organize the day that way i don't\n",
            "[7427.60s → 7432.40s] get interrupted because obviously no one\n",
            "[7429.12s → 7435.12s] else is up uh at those times so i can i\n",
            "[7432.40s → 7437.68s] can go uh you know as i can sort of get\n",
            "[7435.12s → 7439.20s] super deep and super into flow the other\n",
            "[7437.68s → 7442.64s] nice thing about doing it night time\n",
            "[7439.20s → 7444.24s] wise is if i'm really uh onto something\n",
            "[7442.64s → 7446.88s] or i've i've got really deep into\n",
            "[7444.24s → 7448.80s] something i can choose to extend it and\n",
            "[7446.88s → 7450.16s] i'll go into six in the morning whatever\n",
            "[7448.80s → 7451.76s] and then i'll just pay for it the next\n",
            "[7450.16s → 7454.08s] day yeah cause i'll be a bit tired and i\n",
            "[7451.76s → 7456.00s] won't be my best but that's fine i can\n",
            "[7454.08s → 7458.16s] decide looking at my schedule the next\n",
            "[7456.00s → 7460.64s] day that and given where i'm at with\n",
            "[7458.16s → 7462.16s] this particular thought or creative idea\n",
            "[7460.64s → 7464.64s] that i'm going to pay that cost the next\n",
            "[7462.16s → 7467.20s] day so so i think that's that's more\n",
            "[7464.64s → 7468.32s] flexible than morning people who do that\n",
            "[7467.20s → 7470.32s] you know they get up at four in the\n",
            "[7468.32s → 7472.00s] morning they can also do those golden\n",
            "[7470.32s → 7473.68s] hours then but then their start of their\n",
            "[7472.00s → 7475.04s] schedule day starts at breakfast you\n",
            "[7473.68s → 7476.72s] know 8 a.m whatever they have their\n",
            "[7475.04s → 7478.24s] first meeting and then it's hard you\n",
            "[7476.72s → 7479.60s] have to reschedule a day if you're in\n",
            "[7478.24s → 7481.28s] flow yeah that's going to be i don't\n",
            "[7479.60s → 7482.80s] have to see that special threat of\n",
            "[7481.28s → 7483.60s] thoughts that\n",
            "[7482.80s → 7484.96s] the\n",
            "[7483.60s → 7486.64s] you're too passionate about you that\n",
            "[7484.96s → 7488.48s] this is where some of the greatest ideas\n",
            "[7486.64s → 7491.28s] could potentially come is when you just\n",
            "[7488.48s → 7493.28s] lose yourself late into yeah\n",
            "[7491.28s → 7494.88s] and for the meetings i mean you're\n",
            "[7493.28s → 7496.80s] loading in really hard problems in a\n",
            "[7494.88s → 7498.32s] very short amount of time so you have to\n",
            "[7496.80s → 7499.60s] do some kind of first principles\n",
            "[7498.32s → 7501.20s] thinking here it's like what's the\n",
            "[7499.60s → 7503.28s] problem what's the state of things\n",
            "[7501.20s → 7505.04s] what's the right next step yes you have\n",
            "[7503.28s → 7506.96s] to get really good at context switching\n",
            "[7505.04s → 7508.56s] which is one of the hardest things\n",
            "[7506.96s → 7510.16s] because especially as we do so many\n",
            "[7508.56s → 7511.60s] things if you include all the scientific\n",
            "[7510.16s → 7513.76s] things we do scientific fields we're\n",
            "[7511.60s → 7516.00s] working in these are entire you know\n",
            "[7513.76s → 7518.24s] complex fields in themselves and you you\n",
            "[7516.00s → 7521.76s] have to sort of keep up to abreast of\n",
            "[7518.24s → 7524.00s] that but i enjoy it i've always been uh\n",
            "[7521.76s → 7525.12s] a sort of generalist in a way and that's\n",
            "[7524.00s → 7528.08s] actually what happened with my games\n",
            "[7525.12s → 7529.36s] career after chess i i i one of the\n",
            "[7528.08s → 7531.04s] reasons i stopped playing chess was that\n",
            "[7529.36s → 7532.48s] i got into computers but also i started\n",
            "[7531.04s → 7534.48s] realizing there were many other great\n",
            "[7532.48s → 7535.84s] games out there to play too so\n",
            "[7534.48s → 7537.52s] i've always been that way inclined\n",
            "[7535.84s → 7539.12s] multidisciplinary and there's too many\n",
            "[7537.52s → 7541.60s] interesting things in in the world to\n",
            "[7539.12s → 7543.76s] spend all your time just on one thing\n",
            "[7541.60s → 7544.80s] so you mentioned spinoza gotta ask the\n",
            "[7543.76s → 7547.52s] big\n",
            "[7544.80s → 7548.96s] ridiculously big question about life\n",
            "[7547.52s → 7550.08s] what do you think is the meaning of this\n",
            "[7548.96s → 7553.04s] whole thing\n",
            "[7550.08s → 7555.04s] uh why are we humans here you've already\n",
            "[7553.04s → 7556.56s] mentioned that perhaps the universe\n",
            "[7555.04s → 7558.56s] created us\n",
            "[7556.56s → 7560.40s] is that why you think we're here\n",
            "[7558.56s → 7562.16s] to understand how the universe yeah i\n",
            "[7560.40s → 7564.48s] think my answer to that would be and at\n",
            "[7562.16s → 7567.20s] least the the life i'm living is to gain\n",
            "[7564.48s → 7569.20s] and uh to gain and understand the\n",
            "[7567.20s → 7571.04s] knowledge you know to gain knowledge and\n",
            "[7569.20s → 7573.36s] understand the universe that's what i\n",
            "[7571.04s → 7574.56s] think uh i can't see any higher purpose\n",
            "[7573.36s → 7576.24s] than that if you think back to the\n",
            "[7574.56s → 7578.40s] classical greeks you know the virtue of\n",
            "[7576.24s → 7580.48s] gaining knowledge it's uh i think it's\n",
            "[7578.40s → 7583.52s] that it's one of the few true virtues is\n",
            "[7580.48s → 7586.64s] to understand um the world around us and\n",
            "[7583.52s → 7588.16s] the context and humanity better and um\n",
            "[7586.64s → 7589.84s] and i think if you do that you become\n",
            "[7588.16s → 7591.52s] more compassionate and more\n",
            "[7589.84s → 7593.04s] understanding yourself and and more\n",
            "[7591.52s → 7594.88s] tolerant and all these i think all these\n",
            "[7593.04s → 7595.68s] other things may flow from that and to\n",
            "[7594.88s → 7597.04s] me\n",
            "[7595.68s → 7598.64s] you know understanding the nature of\n",
            "[7597.04s → 7600.24s] reality that is the biggest question\n",
            "[7598.64s → 7601.92s] what is going on here is sometimes the\n",
            "[7600.24s → 7603.20s] colloquial way i say what is really\n",
            "[7601.92s → 7605.44s] going on here\n",
            "[7603.20s → 7608.40s] uh it's so mysterious i feel like we're\n",
            "[7605.44s → 7610.80s] in some huge puzzle and and it's but the\n",
            "[7608.40s → 7612.96s] world is also seems to be the universe\n",
            "[7610.80s → 7614.32s] seems to be structured in a way you know\n",
            "[7612.96s → 7616.24s] why is it structured in a way that\n",
            "[7614.32s → 7618.00s] science is even possible that you know\n",
            "[7616.24s → 7619.44s] methods the scientific method works\n",
            "[7618.00s → 7621.92s] things are repeatable\n",
            "[7619.44s → 7624.08s] um it feels like it's almost structured\n",
            "[7621.92s → 7626.40s] in a way to be conducive to gaining\n",
            "[7624.08s → 7627.84s] knowledge so i feel like and you know\n",
            "[7626.40s → 7630.64s] why should computers be even possible\n",
            "[7627.84s → 7633.12s] isn't that amazing that uh computational\n",
            "[7630.64s → 7635.20s] electronic devices can can can can be\n",
            "[7633.12s → 7636.88s] possible and they're made of sand our\n",
            "[7635.20s → 7638.80s] most you know common element that we\n",
            "[7636.88s → 7640.40s] have you know silicon that on the on the\n",
            "[7638.80s → 7641.68s] earth's crust they could be made of\n",
            "[7640.40s → 7644.24s] diamond or something then we would have\n",
            "[7641.68s → 7645.52s] only had one computer yeah right so it's\n",
            "[7644.24s → 7647.60s] a lot of things are kind of slightly\n",
            "[7645.52s → 7649.52s] suspicious to me it sure as heck sounds\n",
            "[7647.60s → 7651.60s] this puzzle sure sounds like something\n",
            "[7649.52s → 7653.76s] we talked about earlier what it takes to\n",
            "[7651.60s → 7655.52s] to design a game\n",
            "[7653.76s → 7657.60s] that's really fun to play for prolonged\n",
            "[7655.52s → 7659.52s] periods of time\n",
            "[7657.60s → 7661.68s] and it does seem like this puzzle like\n",
            "[7659.52s → 7663.84s] you mentioned the more you learn about\n",
            "[7661.68s → 7664.80s] it the more you realize how little you\n",
            "[7663.84s → 7667.04s] know\n",
            "[7664.80s → 7669.44s] so it humbles you but excites you by the\n",
            "[7667.04s → 7671.84s] possibility of learning more it's one\n",
            "[7669.44s → 7674.96s] heck of a one heck of a puzzle we got\n",
            "[7671.84s → 7677.04s] going on here um so like i mentioned of\n",
            "[7674.96s → 7680.56s] all the people in the world you're very\n",
            "[7677.04s → 7681.92s] likely to be the one who creates the agi\n",
            "[7680.56s → 7684.24s] system\n",
            "[7681.92s → 7686.40s] um that achieves human level\n",
            "[7684.24s → 7688.64s] intelligence and goes beyond it so if\n",
            "[7686.40s → 7690.16s] you got a chance and very well you could\n",
            "[7688.64s → 7692.96s] be the person that goes into the room\n",
            "[7690.16s → 7695.20s] with the system and have a conversation\n",
            "[7692.96s → 7696.48s] maybe you only get to ask one question\n",
            "[7695.20s → 7699.28s] if you do\n",
            "[7696.48s → 7702.08s] what question would you ask her\n",
            "[7699.28s → 7703.52s] i would probably ask um what is the true\n",
            "[7702.08s → 7704.64s] nature of reality\n",
            "[7703.52s → 7706.00s] i think that's the question i don't know\n",
            "[7704.64s → 7707.76s] if i'd understand the answer because\n",
            "[7706.00s → 7710.48s] maybe it would be 42 or something like\n",
            "[7707.76s → 7712.32s] that but um that's the question i would\n",
            "[7710.48s → 7714.08s] ask\n",
            "[7712.32s → 7715.52s] and then there'll be a deep sigh from\n",
            "[7714.08s → 7717.44s] the systems like all right how do i\n",
            "[7715.52s → 7720.40s] explain to the excuse me exactly all\n",
            "[7717.44s → 7722.64s] right let me i don't have time\n",
            "[7720.40s → 7724.56s] to explain uh maybe i'll draw you a\n",
            "[7722.64s → 7727.12s] picture that it is\n",
            "[7724.56s → 7728.24s] i mean how do you even begin\n",
            "[7727.12s → 7731.12s] um\n",
            "[7728.24s → 7733.12s] to answer that question\n",
            "[7731.12s → 7734.32s] well i think it would um what would you\n",
            "[7733.12s → 7736.72s] what would you think the answer could\n",
            "[7734.32s → 7738.56s] possibly look like i think it could it\n",
            "[7736.72s → 7739.36s] could start looking like\n",
            "[7738.56s → 7741.52s] uh\n",
            "[7739.36s → 7743.84s] uh more fundamental explanations of\n",
            "[7741.52s → 7745.68s] physics would be the beginning you know\n",
            "[7743.84s → 7747.28s] more careful specification of that\n",
            "[7745.68s → 7749.44s] taking you walking us through by the\n",
            "[7747.28s → 7751.36s] hand as to what one would do to maybe\n",
            "[7749.44s → 7753.04s] prove those things out maybe giving you\n",
            "[7751.36s → 7754.80s] glimpses of\n",
            "[7753.04s → 7756.16s] what things you totally missed in the\n",
            "[7754.80s → 7759.12s] physics of today\n",
            "[7756.16s → 7760.96s] exactly just here here's glimpses of no\n",
            "[7759.12s → 7762.08s] like there's a much\n",
            "[7760.96s → 7763.92s] uh\n",
            "[7762.08s → 7766.64s] a much more elaborate world or a much\n",
            "[7763.92s → 7769.12s] simpler world or something\n",
            "[7766.64s → 7771.04s] a much deeper maybe simpler explanation\n",
            "[7769.12s → 7772.72s] yes of things right than the standard\n",
            "[7771.04s → 7776.16s] model of physics which we know doesn't\n",
            "[7772.72s → 7777.76s] work but we still keep adding to so um\n",
            "[7776.16s → 7779.04s] and and that's how i think the beginning\n",
            "[7777.76s → 7780.64s] of an explanation would look and it\n",
            "[7779.04s → 7782.24s] would start encompassing many of the\n",
            "[7780.64s → 7784.24s] mysteries that we have wondered about\n",
            "[7782.24s → 7785.76s] for thousands of years like you know\n",
            "[7784.24s → 7788.72s] consciousness\n",
            "[7785.76s → 7790.32s] uh life and gravity all of these things\n",
            "[7788.72s → 7792.48s] yeah giving us a glimpses of\n",
            "[7790.32s → 7793.92s] explanations for those things yeah\n",
            "[7792.48s → 7796.40s] well um\n",
            "[7793.92s → 7798.24s] damas dear one of the special\n",
            "[7796.40s → 7800.16s] human beings in this giant puzzle of\n",
            "[7798.24s → 7801.44s] ours and it's a huge honor that you\n",
            "[7800.16s → 7803.28s] would take a pause from the bigger\n",
            "[7801.44s → 7805.28s] puzzle to solve this small puzzle of a\n",
            "[7803.28s → 7806.64s] conversation with me today it's truly an\n",
            "[7805.28s → 7808.96s] honor and a pleasure thank you thank you\n",
            "[7806.64s → 7809.92s] i really enjoyed it thanks lex\n",
            "[7808.96s → 7811.92s] thanks for listening to this\n",
            "[7809.92s → 7813.52s] conversation with demas establish to\n",
            "[7811.92s → 7815.68s] support this podcast please check out\n",
            "[7813.52s → 7817.76s] our sponsors in the description\n",
            "[7815.68s → 7820.24s] and now let me leave you with some words\n",
            "[7817.76s → 7822.08s] from edskar dykstra\n",
            "[7820.24s → 7823.28s] computer science is no more about\n",
            "[7822.08s → 7827.04s] computers\n",
            "[7823.28s → 7828.80s] than astronomy is about telescopes\n",
            "[7827.04s → 7832.36s] thank you for listening and hope to see\n",
            "[7828.80s → 7832.36s] you next time\n"
          ]
        }
      ],
      "source": [
        " for s in transcript_list.snippets:\n",
        "        print(f\"[{s.start:6.2f}s → {s.start + s.duration:6.2f}s] {s.text}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ohyd1doOgcGg"
      },
      "source": [
        "## Step 1b - Indexing (Text Splitting)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "khEFs5pNfIqO"
      },
      "outputs": [],
      "source": [
        "splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "chunks = splitter.create_documents([transcript])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9-CtsTESgeCj",
        "outputId": "cb950d2d-1de8-40db-a2a4-821bde81d303"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "168"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(chunks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GNHrMmbQgn6r",
        "outputId": "ba4b6b38-c468-4e53-a196-162aad38b9f5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Document(metadata={}, page_content=\"the following is a conversation with demus hasabis ceo and co-founder of deepmind a company that has published and builds some of the most incredible artificial intelligence systems in the history of computing including alfred zero that learned all by itself to play the game of gold better than any human in the world and alpha fold two that solved protein folding both tasks considered nearly impossible for a very long time demus is widely considered to be one of the most brilliant and impactful humans in the history of artificial intelligence and science and engineering in general this was truly an honor and a pleasure for me to finally sit down with him for this conversation and i'm sure we will talk many times again in the future this is the lex friedman podcast to support it please check out our sponsors in the description and now dear friends here's demis hassabis let's start with a bit of a personal question am i an ai program you wrote to interview people until i get good enough\")"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chunks[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OKS_MuJZiEqJ"
      },
      "source": [
        "## Step 1c- Indexing (Embedding Generation and Storing in Vector Store)*italicized text*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wz-9-6T3idLp",
        "outputId": "825d7a63-b69d-4957-af8c-7f891bcfbae4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langchain_huggingface in /usr/local/lib/python3.12/dist-packages (1.2.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.33.4 in /usr/local/lib/python3.12/dist-packages (from langchain_huggingface) (0.36.0)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain_huggingface) (1.2.6)\n",
            "Requirement already satisfied: tokenizers<1.0.0,>=0.19.1 in /usr/local/lib/python3.12/dist-packages (from langchain_huggingface) (0.22.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain_huggingface) (3.20.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain_huggingface) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain_huggingface) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain_huggingface) (6.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain_huggingface) (2.32.5)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain_huggingface) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain_huggingface) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain_huggingface) (1.2.0)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.0->langchain_huggingface) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.0->langchain_huggingface) (0.6.1)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.0->langchain_huggingface) (2.12.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.0->langchain_huggingface) (9.1.2)\n",
            "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.0->langchain_huggingface) (0.13.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.2.0->langchain_huggingface) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain_huggingface) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain_huggingface) (3.11.5)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain_huggingface) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain_huggingface) (0.25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.2.0->langchain_huggingface) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.2.0->langchain_huggingface) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.2.0->langchain_huggingface) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<1.0.0,>=0.33.4->langchain_huggingface) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<1.0.0,>=0.33.4->langchain_huggingface) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<1.0.0,>=0.33.4->langchain_huggingface) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<1.0.0,>=0.33.4->langchain_huggingface) (2026.1.4)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain_huggingface) (4.12.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain_huggingface) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain_huggingface) (0.16.0)\n"
          ]
        }
      ],
      "source": [
        "pip install langchain_huggingface"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "3EPt2V-eiSbe"
      },
      "outputs": [],
      "source": [
        "from langchain_huggingface import HuggingFaceEndpointEmbeddings\n",
        "embeddings = HuggingFaceEndpointEmbeddings(\n",
        "    model=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1qljUVwdiNJB"
      },
      "source": [
        "## Step 1d - Indexing (Embedding Generation and Storing in Vector Store)*italicized text*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aqJP3XkQgqkn",
        "outputId": "6896f08b-f2f4-483c-e741-2d9016e071e7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "vector_store = FAISS.from_documents(chunks, embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rz1u67M6itMx",
        "outputId": "a49dd0d6-1771-4fe4-a48b-2410714db941"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{0: '5493928b-58b9-46fb-9b78-b54becd2037f',\n",
              " 1: 'bc2a11e8-064e-4cf7-91f3-18587bd205d9',\n",
              " 2: 'cbb3371a-1da0-4c02-99b9-65419d377d6f',\n",
              " 3: '63dc3aff-758d-4686-8939-d599535496cb',\n",
              " 4: '424baaa6-8632-46a3-b924-cb5ed3100743',\n",
              " 5: '649ce661-353a-47a8-9aad-06bc881b3482',\n",
              " 6: '581982e9-2f49-4693-b890-dd93a56545b0',\n",
              " 7: 'b630ab64-1c3c-4d79-b247-cc02bc521696',\n",
              " 8: 'e93175ff-abf3-47e4-a0a0-4508ac00eb64',\n",
              " 9: '9145fc2b-abba-4ac3-a1fc-0fe1b5d43df1',\n",
              " 10: '06605605-3260-4bff-a248-60b1fe620dea',\n",
              " 11: '6120d962-02df-4f78-972d-871b3c265038',\n",
              " 12: '7d16e53d-6653-4623-9275-18756dac52d4',\n",
              " 13: '94b8f3f7-30da-4a65-b4e8-4d6dcf0aa275',\n",
              " 14: '7aa2ff12-975f-441d-be79-8b10eb716eff',\n",
              " 15: '628286d5-05df-435d-b7d4-42f85c7e26e7',\n",
              " 16: '3306a925-4a6c-4ceb-8a68-1f2b4b3b80ad',\n",
              " 17: '2df59eaa-e1be-47a8-81c5-a18e1bc791f1',\n",
              " 18: 'f5e5828b-e943-429b-b7d6-3553f13ee668',\n",
              " 19: '3d4a87fd-7d30-470e-b08c-889bb681250e',\n",
              " 20: '64bfd361-1529-494d-ae89-d95dc4fd448e',\n",
              " 21: '666b7aa3-e0a7-4cef-a5ca-1696a73b78cc',\n",
              " 22: '01775d16-5e85-4a19-9d68-98a7369a8b16',\n",
              " 23: 'e40d2b20-84f2-4381-8fac-0c1b2ab2d81e',\n",
              " 24: 'c20b7838-4fff-472e-8159-2cd39ebfec6e',\n",
              " 25: 'eb1a2969-bb2c-4255-97e1-55a740e3af67',\n",
              " 26: '74d15012-1359-4e95-a468-fbcbd068292f',\n",
              " 27: 'e7f68aaa-ce35-4fb5-9f1f-cbcb48dfb247',\n",
              " 28: 'f39a6893-609c-462a-9b10-f599339e7ca8',\n",
              " 29: 'dbeb8fd3-9636-4272-8440-f63ec577383f',\n",
              " 30: '602900ea-b043-430d-b39a-f6af9322c827',\n",
              " 31: '2a18f5fd-fac5-43a0-9329-94eaf340683d',\n",
              " 32: 'c199fed2-6efe-4f90-a264-772e8b79e0ed',\n",
              " 33: '61866213-92be-454b-b60e-2b2c1b4b667a',\n",
              " 34: 'da62c9c5-1c29-41e3-b233-2624057f4e3e',\n",
              " 35: 'f94cd065-c43b-48e7-85e9-832e1ff0412f',\n",
              " 36: 'b539756f-c4e8-47e2-bdb8-8c38d523e004',\n",
              " 37: '9293b0e8-a164-481a-b22f-5f2b526d12ff',\n",
              " 38: 'cf6c5ef7-dec0-4114-a9e1-98f2eaa26b6c',\n",
              " 39: '2da9f67a-ac05-466d-8924-e14e00f8fe67',\n",
              " 40: '473155cb-4287-4737-a709-9bbbd0f2aa89',\n",
              " 41: '0ffd515d-14e7-46a5-b98e-47db8c27f8f1',\n",
              " 42: '505ae1fe-43e3-4617-ab48-faf58440a161',\n",
              " 43: '0a8c96c1-3a6a-4e2c-89a8-b61999373e5a',\n",
              " 44: '97d4aad3-65c3-4f22-ab67-a965f1b897cd',\n",
              " 45: '16f0054f-8931-4c71-b63e-9b66dd75195e',\n",
              " 46: '34cf27c2-2590-471c-bbc3-577ecdc90842',\n",
              " 47: 'fa450562-d929-40d5-8e22-baedb597f5b9',\n",
              " 48: '3f7de501-b769-4467-bd18-e19fd3f35305',\n",
              " 49: '61744be7-9439-44f3-aa14-2582516b749b',\n",
              " 50: '4f5633e9-911d-4ebe-9678-30d96e2a2e31',\n",
              " 51: 'ce240959-57f5-4aa4-86ae-724fe7d3ce48',\n",
              " 52: '59844e20-2146-4d17-86b3-1902c44c02f7',\n",
              " 53: '94322b97-73f0-42b3-92f2-3e80b6bdc160',\n",
              " 54: '80631c2c-87a4-4bed-a69c-fdc400adf36a',\n",
              " 55: '8c3a60b5-3440-4fda-a69a-028e1f8b3210',\n",
              " 56: '025c47ba-df51-4465-88c5-85b10ef36baf',\n",
              " 57: 'deefe7fe-c878-48de-9ec8-6a44ea631b33',\n",
              " 58: '2c2c6a1b-6179-4b87-8da7-2b88dba67312',\n",
              " 59: 'e72a077a-f52e-402d-a935-e05f118040c1',\n",
              " 60: 'b3009aea-14ec-4487-9149-94f6fc7f62c0',\n",
              " 61: '924f89f2-5b59-4853-a579-1c125cc1374d',\n",
              " 62: '746d37f7-2e97-4569-acf3-b791a9704fb9',\n",
              " 63: 'b8a42457-610e-4cd4-8aac-09b824b7f644',\n",
              " 64: '96669937-f000-489d-8101-57a6dd4578a8',\n",
              " 65: '60666e3d-b168-4f10-bb9d-1d336b78ffc9',\n",
              " 66: 'a266bf64-f33d-4fc3-b45d-fb70c5bd00fe',\n",
              " 67: '94901887-089c-4ed6-93b1-283e2ebe0ef2',\n",
              " 68: 'beb42573-83b2-4d7a-b3c9-ff52f27f0477',\n",
              " 69: '0bb2a6d9-7b51-401e-963c-64a47225e2dc',\n",
              " 70: '10641da6-4037-4b83-938a-e3c1d8e8de85',\n",
              " 71: 'a683c8eb-e8ea-4540-afb5-adffce7d694b',\n",
              " 72: 'ff05ce05-cb46-46a2-a045-3d463cf73732',\n",
              " 73: 'bd73e85f-c5e6-4128-82be-6b1747f2e419',\n",
              " 74: '79633aac-8356-44a6-9c3f-a3f1b0df385e',\n",
              " 75: '7676b767-616b-4189-8796-9710ce13f0b9',\n",
              " 76: '86869dab-1f7f-40d7-9c4b-bd2dba718d84',\n",
              " 77: 'fa5fbad0-a394-41ac-a3dd-2e52bb9102fe',\n",
              " 78: '93430032-a4fe-4266-b8cb-82c1bb53a848',\n",
              " 79: 'e923c6e0-99c9-46b4-aea5-8d53b6049b0d',\n",
              " 80: 'ccdcb2c3-3bcd-4298-9c5f-339f9e88a908',\n",
              " 81: '065d4db6-7739-45ef-a6f9-182c0b1887de',\n",
              " 82: '405feed5-e061-4e43-9b66-9aec71e0fae9',\n",
              " 83: '0cc866b6-430d-4b3e-90de-d35aa2aedd4f',\n",
              " 84: '92e3a487-479d-40b6-acdb-58d3969cfe13',\n",
              " 85: '54e833bc-a45d-4c30-a74f-b26a88caece0',\n",
              " 86: 'f5a902a8-4e29-46a5-8e97-30f54c7a45c2',\n",
              " 87: 'a44a1c6b-e2bc-49d6-9d1c-090043c20718',\n",
              " 88: '0a9c1913-f764-41a4-99fd-a3836bb713ff',\n",
              " 89: '067eb432-355a-4a0c-8a34-6a9ea229360d',\n",
              " 90: '1a7b22b1-d779-4e0d-af44-2fecc3a2a354',\n",
              " 91: 'a14bc11c-33c0-4226-9be7-eb2e8bd2eab1',\n",
              " 92: '636f6efd-7781-4e81-8b37-2006ad9bba02',\n",
              " 93: '7d1e8f6b-0473-438d-affb-055cf721cade',\n",
              " 94: 'a598c798-97e5-4713-823c-a03c70a39f8a',\n",
              " 95: '7ada6d1a-0cb3-4ca6-9d85-9173ba734b81',\n",
              " 96: 'e8125d88-dbfb-43f8-9841-ac89b9304a8a',\n",
              " 97: '7641422a-f134-4998-a732-1d765129fc2c',\n",
              " 98: '09bb2952-ebfe-4fc2-b89f-137d8ac73318',\n",
              " 99: 'ac8d23d4-271b-44a2-a657-b9b4a52cc329',\n",
              " 100: '9417e776-cd39-4f31-adf6-aad3752c9b3a',\n",
              " 101: 'dc0bc809-b018-4b15-9c39-5b2402e4895d',\n",
              " 102: 'f023fa98-e4ca-4669-a33a-db2eba40fa58',\n",
              " 103: '8350a384-0a75-45b8-9d28-3415cff06079',\n",
              " 104: '64ba800c-4cfc-40cd-8b1f-81059c688f50',\n",
              " 105: 'f2263a96-3cd8-45bc-9c70-4f590506e2fb',\n",
              " 106: '010366e1-6993-4a7d-ab7c-03974bcd1a3e',\n",
              " 107: '4b05dc2b-8ab6-4b12-8b58-33c5c62bd523',\n",
              " 108: 'd4b45608-3fcc-4a03-8fc7-0a75ab40bebc',\n",
              " 109: '19355bcd-f0c7-436c-a3bd-1de094d543f4',\n",
              " 110: 'e60b7c0e-7356-4e90-a301-2dc68bb933b1',\n",
              " 111: '658ec93d-2bba-4705-b82a-df0bdf6f49ad',\n",
              " 112: 'f54f3ba9-dbf0-4ed7-b0e4-65c9f3496422',\n",
              " 113: 'd062d187-ce45-44fa-927d-64bd4e028292',\n",
              " 114: 'aa85a85e-27e2-4a2f-bd69-8f13d59916f4',\n",
              " 115: '0a130810-01ce-4e11-8adb-79f1b58ac063',\n",
              " 116: '46895fde-2cde-4048-af34-8abbdcfc82e3',\n",
              " 117: '4de68b28-670d-4415-821b-53849d5e25ce',\n",
              " 118: '8e86c54b-cc25-4188-bf25-3063d5c62236',\n",
              " 119: 'a4f9cc1b-2e6c-426e-a33d-f6ce296b15e3',\n",
              " 120: '82acb13c-62c8-42e9-a6d7-0bc92c5c1da1',\n",
              " 121: 'b44c4357-6ebd-4189-8b4e-29fa9eaf0cff',\n",
              " 122: 'fd18b3b3-7d6f-41b7-b7d4-572642acd435',\n",
              " 123: '013b98b5-19d1-4cd4-9696-5656188ee971',\n",
              " 124: '95c24804-3bd4-46da-b069-049305e6abf7',\n",
              " 125: '304fc023-b38c-4903-8339-cd715df2e703',\n",
              " 126: '43c30436-4f10-4777-b24f-6fc99e064fec',\n",
              " 127: '82674f8b-81e2-4274-be99-2ab518d56122',\n",
              " 128: '275e73a3-20ee-4f0d-b2f8-2e8e8400e715',\n",
              " 129: '19cc4ef9-0db9-4692-93ba-89d4bcec8d89',\n",
              " 130: 'c1c04621-0fb0-440f-ad62-134c52c003f8',\n",
              " 131: '904dcb7e-3b26-441e-934b-d9bead9a1716',\n",
              " 132: 'afaa9ea2-ccbf-4aea-9d04-3853900ad7ed',\n",
              " 133: '39569309-b10e-48cd-8526-6b626353d56b',\n",
              " 134: 'dc49415e-8caf-40a0-b24f-a5337360206c',\n",
              " 135: '63716e2a-ed79-4b0e-9e49-86b2229fe8f5',\n",
              " 136: '5be43994-9d1a-4dc6-873d-3a56e22aec4f',\n",
              " 137: '3115db32-46c5-4290-b4e1-3660243d4255',\n",
              " 138: '90bb9db2-f6b9-4459-84ed-e5a198697774',\n",
              " 139: '7b20ab98-6c16-4ca1-8df0-7c4f8207297e',\n",
              " 140: 'be4ad5fc-fac1-4ea5-b70d-a000a1efb203',\n",
              " 141: 'f1f7f861-4a16-4739-aa0c-3015cb97b073',\n",
              " 142: '30e3847d-b248-4687-bf33-1e8b3712667a',\n",
              " 143: 'ed16c138-219b-4396-9273-560c14453a35',\n",
              " 144: '4e5217fa-b174-4078-af8c-77537357a607',\n",
              " 145: '934d969c-a834-4cf8-9ba7-8cdf8fae05e2',\n",
              " 146: 'b74195df-b3b2-4baa-af2a-c14ed5b0edbd',\n",
              " 147: '5d248e19-c6ca-447f-8fc7-2ee4b8a5dbe3',\n",
              " 148: 'dd88f8b6-f9ae-40b4-b64d-8d303cd59d4a',\n",
              " 149: 'b79a199e-0604-4899-893d-d44a7c874e17',\n",
              " 150: '4823ec61-b17d-4d06-918f-cc235c7e4f94',\n",
              " 151: 'e0f00c09-e8fe-4568-ad11-0dd1cef3debf',\n",
              " 152: 'a31ebd7a-b4a0-4ba3-be2d-0704a5b32148',\n",
              " 153: '3e683aef-4c4c-41db-befd-51cda1790136',\n",
              " 154: '6bfd0220-83cb-4ac8-b77b-0013b60b23b4',\n",
              " 155: '709ce2f1-e6bb-41e7-b9f1-a51c7e18aac2',\n",
              " 156: '4d228bdc-dd85-4414-a2d6-7988940b5875',\n",
              " 157: 'c4447a3f-43c1-4362-ac7b-16710e2badc9',\n",
              " 158: 'e9738bba-d965-402f-bc52-1f57834b7761',\n",
              " 159: 'eaa8d2e8-db98-4b6b-a0f4-28ae99de93e9',\n",
              " 160: 'd37f2163-4a2b-4f56-9eca-125c6cadc900',\n",
              " 161: '966d980e-f1db-41cb-bcb6-12aa2595f4e0',\n",
              " 162: '2c39d967-dfd2-4096-8200-51aecd79276a',\n",
              " 163: 'c10a6aca-15de-48b6-8ad8-6c4914916c3d',\n",
              " 164: 'ed251e5a-d209-4454-b664-f18abc95455b',\n",
              " 165: 'cd67ec2d-498c-48fb-b96c-cbba1f1b41a3',\n",
              " 166: '0be694dc-1840-49fa-89f0-c07b1e3e6807',\n",
              " 167: '1a068a7a-59ce-496a-aa90-f903f87ce9a4'}"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vector_store.index_to_docstore_id"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LDbQmtacjKXc"
      },
      "source": [
        "## Step 2 - Retrieval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gCBGGi1tiwzq",
        "outputId": "fb4c0cf8-6d26-4c05-f720-821a0005d7ec"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEndpointEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x780dd879c650>, search_kwargs={'k': 4})"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "retriever = vector_store.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 4})\n",
        "retriever"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qrjsksmCjJd9",
        "outputId": "bdf1ad1d-abf3-4335-e3aa-58553e021d89"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(id='96669937-f000-489d-8101-57a6dd4578a8', metadata={}, page_content=\"and how it works this is tough to uh ask you this question because you probably will say it's everything but let's let's try let's try to think to this because you're in a very interesting position where deepmind is the place of some of the most uh brilliant ideas in the history of ai but it's also a place of brilliant engineering so how much of solving intelligence this big goal for deepmind how much of it is science how much is engineering so how much is the algorithms how much is the data how much is the hardware compute infrastructure how much is it the software computer infrastructure yeah um what else is there how much is the human infrastructure and like just the humans interact in certain kinds of ways in all the space of all those ideas how much does maybe like philosophy how much what's the key if um uh if if you were to sort of look back like if we go forward 200 years look back what was the key thing that solved intelligence is that ideas i think it's a combination first\"),\n",
              " Document(id='5493928b-58b9-46fb-9b78-b54becd2037f', metadata={}, page_content=\"the following is a conversation with demus hasabis ceo and co-founder of deepmind a company that has published and builds some of the most incredible artificial intelligence systems in the history of computing including alfred zero that learned all by itself to play the game of gold better than any human in the world and alpha fold two that solved protein folding both tasks considered nearly impossible for a very long time demus is widely considered to be one of the most brilliant and impactful humans in the history of artificial intelligence and science and engineering in general this was truly an honor and a pleasure for me to finally sit down with him for this conversation and i'm sure we will talk many times again in the future this is the lex friedman podcast to support it please check out our sponsors in the description and now dear friends here's demis hassabis let's start with a bit of a personal question am i an ai program you wrote to interview people until i get good enough\"),\n",
              " Document(id='bd73e85f-c5e6-4128-82be-6b1747f2e419', metadata={}, page_content=\"ambitious as trying to solve intelligence and you're you're you know it's blue sky research no one knows how to do it you you you need to use any evidence or any source of information you can to help guide you in the right direction or give you confidence you're going in the right direction so so that that was one reason we pushed so hard on that and that's and just going back to your early question about organization the other big thing that i think we innovated with at deepmind to encourage invention and and uh and innovation was the multi-disciplinary organization we built and we still have today so deepmind originally was a confluence of the of the most cutting-edge knowledge in neuroscience with machine learning engineering and mathematics right and and gaming and then since then we built that out even further so we have philosophers here and and uh by you know ethicists but also other types of scientists physicists and so on um and that's what brings together i tried to build a\"),\n",
              " Document(id='666b7aa3-e0a7-4cef-a5ca-1696a73b78cc', metadata={}, page_content=\"used of ai is in deep mind from the beginning which is using games as a testing ground for proving out ai algorithms and developing ai algorithms and that was a that was a sort of um a core component of our vision at the start of deepmind was that we would use games very heavily uh as our main testing ground certainly to begin with um because it's super efficient to use games and also you know it's very easy to have metrics to see how well your systems are improving and what direction your ideas are going in and whether you're making incremental improvements and because those games are often rooted in something that humans did for a long time beforehand there's already a strong set of rules like it's already a damn good benchmark yes it's really good for so many reasons because you've got you've got you've got clear measures of how good humans can be at these things and in some cases like go we've been playing it for thousands of years um and and uh often they have scores or at least\")]"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "retriever.invoke('What is deepmind')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UvB60Xlsj08S"
      },
      "source": [
        "## Step 3 - Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "cDv2lKjMjiLL"
      },
      "outputs": [],
      "source": [
        "llm = ChatGoogleGenerativeAI(model=\"gemini-3-flash-preview\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "IeT9PyQDj8Ks"
      },
      "outputs": [],
      "source": [
        "prompt = PromptTemplate(\n",
        "    template=\"\"\"\n",
        "      You are a helpful assistant.\n",
        "      Answer ONLY from the provided transcript context.\n",
        "      If the context is insufficient, just say you don't know.\n",
        "\n",
        "      {context}\n",
        "      Question: {question}\n",
        "    \"\"\",\n",
        "    input_variables = ['context', 'question']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "eJJthuAikCHw"
      },
      "outputs": [],
      "source": [
        "question          = \"is the topic of nuclear fusion discussed in this video? if yes then what was discussed\"\n",
        "retrieved_docs    = retriever.invoke(question)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6JhhDsqgkFgH",
        "outputId": "abd58da6-b42b-42d6-a7ed-f91fb4db9b41"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(id='7ada6d1a-0cb3-4ca6-9d85-9173ba734b81', metadata={}, page_content=\"in this case in fusion we we collaborated with epfl in switzerland the swiss technical institute who are amazing they have a test reactor that they were willing to let us use which you know i double checked with the team we were going to use carefully and safely i was impressed they managed to persuade them to let us use it and um and it's a it's an amazing test reactor they have there and they try all sorts of pretty crazy experiments on it and um the the the what we tend to look at is if we go into a new domain like fusion what are all the bottleneck problems uh like thinking from first principles you know what are all the bottleneck problems that are still stopping fusion working today and then we look at we you know we get a fusion expert to tell us and then we look at those bottlenecks and we look at the ones which ones are amenable to our ai methods today yes right and and and then and would be interesting from a research perspective from our point of view from an ai point of\"),\n",
              " Document(id='a598c798-97e5-4713-823c-a03c70a39f8a', metadata={}, page_content='that i would like to i think could be very transformative if we helped accelerate and uh really interesting problems scientific challenges in of themselves this is energy so energy yes exactly so energy and climate so we talked about disease and biology as being one of the biggest places i think ai can help with i think energy and climate uh is another one so maybe they would be my top two um and fusion is one one area i think ai can help with now fusion has many challenges mostly physics material science and engineering challenges as well to build these massive fusion reactors and contain the plasma and what we try to do whenever we go into a new field to apply our systems is we look for um we talk to domain experts we try and find the best people in the world to collaborate with um in this case in fusion we we collaborated with epfl in switzerland the swiss technical institute who are amazing they have a test reactor that they were willing to let us use which you know i double'),\n",
              " Document(id='09bb2952-ebfe-4fc2-b89f-137d8ac73318', metadata={}, page_content=\"so we with this problem and we published it in a nature paper last year uh we held the fusion that we held the plasma in specific shapes so actually it's almost like carving the plasma into different shapes and control and hold it there for the record amount of time so um so that's one of the problems of of fusion sort of um solved so i have a controller that's able to no matter the shape uh contain it continue yeah contain it and hold it in structure and there's different shapes that are better for for the energy productions called droplets and and and so on so um so that was huge and now we're looking we're talking to lots of fusion startups to see what's the next problem we can tackle uh in the fusion area so another fascinating place in a paper title pushing the frontiers of density functionals by solving the fractional electron problem so you're taking on modeling and simulating the quantum mechanical behavior of electrons yes um can you explain this work and can ai model and\"),\n",
              " Document(id='7d1e8f6b-0473-438d-affb-055cf721cade', metadata={}, page_content=\"like room temperature superconductors or something on my list one day i'd like to like you know have an ai system to help build better optimized batteries all of these sort of mechanical things mr i think a systematic sort of search could be uh guided by a model could be um could be extremely powerful so speaking of which you have a paper on nuclear fusion uh magnetic control of tokamak plasmas to deep reinforcement learning so you uh you're seeking to solve nuclear fusion with deep rl so it's doing control of high temperature plasmas can you explain this work and uh can ai eventually solve nuclear fusion it's been very fun last year or two and very productive because we've been taking off a lot of my dream projects if you like of things that i've collected over the years of areas of science that i would like to i think could be very transformative if we helped accelerate and uh really interesting problems scientific challenges in of themselves this is energy so energy yes exactly so\")]"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "retrieved_docs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "id": "LxtalyRMkHSa",
        "outputId": "92884c0a-72e9-4b88-9ab6-aba478771fc2"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"in this case in fusion we we collaborated with epfl in switzerland the swiss technical institute who are amazing they have a test reactor that they were willing to let us use which you know i double checked with the team we were going to use carefully and safely i was impressed they managed to persuade them to let us use it and um and it's a it's an amazing test reactor they have there and they try all sorts of pretty crazy experiments on it and um the the the what we tend to look at is if we go into a new domain like fusion what are all the bottleneck problems uh like thinking from first principles you know what are all the bottleneck problems that are still stopping fusion working today and then we look at we you know we get a fusion expert to tell us and then we look at those bottlenecks and we look at the ones which ones are amenable to our ai methods today yes right and and and then and would be interesting from a research perspective from our point of view from an ai point of\\n\\nthat i would like to i think could be very transformative if we helped accelerate and uh really interesting problems scientific challenges in of themselves this is energy so energy yes exactly so energy and climate so we talked about disease and biology as being one of the biggest places i think ai can help with i think energy and climate uh is another one so maybe they would be my top two um and fusion is one one area i think ai can help with now fusion has many challenges mostly physics material science and engineering challenges as well to build these massive fusion reactors and contain the plasma and what we try to do whenever we go into a new field to apply our systems is we look for um we talk to domain experts we try and find the best people in the world to collaborate with um in this case in fusion we we collaborated with epfl in switzerland the swiss technical institute who are amazing they have a test reactor that they were willing to let us use which you know i double\\n\\nso we with this problem and we published it in a nature paper last year uh we held the fusion that we held the plasma in specific shapes so actually it's almost like carving the plasma into different shapes and control and hold it there for the record amount of time so um so that's one of the problems of of fusion sort of um solved so i have a controller that's able to no matter the shape uh contain it continue yeah contain it and hold it in structure and there's different shapes that are better for for the energy productions called droplets and and and so on so um so that was huge and now we're looking we're talking to lots of fusion startups to see what's the next problem we can tackle uh in the fusion area so another fascinating place in a paper title pushing the frontiers of density functionals by solving the fractional electron problem so you're taking on modeling and simulating the quantum mechanical behavior of electrons yes um can you explain this work and can ai model and\\n\\nlike room temperature superconductors or something on my list one day i'd like to like you know have an ai system to help build better optimized batteries all of these sort of mechanical things mr i think a systematic sort of search could be uh guided by a model could be um could be extremely powerful so speaking of which you have a paper on nuclear fusion uh magnetic control of tokamak plasmas to deep reinforcement learning so you uh you're seeking to solve nuclear fusion with deep rl so it's doing control of high temperature plasmas can you explain this work and uh can ai eventually solve nuclear fusion it's been very fun last year or two and very productive because we've been taking off a lot of my dream projects if you like of things that i've collected over the years of areas of science that i would like to i think could be very transformative if we helped accelerate and uh really interesting problems scientific challenges in of themselves this is energy so energy yes exactly so\""
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "context_text = \"\\n\\n\".join(doc.page_content for doc in retrieved_docs)\n",
        "context_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "rsY1daAfkR_O"
      },
      "outputs": [],
      "source": [
        "final_prompt = prompt.invoke({\"context\": context_text, \"question\": question})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hvj8MbY-kV42",
        "outputId": "4305df78-0a9a-4a40-dfe1-99e685708018"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "StringPromptValue(text=\"\\n      You are a helpful assistant.\\n      Answer ONLY from the provided transcript context.\\n      If the context is insufficient, just say you don't know.\\n\\n      in this case in fusion we we collaborated with epfl in switzerland the swiss technical institute who are amazing they have a test reactor that they were willing to let us use which you know i double checked with the team we were going to use carefully and safely i was impressed they managed to persuade them to let us use it and um and it's a it's an amazing test reactor they have there and they try all sorts of pretty crazy experiments on it and um the the the what we tend to look at is if we go into a new domain like fusion what are all the bottleneck problems uh like thinking from first principles you know what are all the bottleneck problems that are still stopping fusion working today and then we look at we you know we get a fusion expert to tell us and then we look at those bottlenecks and we look at the ones which ones are amenable to our ai methods today yes right and and and then and would be interesting from a research perspective from our point of view from an ai point of\\n\\nthat i would like to i think could be very transformative if we helped accelerate and uh really interesting problems scientific challenges in of themselves this is energy so energy yes exactly so energy and climate so we talked about disease and biology as being one of the biggest places i think ai can help with i think energy and climate uh is another one so maybe they would be my top two um and fusion is one one area i think ai can help with now fusion has many challenges mostly physics material science and engineering challenges as well to build these massive fusion reactors and contain the plasma and what we try to do whenever we go into a new field to apply our systems is we look for um we talk to domain experts we try and find the best people in the world to collaborate with um in this case in fusion we we collaborated with epfl in switzerland the swiss technical institute who are amazing they have a test reactor that they were willing to let us use which you know i double\\n\\nso we with this problem and we published it in a nature paper last year uh we held the fusion that we held the plasma in specific shapes so actually it's almost like carving the plasma into different shapes and control and hold it there for the record amount of time so um so that's one of the problems of of fusion sort of um solved so i have a controller that's able to no matter the shape uh contain it continue yeah contain it and hold it in structure and there's different shapes that are better for for the energy productions called droplets and and and so on so um so that was huge and now we're looking we're talking to lots of fusion startups to see what's the next problem we can tackle uh in the fusion area so another fascinating place in a paper title pushing the frontiers of density functionals by solving the fractional electron problem so you're taking on modeling and simulating the quantum mechanical behavior of electrons yes um can you explain this work and can ai model and\\n\\nlike room temperature superconductors or something on my list one day i'd like to like you know have an ai system to help build better optimized batteries all of these sort of mechanical things mr i think a systematic sort of search could be uh guided by a model could be um could be extremely powerful so speaking of which you have a paper on nuclear fusion uh magnetic control of tokamak plasmas to deep reinforcement learning so you uh you're seeking to solve nuclear fusion with deep rl so it's doing control of high temperature plasmas can you explain this work and uh can ai eventually solve nuclear fusion it's been very fun last year or two and very productive because we've been taking off a lot of my dream projects if you like of things that i've collected over the years of areas of science that i would like to i think could be very transformative if we helped accelerate and uh really interesting problems scientific challenges in of themselves this is energy so energy yes exactly so\\n      Question: is the topic of nuclear fusion discussed in this video? if yes then what was discussed\\n    \")"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "final_prompt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ur1u9Hi8kczH"
      },
      "source": [
        "## Step 4 - Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "unTxAJsYkYvi",
        "outputId": "989d7bd2-2986-4616-9e21-7603ce4b84e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'type': 'text', 'text': 'Yes, the topic of nuclear fusion is discussed. According to the transcript:\\n\\n*   **Significance:** Fusion is described as a \"transformative\" area that could help accelerate progress in energy and climate.\\n*   **Collaboration:** The team collaborated with EPFL (the Swiss Technical Institute) in Switzerland to use their test reactor for experiments.\\n*   **Methodology:** They look at \"bottleneck problems\" from first principles and identify which ones are amenable to AI methods. \\n*   **Achievements:** They published a paper in *Nature* titled \"Magnetic control of tokamak plasmas to deep reinforcement learning.\" Using deep reinforcement learning (RL), they successfully controlled and held high-temperature plasma in specific shapes (such as droplets) for record amounts of time.\\n*   **Challenges:** Fusion involves significant challenges in physics, material science, and engineering, particularly in building massive reactors and containing plasma.\\n*   **Future Work:** The team is currently talking to fusion startups to determine the next problems they can tackle in the field.', 'extras': {'signature': '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'}}]\n"
          ]
        }
      ],
      "source": [
        "answer = llm.invoke(final_prompt)\n",
        "print(answer.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "osfDCTnilcQk"
      },
      "source": [
        "## Building a Chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "A2rRl0VskuRD"
      },
      "outputs": [],
      "source": [
        "from langchain_core.runnables import RunnableParallel, RunnablePassthrough, RunnableLambda\n",
        "from langchain_core.output_parsers import StrOutputParser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "c99pDJHQpvm5"
      },
      "outputs": [],
      "source": [
        "def format_docs(retrieved_docs):\n",
        "  context_text = \"\\n\\n\".join(doc.page_content for doc in retrieved_docs)\n",
        "  return context_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "X0jlrvImpyIs"
      },
      "outputs": [],
      "source": [
        "parallel_chain = RunnableParallel({\n",
        "    'context': retriever | RunnableLambda(format_docs),\n",
        "    'question': RunnablePassthrough()\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IbxWAUIjp5_O",
        "outputId": "d8723f21-2d09-4a7a-86a8-9a0ee099ac0a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'context': \"to get world peace because there's also other corrupting things like wanting power over people and this kind of stuff which is not necessarily satisfied by by just abundance but i think it will help um and i think uh but i think ultimately ai is not going to be run by any one person or one organization i think it should belong to the world belong to humanity um and i think maybe many there'll be many ways this will happen and ultimately um everybody should have a say in that do you have advice for uh young people in high school and college maybe um if they're interested in ai or interested in having a big impact on the world what they should do to have a career they can be proud of her to have a life they can be proud of i love giving talks to the next generation what i say to them is actually two things i i think the most important things to learn about and to find out about when you're when you're young is what are your true passions is first of all there's two things one is find\\n\\nthe following is a conversation with demus hasabis ceo and co-founder of deepmind a company that has published and builds some of the most incredible artificial intelligence systems in the history of computing including alfred zero that learned all by itself to play the game of gold better than any human in the world and alpha fold two that solved protein folding both tasks considered nearly impossible for a very long time demus is widely considered to be one of the most brilliant and impactful humans in the history of artificial intelligence and science and engineering in general this was truly an honor and a pleasure for me to finally sit down with him for this conversation and i'm sure we will talk many times again in the future this is the lex friedman podcast to support it please check out our sponsors in the description and now dear friends here's demis hassabis let's start with a bit of a personal question am i an ai program you wrote to interview people until i get good enough\\n\\nof deep mind just as a human being let me ask you about this one particular anecdotal evidence of the google engineer who made a comment or believed that there's some aspect of a language model the lambda language model that exhibited sentience so you said you believe there might be a responsibility to build systems that are not essential and this experience of a particular engineer i think i'd love to get your general opinion on this kind of thing but i think it will happen more and more and more which uh not when engineers but when people out there that don't have an engineering background start interacting with increasingly intelligent systems we anthropomorphize them they they start to have deep impactful um interactions with us in a way that we miss them yeah when they're gone and we sure feel like they're living entities self-aware entities and maybe even we project sentience onto them so what what's your thought about this particular uh system was is uh have you ever met a\\n\\nthat are amazingly smart at certain things like maybe playing go and chess and other things but they don't feel at all in any shape or form conscious in the way that you know you do to me or i do to you and um and i think actually building ai is uh these intelligent constructs uh is one of the best ways to explore the mystery of consciousness to break it down because um we're going to have devices that are pretty smart at certain things or capable of certain things but potentially won't have any semblance of self-awareness or other things and in fact i would advocate if there's a choice building systems in the first place ai systems that are not conscious to begin with uh are just tools um until we understand them better and the capabilities better so on that topic just not as the ceo of deep mind just as a human being let me ask you about this one particular anecdotal evidence of the google engineer who made a comment or believed that there's some aspect of a language model the\",\n",
              " 'question': 'who is Demis'}"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "parallel_chain.invoke('who is Demis')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "xQvRBYEIp8aK"
      },
      "outputs": [],
      "source": [
        "parser = StrOutputParser()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "27VhkUiTqKWV"
      },
      "outputs": [],
      "source": [
        "main_chain = parallel_chain | prompt | llm | parser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S_D0wStSqOVg",
        "outputId": "371e748f-c19b-47fc-872e-00e1c03d356f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              +---------------------------------+           \n",
            "              | Parallel<context,question>Input |           \n",
            "              +---------------------------------+           \n",
            "                    ****                ****                \n",
            "                 ***                        ***             \n",
            "               **                              ***          \n",
            "+----------------------+                          **        \n",
            "| VectorStoreRetriever |                           *        \n",
            "+----------------------+                           *        \n",
            "            *                                      *        \n",
            "            *                                      *        \n",
            "            *                                      *        \n",
            "    +-------------+                         +-------------+ \n",
            "    | format_docs |                         | Passthrough | \n",
            "    +-------------+*                        +-------------+ \n",
            "                    ****                ****                \n",
            "                        ***          ***                    \n",
            "                           **      **                       \n",
            "              +----------------------------------+          \n",
            "              | Parallel<context,question>Output |          \n",
            "              +----------------------------------+          \n",
            "                                *                           \n",
            "                                *                           \n",
            "                                *                           \n",
            "                      +----------------+                    \n",
            "                      | PromptTemplate |                    \n",
            "                      +----------------+                    \n",
            "                                *                           \n",
            "                                *                           \n",
            "                                *                           \n",
            "                  +------------------------+                \n",
            "                  | ChatGoogleGenerativeAI |                \n",
            "                  +------------------------+                \n",
            "                                *                           \n",
            "                                *                           \n",
            "                                *                           \n",
            "                      +-----------------+                   \n",
            "                      | StrOutputParser |                   \n",
            "                      +-----------------+                   \n",
            "                                *                           \n",
            "                                *                           \n",
            "                                *                           \n",
            "                   +-----------------------+                \n",
            "                   | StrOutputParserOutput |                \n",
            "                   +-----------------------+                \n"
          ]
        }
      ],
      "source": [
        "main_chain.get_graph().print_ascii()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "m9drj87RrPEq",
        "outputId": "4c2f045f-c8fa-4d53-a0ed-3f2229942396"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Based on the transcript provided, the video is a conversation between Lex and Demis Hassabis. The summary of their discussion includes:\\n\\n*   **Explaining the Universe:** They discuss how a more fundamental and \"simpler explanation\" of the world might eventually replace the current standard model of physics and encompass mysteries like consciousness, life, and gravity.\\n*   **Defining Intelligence:** Demis suggests that a sign of intelligence is the ability to explain complex topics simply, referencing Richard Feynman as an example.\\n*   **Human-Computer Symbiosis:** They touch on how humans are already symbiotic with devices and the potential for enhancing ourselves.\\n*   **AI and Chess History:** They discuss the history of AI in chess, mentioning Claude Shannon\\'s 1949 program and Alan Turing, who had to run his own chess program by hand because computers were too slow. \\n*   **Deep Blue vs. Kasparov:** They reflect on Deep Blue’s victory over Garry Kasparov. The speaker notes they were more impressed by Kasparov’s mind than the \"brute\" calculation of the machine, as he could play at the same level using human intelligence.'"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "main_chain.invoke('Can you summarize the video')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NDylkDzasTAA"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
